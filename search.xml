<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[提供的并发容器总结]]></title>
    <url>%2Fblog%2F2019%2F09%2F13%2F%E9%AB%98%E5%B9%B6%E5%8F%91%2F%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[JDK提供的这些容器大部分在 java.util.concurrent 包中。 ConcurrentHashMap: 线程安全的HashMap CopyOnWriteArrayList: 线程安全的List，在读多写少的场合性能非常好，远远好于Vector. ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。 BlockingQueue: 这是一个接口，JDK内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。 ConcurrentSkipListMap: 跳表的实现。这是一个Map，使用跳表的数据结构进行快速查找。 二 ConcurrentHashMap我们知道 HashMap 不是线程安全的，在并发场景下如果要保证一种可行的方式是使用 Collections.synchronizedMap() 方法来包装我们的 HashMap。但这是通过使用一个全局的锁来同步不同线程间的并发访问，因此会带来不可忽视的性能问题。 所以就有了 HashMap 的线程安全版本—— ConcurrentHashMap 的诞生。在ConcurrentHashMap中，无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。 关于 ConcurrentHashMap 相关问题，我在 《这几道Java集合框架面试题几乎必问》 这篇文章中已经提到过。下面梳理一下关于 ConcurrentHashMap 比较重要的问题： ConcurrentHashMap 和 Hashtable 的区别 ConcurrentHashMap线程安全的具体实现方式/底层具体实现 三 CopyOnWriteArrayList3.1 CopyOnWriteArrayList 简介123public class CopyOnWriteArrayList&lt;E&gt;extends Objectimplements List&lt;E&gt;, RandomAccess, Cloneable, Serializable 在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问List的内部数据，毕竟读取操作是安全的。 这和我们之前在多线程章节讲过 ReentrantReadWriteLock 读写锁的思想非常类似，也就是读读共享、写写互斥、读写互斥、写读互斥。JDK中提供了 CopyOnWriteArrayList 类比相比于在读写锁的思想又更进一步。为了将读取的性能发挥到极致，CopyOnWriteArrayList 读取是完全不用加锁的，并且更厉害的是：写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待。这样一来，读操作的性能就会大幅度提升。那它是怎么做的呢？ 3.2 CopyOnWriteArrayList 是如何做到的？ CopyOnWriteArrayList 类的所有可变操作（add，set等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。 从 CopyOnWriteArrayList 的名字就能看出CopyOnWriteArrayList 是满足CopyOnWrite 的ArrayList，所谓CopyOnWrite 也就是说：在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。 3.3 CopyOnWriteArrayList 读取和写入源码简单分析3.3.1 CopyOnWriteArrayList 读取操作的实现读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全。 123456789101112/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array;public E get(int index) &#123; return get(getArray(), index);&#125;@SuppressWarnings("unchecked")private E get(Object[] a, int index) &#123; return (E) a[index];&#125;final Object[] getArray() &#123; return array;&#125; 3.3.2 CopyOnWriteArrayList 写入操作的实现CopyOnWriteArrayList 写入操作 add() 方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来。 1234567891011121314151617181920/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock();//加锁 try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1);//拷贝新数组 newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock();//释放锁 &#125;&#125; 四 ConcurrentLinkedQueueJava提供的线程安全的 Queue 可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。 从名字可以看出，ConcurrentLinkedQueue这个队列使用链表作为其数据结构．ConcurrentLinkedQueue 应该算是在高并发环境中性能最好的队列了。它之所有能有很好的性能，是因为其内部复杂的实现。 ConcurrentLinkedQueue 内部代码我们就不分析了，大家知道ConcurrentLinkedQueue 主要使用 CAS 非阻塞算法来实现线程安全就好了。 ConcurrentLinkedQueue 适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的ConcurrentLinkedQueue来替代。 五 BlockingQueue5.1 BlockingQueue 简单介绍上面我们己经提到了 ConcurrentLinkedQueue 作为高性能的非阻塞队列。下面我们要讲到的是阻塞队列——BlockingQueue。阻塞队列（BlockingQueue）被广泛使用在“生产者-消费者”问题中，其原因是BlockingQueue提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。 BlockingQueue 是一个接口，继承自 Queue，所以其实现类也可以作为 Queue 的实现来使用，而 Queue 又继承自 Collection 接口。下面是 BlockingQueue 的相关实现类： 下面主要介绍一下:ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue，这三个 BlockingQueue 的实现类。 5.2 ArrayBlockingQueueArrayBlockingQueue 是 BlockingQueue 接口的有界队列实现类，底层采用数组来实现。ArrayBlockingQueue一旦创建，容量不能改变。其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。 ArrayBlockingQueue 默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到 ArrayBlockingQueue。而非公平性则是指访问 ArrayBlockingQueue 的顺序不是遵守严格的时间顺序，有可能存在，当 ArrayBlockingQueue 可以被访问时，长时间阻塞的线程依然无法访问到 ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。如果需要获得公平性的 ArrayBlockingQueue，可采用如下代码： 1private static ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(10,true); 5.3 LinkedBlockingQueueLinkedBlockingQueue 底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足FIFO的特性，与ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于Integer.MAX_VALUE。 相关构造方法: 12345678910111213141516171819202122/** *某种意义上的无界队列 * Creates a &#123;@code LinkedBlockingQueue&#125; with a capacity of * &#123;@link Integer#MAX_VALUE&#125;. */public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE);&#125;/** *有界队列 * Creates a &#123;@code LinkedBlockingQueue&#125; with the given (fixed) capacity. * * @param capacity the capacity of this queue * @throws IllegalArgumentException if &#123;@code capacity&#125; is not greater * than zero */public LinkedBlockingQueue(int capacity) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new Node&lt;E&gt;(null);&#125; 5.4 PriorityBlockingQueuePriorityBlockingQueue 是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 compareTo() 方法来指定元素排序规则，或者初始化时通过构造器参数 Comparator 来指定排序规则。 PriorityBlockingQueue 并发控制采用的是 ReentrantLock，队列为无界队列（ArrayBlockingQueue 是有界队列，LinkedBlockingQueue 也可以通过在构造函数中传入 capacity 指定队列最大的容量，但是 PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容）。 简单地说，它就是 PriorityQueue 的线程安全版本。不可以插入 null 值，同时，插入队列的对象必须是可比较大小的（comparable），否则报 ClassCastException 异常。它的插入操作 put 方法不会 block，因为它是无界队列（take 方法在队列为空的时候会阻塞）。 推荐文章： 《解读 Java 并发队列 BlockingQueue》 https://javadoop.com/post/java-concurrent-queue 六 ConcurrentSkipListMap下面这部分内容参考了极客时间专栏《数据结构与算法之美》以及《实战Java高并发程序设计》。 为了引出ConcurrentSkipListMap，先带着大家简单理解一下跳表。 对于一个单链表，即使链表是有序的，如果我们想要在其中查找某个数据，也只能从头到尾遍历链表，这样效率自然就会很低，跳表就不一样了。跳表是一种可以用来快速查找的数据结构，有点类似于平衡树。它们都可以对元素进行快速的查找。但一个重要的区别是：对平衡树的插入和删除往往很可能导致平衡树进行一次全局的调整。而对跳表的插入和删除只需要对整个数据结构的局部进行操作即可。这样带来的好处是：在高并发的情况下，你会需要一个全局锁来保证整个平衡树的线程安全。而对于跳表，你只需要部分锁即可。这样，在高并发环境下，你就可以拥有更好的性能。而就查询的性能而言，跳表的时间复杂度也是 O(logn) 所以在并发数据结构中，JDK 使用跳表来实现一个 Map。 跳表的本质是同时维护了多个链表，并且链表是分层的， 最低层的链表维护了跳表内所有的元素，每上面一层链表都是下面一层的子集。 跳表内的所有链表的元素都是排序的。查找时，可以从顶级链表开始找。一旦发现被查找的元素大于当前链表中的取值，就会转入下一层链表继续找。这也就是说在查找过程中，搜索是跳跃式的。如上图所示，在跳表中查找元素18。 查找18 的时候原来需要遍历 18 次，现在只需要 7 次即可。针对链表长度比较大的时候，构建索引查找效率的提升就会非常明显。 从上面很容易看出，跳表是一种利用空间换时间的算法。 使用跳表实现Map 和使用哈希算法实现Map的另外一个不同之处是：哈希并不会保存元素的顺序，而跳表内所有的元素都是排序的。因此在对跳表进行遍历时，你会得到一个有序的结果。所以，如果你的应用需要有序性，那么跳表就是你不二的选择。JDK 中实现这一数据结构的类是ConcurrentSkipListMap。 七 参考 《实战Java高并发程序设计》 https://javadoop.com/post/java-concurrent-queue https://juejin.im/post/5aeebd02518825672f19c546]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS 简单介绍]]></title>
    <url>%2Fblog%2F2019%2F09%2F13%2F%E9%AB%98%E5%B9%B6%E5%8F%91%2FAQS%2F</url>
    <content type="text"><![CDATA[AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。 2 AQS 原理 在面试中被问到并发知识的时候，大多都会被问到“请你说一下自己对于AQS原理的理解”。下面给大家一个示例供大家参加，面试不是背题，大家一定要加入自己的思想，即使加入不了自己的思想也要保证自己能够通俗的讲出来而不是背出来。 下面大部分内容其实在AQS类注释上已经给出了，不过是英语看着比较吃力一点，感兴趣的话可以看看源码。 2.1 AQS 原理概览AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。 看个AQS(AbstractQueuedSynchronizer)原理图： AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。 1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 状态信息通过protected类型的getState，setState，compareAndSetState进行操作 12345678910111213//返回同步状态的当前值protected final int getState() &#123; return state;&#125; // 设置同步状态的值protected final void setState(int newState) &#123; state = newState;&#125;//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 2.2 AQS 对资源的共享方式AQS定义两种资源共享方式 Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。 ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在上层已经帮我们实现好了。 2.3 AQS底层使用了模板方法模式同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）： 使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放） 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。 这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用，下面简单的给大家介绍一下模板方法模式，模板方法模式是一个很容易理解的设计模式之一。 模板方法模式是基于”继承“的，主要是为了在不改变模板结构的前提下在子类中重新定义模板中的内容以实现复用代码。举个很简单的例子假如我们要去一个地方的步骤是：购票buyTicket()-&gt;安检securityCheck()-&gt;乘坐某某工具回家ride()-&gt;到达目的地arrive()。我们可能乘坐不同的交通工具回家比如飞机或者火车，所以除了ride()方法，其他方法的实现几乎相同。我们可以定义一个包含了这些方法的抽象类，然后用户根据自己的需要继承该抽象类然后修改 ride()方法。 AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法： 12345isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 推荐两篇 AQS 原理和相关源码分析的文章： http://www.cnblogs.com/waterystone/p/4920797.html https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html 3 Semaphore(信号量)-允许多个线程同时访问synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。示例代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940/** * * @author Snailclimb * @date 2018年9月30日 * @Description: 需要一次性拿一个许可的情况 */public class SemaphoreExample1 &#123; // 请求的数量 private static final int threadCount = 550; public static void main(String[] args) throws InterruptedException &#123; // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢） ExecutorService threadPool = Executors.newFixedThreadPool(300); // 一次只能允许执行的线程数量。 final Semaphore semaphore = new Semaphore(20); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadnum = i; threadPool.execute(() -&gt; &#123;// Lambda 表达式的运用 try &#123; semaphore.acquire();// 获取一个许可，所以可运行线程数量为20/1=20 test(threadnum); semaphore.release();// 释放一个许可 &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;); &#125; threadPool.shutdown(); System.out.println("finish"); &#125; public static void test(int threadnum) throws InterruptedException &#123; Thread.sleep(1000);// 模拟请求的耗时操作 System.out.println("threadnum:" + threadnum); Thread.sleep(1000);// 模拟请求的耗时操作 &#125;&#125; 执行 acquire 方法阻塞，直到有一个许可证可以获得然后拿走一个许可证；每个 release 方法增加一个许可证，这可能会释放一个阻塞的acquire方法。然而，其实并没有实际的许可证这个对象，Semaphore只是维持了一个可获得许可证的数量。 Semaphore经常用于限制获取某种资源的线程数量。 当然一次也可以一次拿取和释放多个许可，不过一般没有必要这样做： 123semaphore.acquire(5);// 获取5个许可，所以可运行线程数量为20/5=4test(threadnum);semaphore.release(5);// 获取5个许可，所以可运行线程数量为20/5=4 除了 acquire方法之外，另一个比较常用的与之对应的方法是tryAcquire方法，该方法如果获取不到许可就立即返回false。 Semaphore 有两种模式，公平模式和非公平模式。 公平模式： 调用acquire的顺序就是获取许可证的顺序，遵循FIFO； 非公平模式： 抢占式的。 Semaphore 对应的两个构造方法如下： 1234567public Semaphore(int permits) &#123; sync = new NonfairSync(permits); &#125; public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; 这两个构造方法，都必须提供许可的数量，第二个构造方法可以指定是公平模式还是非公平模式，默认非公平模式。 由于篇幅问题，如果对 Semaphore 源码感兴趣的朋友可以看下面这篇文章： https://blog.csdn.net/qq_19431333/article/details/70212663 4 CountDownLatch （倒计时器）CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。在Java并发中，countdownlatch的概念是一个常见的面试题，所以一定要确保你很好的理解了它。 4.1 CountDownLatch 的三种典型用法①某一线程在开始运行前等待n个线程执行完毕。将 CountDownLatch 的计数器初始化为n ：new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减1 countdownlatch.countDown()，当计数器的值变为0时，在CountDownLatch上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。 ②实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 ：new CountDownLatch(1)，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为0，多个线程同时被唤醒。 ③死锁检测：一个非常方便的使用场景是，你可以使用n个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。 4.2 CountDownLatch 的使用示例123456789101112131415161718192021222324252627282930313233343536373839/** * * @author SnailClimb * @date 2018年10月1日 * @Description: CountDownLatch 使用方法示例 */public class CountDownLatchExample1 &#123; // 请求的数量 private static final int threadCount = 550; public static void main(String[] args) throws InterruptedException &#123; // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢） ExecutorService threadPool = Executors.newFixedThreadPool(300); final CountDownLatch countDownLatch = new CountDownLatch(threadCount); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadnum = i; threadPool.execute(() -&gt; &#123;// Lambda 表达式的运用 try &#123; test(threadnum); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; finally &#123; countDownLatch.countDown();// 表示一个请求已经被完成 &#125; &#125;); &#125; countDownLatch.await(); threadPool.shutdown(); System.out.println("finish"); &#125; public static void test(int threadnum) throws InterruptedException &#123; Thread.sleep(1000);// 模拟请求的耗时操作 System.out.println("threadnum:" + threadnum); Thread.sleep(1000);// 模拟请求的耗时操作 &#125;&#125; 上面的代码中，我们定义了请求的数量为550，当这550个请求被处理完成之后，才会执行System.out.println(&quot;finish&quot;);。 与CountDownLatch的第一次交互是主线程等待其他线程。主线程必须在启动其他线程后立即调用CountDownLatch.await()方法。这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务。 其他N个线程必须引用闭锁对象，因为他们需要通知CountDownLatch对象，他们已经完成了各自的任务。这种通知机制是通过 CountDownLatch.countDown()方法来完成的；每调用一次这个方法，在构造函数中初始化的count值就减1。所以当N个线程都调 用了这个方法，count的值等于0，然后主线程就能通过await()方法，恢复执行自己的任务。 4.3 CountDownLatch 的不足CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。 4.4 CountDownLatch相常见面试题：解释一下CountDownLatch概念？ CountDownLatch 和CyclicBarrier的不同之处？ 给出一些CountDownLatch使用的例子？ CountDownLatch 类中主要的方法？ 5 CyclicBarrier(循环栅栏)CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。 CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 5.1 CyclicBarrier 的应用场景CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个Excel保存了用户所有银行流水，每个Sheet保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个sheet里的银行流水，都执行完之后，得到每个sheet的日均银行流水，最后，再用barrierAction用这些线程的计算结果，计算出整个Excel的日均银行流水。 5.2 CyclicBarrier 的使用示例示例1： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * * @author Snailclimb * @date 2018年10月1日 * @Description: 测试 CyclicBarrier 类中带参数的 await() 方法 */public class CyclicBarrierExample2 &#123; // 请求的数量 private static final int threadCount = 550; // 需要同步的线程数量 private static final CyclicBarrier cyclicBarrier = new CyclicBarrier(5); public static void main(String[] args) throws InterruptedException &#123; // 创建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadNum = i; Thread.sleep(1000); threadPool.execute(() -&gt; &#123; try &#123; test(threadNum); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;); &#125; threadPool.shutdown(); &#125; public static void test(int threadnum) throws InterruptedException, BrokenBarrierException &#123; System.out.println("threadnum:" + threadnum + "is ready"); try &#123; /**等待60秒，保证子线程完全执行结束*/ cyclicBarrier.await(60, TimeUnit.SECONDS); &#125; catch (Exception e) &#123; System.out.println("-----CyclicBarrierException------"); &#125; System.out.println("threadnum:" + threadnum + "is finish"); &#125;&#125; 运行结果，如下： 123456789101112131415161718192021threadnum:0is readythreadnum:1is readythreadnum:2is readythreadnum:3is readythreadnum:4is readythreadnum:4is finishthreadnum:0is finishthreadnum:1is finishthreadnum:2is finishthreadnum:3is finishthreadnum:5is readythreadnum:6is readythreadnum:7is readythreadnum:8is readythreadnum:9is readythreadnum:9is finishthreadnum:5is finishthreadnum:8is finishthreadnum:7is finishthreadnum:6is finish...... 可以看到当线程数量也就是请求数量达到我们定义的 5 个的时候， await方法之后的方法才被执行。 另外，CyclicBarrier还提供一个更高级的构造函数CyclicBarrier(int parties, Runnable barrierAction)，用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景。示例代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * * @author SnailClimb * @date 2018年10月1日 * @Description: 新建 CyclicBarrier 的时候指定一个 Runnable */public class CyclicBarrierExample3 &#123; // 请求的数量 private static final int threadCount = 550; // 需要同步的线程数量 private static final CyclicBarrier cyclicBarrier = new CyclicBarrier(5, () -&gt; &#123; System.out.println("------当线程数达到之后，优先执行------"); &#125;); public static void main(String[] args) throws InterruptedException &#123; // 创建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadNum = i; Thread.sleep(1000); threadPool.execute(() -&gt; &#123; try &#123; test(threadNum); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;); &#125; threadPool.shutdown(); &#125; public static void test(int threadnum) throws InterruptedException, BrokenBarrierException &#123; System.out.println("threadnum:" + threadnum + "is ready"); cyclicBarrier.await(); System.out.println("threadnum:" + threadnum + "is finish"); &#125;&#125; 运行结果，如下： 1234567891011121314151617181920212223threadnum:0is readythreadnum:1is readythreadnum:2is readythreadnum:3is readythreadnum:4is ready------当线程数达到之后，优先执行------threadnum:4is finishthreadnum:0is finishthreadnum:2is finishthreadnum:1is finishthreadnum:3is finishthreadnum:5is readythreadnum:6is readythreadnum:7is readythreadnum:8is readythreadnum:9is ready------当线程数达到之后，优先执行------threadnum:9is finishthreadnum:5is finishthreadnum:6is finishthreadnum:8is finishthreadnum:7is finish...... 5.3 CyclicBarrier和CountDownLatch的区别CountDownLatch是计数器，只能使用一次，而CyclicBarrier的计数器提供reset功能，可以多次使用。但是我不那么认为它们之间的区别仅仅就是这么简单的一点。我们来从jdk作者设计的目的来看，javadoc是这么描述它们的： CountDownLatch: A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.(CountDownLatch: 一个或者多个线程，等待其他多个线程完成某件事情之后才能执行；)CyclicBarrier : A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.(CyclicBarrier : 多个线程互相等待，直到到达同一个同步点，再继续一起执行。) 对于CountDownLatch来说，重点是“一个线程（多个线程）等待”，而其他的N个线程在完成“某件事情”之后，可以终止，也可以等待。而对于CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。 CountDownLatch是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而CyclicBarrier更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。 CyclicBarrier和CountDownLatch的区别这部分内容参考了如下两篇文章： https://blog.csdn.net/u010185262/article/details/54692886 https://blog.csdn.net/tolcf/article/details/50925145?utm_source=blogxgwz0 6 ReentrantLock 和 ReentrantReadWriteLockReentrantLock 和 synchronized 的区别在上面已经讲过了这里就不多做讲解。另外，需要注意的是：读写锁 ReentrantReadWriteLock 可以保证多个线程可以同时读，所以在读操作远大于写操作的时候，读写锁就非常有用了。 由于篇幅问题，关于 ReentrantLock 和 ReentrantReadWriteLock 详细内容可以查看我的这篇原创文章。 ReentrantLock 和 ReentrantReadWriteLock]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程悟道—学习前人怎么解决问题（一）]]></title>
    <url>%2Fblog%2F2019%2F08%2F27%2F%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%2F%E7%BC%96%E7%A8%8B%E4%B8%8E%E6%82%9F%E9%81%93%2F</url>
    <content type="text"><![CDATA[从”搬石头问题”引发的”集群搭建问题”小记：很多的文章都是纯理论和操作手册，我想通过写一些类似小故事的文章启发自己和大家养成一个程序员的思维，这样读起来会更容易一些。我觉得这是很重要的，他能帮助我们快速理解很多框架的实现原理。千峰的李卫民老师讲过道德经里的一句话“有道无术，术可求；有术无道，止于术”，我的目标是和大家一同“修道论术”。 博客：https://mrznan.github.io/blog/ ​ 首先给咱一个明确的定位，咱的工作就是搬石头！工头（客户端）是你老大，让你干啥就得干啥。 ​ 工头老大也没事别的事难为你，就是让你去搬石头（需求），刚开始你一个人还可以，一块大石头也就100来斤，老骨头还受得了。突然某一天，让你搬个300斤的石头，你没日没夜的搬石头，练就了一身肌肉，终于也勉强给抬起来了。 ​ 这就是所谓的垂直扩展，也就是提升自身硬实力，能从搬一百斤的石头飙升到三百斤，估计你的工资也翻了两三倍了吧！所以持续提升硬实力永远是不会错的，这是真理啊！（买牛逼服务器）。 ​ 更可恶的是，突然又一天，你接到的命令是抬起一块一吨重的石头，这下你可是犯了难了。 ​ 俗话说，人多力量大，你机智的选择了找你的狐朋狗友们来帮忙，一起抬。（所谓水平扩展） ​ 当然请了朋友来、打个电话、吃顿饭是免不了的了。思来想去，罗列步骤大致如下： ​ 1、想一想，都有谁能够帮我搬这块石头呢？于是拿小笔笔写了个名单。或者发个朋友圈，说我需要帮忙搬石头，愿意帮我的明天来“大同刀削面”集合。（配置，可以是互相寻找，也可以是主动注册） ​ 2、开始打电话，“老张”，过来帮咱搬一下石头呗！（老张心想，这货打电话准没好事！），同时又给单子上的其他人都打了电话。（首次进行了通信） ​ 3、你约定好定在“大同刀削面”给大家吃顿好的（真是小气），饭局中，你想到这搬石头的时候可不能瞎搬，万一弄不好砸了脚可不太好。你大概看了看，说道：“老李啊，你是我们这群人里，年纪最大的，你搬过的石头比我们吃过的盐还多，到时候，你可得给大家组织组织啊”。（选了个主节点） ​ 4、吃了饭，铆足了劲，大家开始活动了。工头见状：“哎呦，不错欧，懂得请后援了”，“工头大哥，一会我们搬得时候有啥问题，您就和我们老李说，他可是搬石头能手啊！”（对外只暴露一个入口） ​ 5、“老李啊，你组织大家把这块巨石从咱们喜马拉雅山低搬到山顶去哈！”，“我靠，一碗刀削面，你让我干了喜马拉雅山顶…算了,搬吧！真坑”。老李开始安排:”小王啊、你最年轻有劲，你就在最下边顶住啊 ….”。(资源分配)咱们下边的人先上一个台阶，上边的人再上哈，迈步子要整齐，可别乱了…(资源调度，任务调度) ​ 6、不巧老李上到半山腰病倒了下山回家去吧，你急了，老李现在不在了，我们怎么合作啊，再选一个指挥吧！那了大家投票吧，当然不能选自己，于是大家开始投票，有一半以上的人选了老赵，于是老赵有开始指挥大家去完成搬石头大任。（灾备） ​ 大致基本的流程就是这样，从单机到集群。最大的难点莫过于怎么把集群做成一台足够强大且永不挂机的单机**，无限强大意味着cpu要多少核有多少核，内存，磁盘要多大有多大，还有永远不挂。我们同样围绕这句话去思考，开始划重点了：1、一台，2、足够强大，3：永不挂机。 1、一台机器意味着对外要一致​ 先秦时期，很多有大权势，大财富的人都喜欢招收门客，当有人向他询问事情时，他们经常会寻求门客建议，大家共同商榷，那时的百家争鸣可能也和这多少有些关系，对外却仅仅只是你一个人而已。所谓“吕府”，大伙只知有吕不韦不知有其他耳。 2、足够强大意味着扩展要灵活​ 你家老爷再牛逼，个人能力再强大也是解决不了所有事情的，毕竟能当老爷的都是些大人物，事情都比较繁忙。所以广收天下门客才是硬道理，收门客有很多钟办法，但最常用的有两种：一是我知道诸葛亮是人才，所以我三顾茅庐，另一种是打出“广招门客”大旗，让天下人知我，投奔我，我则择优录用。（集群的搭建） ​ 当然，这么多门客的管理会让你有些又疼。 ​ 首先你要对这些门客统统进行备案，统计一下他的年龄，兴趣，爱好，有啥特长，是否娶妻等等（元数据），当有新的门客得到批准（在你这注册成功）加入这个团队后，还要有人把以上信息再补充上（服务注册与发现）。你时不时还要请大家一起吃个饭、点个名，看看谁没来，是请假了，还是出门发现自己生父是秦王直接撂挑子不干了（服务上下线）。 ​ 门客再多也不能解决无限多的问题，所以像这种有身份的人，一般会有一个看门老大爷和两三个门卫。他们的工作就是一天杵在哪里，看看谁来拜访我家老爷，如果拜访的太多了（并发太高），或者不合时宜（维护中），或者不想见（攻击者），这老大爷就会说：“各位请回吧！老爷今天不见客了。”，你压根连门也进不去！，（熔断，服务降级）。 3、永不挂机意味着在你能承受的风险面前他永远能用​ 一帮劫匪绑架了老爷，意图勒索钱财，这时就要选一个说了算的人出来主持大局，人选大致会有两种办法，一、老爷早就定了主持大局之人，潘小莲。二、没定的话就大家选举一个吧。（master挂了怎么办，高可用）最好得有个主心骨，要不然，我该听谁的，想想都脑袋疼。（脑裂） ​ 老爷被绑架我觉得是一个家族能够承受的风险，在这种情况下选一个主心骨，这个家一样能撑起来。什么是不能承受，比如你家老爷写了首诗“不教胡马度阴山”，皇帝一看，这胡马是不是在说我，一气之下诛九族。（灾备） ​ 这一切的目地就是，客户端要知道访问谁，服务端要一直知道我这有啥，我能干啥（鸡鸣狗盗随便来） 敲黑板了， ​ 总结一下重点要解决的问题，1、这么多门客，怎么管理，2、门客之间的关系，怎么维护，3、老爷或者门客出问题了该怎么办 ​ 翻译过来也就是，这么多节点，怎么建立联系形成集群，怎么管理节点分配任务和资源，怎么保持持续通信动态上下线，怎么保证持续可用实现永不挂机。看看大数据的hadoop，kafka，spark，包括现在的微服务等等都是在解决这些问题，这些问题得解决就使你在使用他们时就如同操作一台强大的单机。]]></content>
      <categories>
        <category>思想悟道</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>云计算</tag>
        <tag>思想悟道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2Fblog%2F2019%2F08%2F25%2F%E9%AB%98%E5%B9%B6%E5%8F%91%2FThredLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal简介通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK中提供的ThreadLocal类正是为了解决这样的问题。 ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。 如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get（） 和 set（） 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。 再举个简单的例子： 比如有两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么ThreadLocal就是用来这两个线程竞争的。 ThreadLocal示例相信看了上面的解释，大家已经搞懂 ThreadLocal 类是个什么东西了。 1234567891011121314151617181920212223242526272829303132import java.text.SimpleDateFormat;import java.util.Random;public class ThreadLocalExample implements Runnable&#123; // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本 private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat("yyyyMMdd HHmm")); public static void main(String[] args) throws InterruptedException &#123; ThreadLocalExample obj = new ThreadLocalExample(); for(int i=0 ; i&lt;10; i++)&#123; Thread t = new Thread(obj, ""+i); Thread.sleep(new Random().nextInt(1000)); t.start(); &#125; &#125; @Override public void run() &#123; System.out.println("Thread Name= "+Thread.currentThread().getName()+" default Formatter = "+formatter.get().toPattern()); try &#123; Thread.sleep(new Random().nextInt(1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //formatter pattern is changed here by thread, but it won't reflect to other threads formatter.set(new SimpleDateFormat()); System.out.println("Thread Name= "+Thread.currentThread().getName()+" formatter = "+formatter.get().toPattern()); &#125;&#125; Output: 1234567891011121314151617181920Thread Name= 0 default Formatter = yyyyMMdd HHmmThread Name= 0 formatter = yy-M-d ah:mmThread Name= 1 default Formatter = yyyyMMdd HHmmThread Name= 2 default Formatter = yyyyMMdd HHmmThread Name= 1 formatter = yy-M-d ah:mmThread Name= 3 default Formatter = yyyyMMdd HHmmThread Name= 2 formatter = yy-M-d ah:mmThread Name= 4 default Formatter = yyyyMMdd HHmmThread Name= 3 formatter = yy-M-d ah:mmThread Name= 4 formatter = yy-M-d ah:mmThread Name= 5 default Formatter = yyyyMMdd HHmmThread Name= 5 formatter = yy-M-d ah:mmThread Name= 6 default Formatter = yyyyMMdd HHmmThread Name= 6 formatter = yy-M-d ah:mmThread Name= 7 default Formatter = yyyyMMdd HHmmThread Name= 7 formatter = yy-M-d ah:mmThread Name= 8 default Formatter = yyyyMMdd HHmmThread Name= 9 default Formatter = yyyyMMdd HHmmThread Name= 8 formatter = yy-M-d ah:mmThread Name= 9 formatter = yy-M-d ah:mm 从输出中可以看出，Thread-0已经改变了formatter的值，但仍然是thread-2默认格式化程序与初始化值相同，其他线程也一样。 上面有一段代码用到了创建 ThreadLocal 变量的那段代码用到了 Java8 的知识，它等于下面这段代码，如果你写了下面这段代码的话，IDEA会提示你转换为Java8的格式(IDEA真的不错！)。因为ThreadLocal类在Java 8中扩展，使用一个新的方法withInitial()，将Supplier功能接口作为参数。 1234567private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = new ThreadLocal&lt;SimpleDateFormat&gt;()&#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat("yyyyMMdd HHmm"); &#125; &#125;; ThreadLocal原理从 Thread类源代码入手。 123456789public class Thread implements Runnable &#123; ......//与此线程有关的ThreadLocal值。由ThreadLocal类维护ThreadLocal.ThreadLocalMap threadLocals = null;//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ......&#125; 从上面Thread类 源代码可以看出Thread 类中有一个 threadLocals 和 一个 inheritableThreadLocals 变量，它们都是 ThreadLocalMap 类型的变量,我们可以把 ThreadLocalMap 理解为ThreadLocal 类实现的定制化的 HashMap。默认情况下这两个变量都是null，只有当前线程调用 ThreadLocal 类的 set或get方法时才创建它们，实际上调用这两个方法的时候，我们调用的是ThreadLocalMap类对应的 get()、set()方法。 ThreadLocal类的set()方法 1234567891011public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 通过上面这些内容，我们足以通过猜测得出结论：最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。 每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为key的键值对。这里解释了为什么每个线程访问同一个ThreadLocal，得到的确是不同的数值。另外，ThreadLocal 是 map结构是为了让每个线程可以关联多个 ThreadLocal变量。 ThreadLocalMap是ThreadLocal的静态内部类。 ThreadLocal 内存泄露问题ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候会 key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; 弱引用介绍： 如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发基础知识]]></title>
    <url>%2Fblog%2F2019%2F08%2F25%2F%E9%AB%98%E5%B9%B6%E5%8F%91%2F1%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Java 并发的基础知识，可能会在笔试中遇到，技术面试中也可能以并发知识环节提问的第一个问题出现。比如面试官可能会问你：“谈谈自己对于进程和线程的理解，两者的区别是什么？”本节思维导图：一 进程和线程进程和线程的对比这一知识点由于过于基础，所以在面试中很少碰到，但是极有可能会在笔试题中碰到。常见的提问形式是这样的：“什么是线程和进程?，请简要描述线程与进程的关系、区别及优缺点？ ”。 1.1. 何为进程?进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。 在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。 如下图所示，在 windows 中通过查看任务管理器的方式，我们就可以清楚看到 window 当前运行的进程（.exe 文件的运行）。 1.2 何为线程?线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 Java 程序天生就是多线程程序，我们可以通过 JMX 来看一下一个普通的 Java 程序有哪些线程，代码如下。 123456789101112public class MultiThread &#123; public static void main(String[] args) &#123; // 获取 Java 线程管理 MXBean ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean(); // 不需要获取同步的 monitor 和 synchronizer 信息，仅获取线程和线程堆栈信息 ThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false); // 遍历线程信息，仅打印线程 ID 和线程名称信息 for (ThreadInfo threadInfo : threadInfos) &#123; System.out.println("[" + threadInfo.getThreadId() + "] " + threadInfo.getThreadName()); &#125; &#125;&#125; 上述程序输出如下（输出内容可能不同，不用太纠结下面每个线程的作用，只用知道 main 线程执行 main 方法即可）： 12345[5] Attach Listener //添加事件[4] Signal Dispatcher // 分发处理给 JVM 信号的线程[3] Finalizer //调用对象 finalize 方法的线程[2] Reference Handler //清除 reference 线程[1] main //main 线程,程序入口 从上面的输出内容可以看出：一个 Java 程序的运行是 main 线程和多个其他线程同时运行。 1.3 从 JVM 角度说进程和线程之间的关系（重要）1.3.1 图解进程和线程的关系下图是 Java 内存区域，通过下图我们从 JVM 的角度来说一下线程和进程之间的关系。如果你对 Java 内存区域 (运行时数据区) 这部分知识不太了解的话可以阅读一下我的这篇文章：[《可能是把 Java 内存区域讲的最清楚的一篇文章》](https://github.com/Snailclimb/JavaGuide/blob/master/Java 相关/可能是把 Java 内存区域讲的最清楚的一篇文章.md) 从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的堆和方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的程序计数器、虚拟机栈 和 本地方法栈。 下面来思考这样一个问题：为什么程序计数器、虚拟机栈和本地方法栈是线程私有的呢？为什么堆和方法区是线程共享的呢？ 1.3.2 程序计数器为什么是私有的?程序计数器主要有下面两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。 所以，程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。 1.3.3 虚拟机栈和本地方法栈为什么是私有的? 虚拟机栈：每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。 本地方法栈：和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 所以，为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。 1.3.4 一句话简单了解堆和方法区堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 二 多线程并发编程2.1 并发与并行概念解读 并发： 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)； 并行：单位时间内，多个任务同时执行。 2.2 为什么要使用多线程?先从总体上来说： 从计算机底层来说：线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。 从当代互联网发展趋势来说：现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。 再深入到计算机底层来探讨： 单核时代： 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。 多核时代: 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。 2.3 使用多线程可能带来的问题并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、死锁还有受限于硬件和软件的资源闲置问题。 三 线程的创建与运行前两种实际上很少使用，一般都是用线程池的方式比较多一点。 3.1 继承 Thread 类的方式1234567public class MyThread extends Thread &#123; @Override public void run() &#123; super.run(); System.out.println("MyThread"); &#125;&#125; Run.java 123456789public class Run &#123; public static void main(String[] args) &#123; MyThread mythread = new MyThread(); mythread.start(); System.out.println("运行结束"); &#125;&#125; 运行结果： 从上面的运行结果可以看出：线程是一个子任务，CPU 以不确定的方式，或者说是以随机的时间来调用线程中的 run 方法。 3.2 实现 Runnable 接口的方式推荐实现 Runnable 接口方式开发多线程，因为 Java 单继承但是可以实现多个接口。 MyRunnable.java 123456public class MyRunnable implements Runnable &#123; @Override public void run() &#123; System.out.println("MyRunnable"); &#125;&#125; Run.java 12345678910public class Run &#123; public static void main(String[] args) &#123; Runnable runnable=new MyRunnable(); Thread thread=new Thread(runnable); thread.start(); System.out.println("运行结束！"); &#125;&#125; 运行结果： 3.3 使用线程池的方式使用线程池的方式也是最推荐的一种方式，另外，《阿里巴巴 Java 开发手册》在第一章第六节并发处理这一部分也强调到“线程资源必须通过线程池提供，不允许在应用中自行显示创建线程”。这里就不给大家演示代码了，线程池这一节会详细介绍到这部分内容。 四 线程的生命周期和状态Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4 节）。 线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4 节）： 由上图可以看出：线程创建之后它将处于 NEW（新建） 状态，调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 RUNNING（运行） 状态。 操作系统隐藏 Java 虚拟机（JVM）中的 RUNNABLE 和 RUNNING 状态，它只能看到 RUNNABLE 状态（图源：HowToDoInJava：Java Thread Life Cycle and Thread States），所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。 当线程执行 wait()方法之后，线程进入 WAITING（等待）状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。线程在执行 Runnable 的run()方法之后将会进入到 TERMINATED（终止） 状态。 五 线程优先级理论上来说系统会根据优先级来决定首先使哪个线程进入运行状态。当 CPU 比较闲的时候，设置线程优先级几乎不会有任何作用，而且很多操作系统压根不会不会理会你设置的线程优先级，所以不要让业务过度依赖于线程的优先级。 另外，线程优先级具有继承特性比如 A 线程启动 B 线程，则 B 线程的优先级和 A 是一样的。线程优先级还具有随机性 也就是说线程优先级高的不一定每一次都先执行完。 Thread 类中包含的成员变量代表了线程的某些优先级。如Thread.MIN_PRIORITY（常数 1），Thread.NORM_PRIORITY（常数 5）,Thread.MAX_PRIORITY（常数 10）。其中每个线程的优先级都在1 到10 之间，在默认情况下优先级都是Thread.NORM_PRIORITY（常数 5）。 一般情况下，不会对线程设定优先级别，更不会让某些业务严重地依赖线程的优先级别，比如权重，借助优先级设定某个任务的权重，这种方式是不可取的，一般定义线程的时候使用默认的优先级就好了。 相关方法： 12public final void setPriority(int newPriority) //为线程设定优先级public final int getPriority() //获取线程的优先级 设置线程优先级方法源码： 123456789101112131415public final void setPriority(int newPriority) &#123; ThreadGroup g; checkAccess(); //线程游戏优先级不能小于 1 也不能大于 10，否则会抛出异常 if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) &#123; throw new IllegalArgumentException(); &#125; //如果指定的线程优先级大于该线程所在线程组的最大优先级，那么该线程的优先级将设为线程组的最大优先级 if((g = getThreadGroup()) != null) &#123; if (newPriority &gt; g.getMaxPriority()) &#123; newPriority = g.getMaxPriority(); &#125; setPriority0(priority = newPriority); &#125;&#125; 六 守护线程和用户线程守护线程和用户线程简介: 用户 (User) 线程：运行在前台，执行具体的任务，如程序的主线程、连接网络的子线程等都是用户线程 守护 (Daemon) 线程：运行在后台，为其他前台线程服务.也可以说守护线程是 JVM 中非守护线程的 “佣人”。一旦所有用户线程都结束运行，守护线程会随 JVM 一起结束工作. main 函数所在的线程就是一个用户线程啊，main 函数启动的同时在 JVM 内部同时还启动了好多守护线程，比如垃圾回收线程。 那么守护线程和用户线程有什么区别呢？ 比较明显的区别之一是用户线程结束，JVM 退出，不管这个时候有没有守护线程运行。而守护线程不会影响 JVM 的退出。 注意事项： setDaemon(true)必须在start（）方法前执行，否则会抛出 IllegalThreadStateException 异常 在守护线程中产生的新线程也是守护线程 不是所有的任务都可以分配给守护线程来执行，比如读写操作或者计算逻辑 守护 (Daemon) 线程中不能依靠 finally 块的内容来确保执行关闭或清理资源的逻辑。因为我们上面也说过了一旦所有用户线程都结束运行，守护线程会随 JVM 一起结束工作，所以守护 (Daemon) 线程中的 finally 语句块可能无法被执行。 七 上下文切换多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换会这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。 Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。 八 线程死锁认识线程死锁多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。 下面通过一个例子来说明线程死锁,代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》)： 123456789101112131415161718192021222324252627282930313233343536public class DeadLockDemo &#123; private static Object resource1 = new Object();//资源 1 private static Object resource2 = new Object();//资源 2 public static void main(String[] args) &#123; new Thread(() -&gt; &#123; synchronized (resource1) &#123; System.out.println(Thread.currentThread() + "get resource1"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + "waiting get resource2"); synchronized (resource2) &#123; System.out.println(Thread.currentThread() + "get resource2"); &#125; &#125; &#125;, "线程 1").start(); new Thread(() -&gt; &#123; synchronized (resource2) &#123; System.out.println(Thread.currentThread() + "get resource2"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + "waiting get resource1"); synchronized (resource1) &#123; System.out.println(Thread.currentThread() + "get resource1"); &#125; &#125; &#125;, "线程 2").start(); &#125;&#125; Output 1234Thread[线程 1,5,main]get resource1Thread[线程 2,5,main]get resource2Thread[线程 1,5,main]waiting get resource2Thread[线程 2,5,main]waiting get resource1 线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过Thread.sleep(1000);让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。 学过操作系统的朋友都知道产生死锁必须具备以下四个条件： 互斥条件：该资源任意一个时刻只由一个线程占用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 如何避免线程死锁?我们只要破坏产生死锁的四个条件中的其中一个就可以了。 破坏互斥条件 这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。 破坏请求与保持条件 一次性申请所有的资源。 破坏不剥夺条件 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 破坏循环等待条件 靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 我们对线程 2 的代码修改成下面这样就不会产生死锁了。 1234567891011121314new Thread(() -&gt; &#123; synchronized (resource1) &#123; System.out.println(Thread.currentThread() + "get resource1"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + "waiting get resource2"); synchronized (resource2) &#123; System.out.println(Thread.currentThread() + "get resource2"); &#125; &#125;&#125;, "线程 2").start(); Output 12345678Thread[线程 1,5,main]get resource1Thread[线程 1,5,main]waiting get resource2Thread[线程 1,5,main]get resource2Thread[线程 2,5,main]get resource1Thread[线程 2,5,main]waiting get resource2Thread[线程 2,5,main]get resource2Process finished with exit code 0 我们分析一下上面的代码为什么避免了死锁的发生? 线程 1 首先获得到 resource1 的监视器锁,这时候线程 2 就获取不到了。然后线程 1 再去获取 resource2 的监视器锁，可以获取到。然后线程 1 释放了对 resource1、resource2 的监视器锁的占用，线程 2 获取到就可以执行了。这样就破坏了破坏循环等待条件，因此避免了死锁。 参考 《Java 并发编程之美》 《Java 并发编程的艺术》 https://howtodoinjava.com/java/multi-threading/java-thread-life-cycle-and-thread-states/]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Atomic 原子类介绍]]></title>
    <url>%2Fblog%2F2019%2F08%2F25%2F%E9%AB%98%E5%B9%B6%E5%8F%91%2FAtomic%2F</url>
    <content type="text"><![CDATA[Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。所以，所谓原子类说简单点就是具有原子/原子操作特征的类。并发包 java.util.concurrent 的原子类都存放在java.util.concurrent.atomic下,如下图所示。 根据操作的数据类型，可以将JUC包中的原子类分为4类 基本类型 使用原子的方式更新基本类型 AtomicInteger：整型原子类 AtomicLong：长整型原子类 AtomicBoolean ：布尔型原子类 数组类型 使用原子的方式更新数组里的某个元素 AtomicIntegerArray：整型数组原子类 AtomicLongArray：长整型数组原子类 AtomicReferenceArray ：引用类型数组原子类 引用类型 AtomicReference：引用类型原子类 AtomicStampedRerence：原子更新引用类型里的字段原子类 AtomicMarkableReference ：原子更新带有标记位的引用类型 对象的属性修改类型 AtomicIntegerFieldUpdater:原子更新整型字段的更新器 AtomicLongFieldUpdater：原子更新长整型字段的更新器 AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 下面我们来详细介绍一下这些原子类。 2 基本类型原子类2.1 基本类型原子类介绍使用原子的方式更新基本类型 AtomicInteger：整型原子类 AtomicLong：长整型原子类 AtomicBoolean ：布尔型原子类 上面三个类提供的方法几乎相同，所以我们这里以 AtomicInteger 为例子来介绍。 AtomicInteger 类常用方法 1234567public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并自增public final int getAndDecrement() //获取当前的值，并自减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 2.2 AtomicInteger 常见方法使用1234567891011121314151617import java.util.concurrent.atomic.AtomicInteger;public class AtomicIntegerTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub int temvalue = 0; AtomicInteger i = new AtomicInteger(0); temvalue = i.getAndSet(3); System.out.println("temvalue:" + temvalue + "; i:" + i);//temvalue:0; i:3 temvalue = i.getAndIncrement(); System.out.println("temvalue:" + temvalue + "; i:" + i);//temvalue:3; i:4 temvalue = i.getAndAdd(5); System.out.println("temvalue:" + temvalue + "; i:" + i);//temvalue:4; i:9 &#125;&#125; 2.3 基本数据类型原子类的优势通过一个简单例子带大家看一下基本数据类型原子类的优势 ①多线程环境不使用原子类保证线程安全（基本数据类型） 1234567891011class Test &#123; private volatile int count = 0; //若要线程安全执行执行count++，需要加锁 public synchronized void increment() &#123; count++; &#125; public int getCount() &#123; return count; &#125;&#125; ②多线程环境使用原子类保证线程安全（基本数据类型） 1234567891011class Test2 &#123; private AtomicInteger count = new AtomicInteger(); public void increment() &#123; count.incrementAndGet(); &#125; //使用AtomicInteger之后，不需要加锁，也可以实现线程安全。 public int getCount() &#123; return count.get(); &#125;&#125; 2.4 AtomicInteger 线程安全原理简单分析AtomicInteger 类的部分源码： 123456789101112// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。 3 数组类型原子类3.1 数组类型原子类介绍使用原子的方式更新数组里的某个元素 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray ：引用类型数组原子类 上面三个类提供的方法几乎相同，所以我们这里以 AtomicIntegerArray 为例子来介绍。 AtomicIntegerArray 类常用方法 1234567public final int get(int i) //获取 index=i 位置元素的值public final int getAndSet(int i, int newValue)//返回 index=i 位置的当前的值，并将其设置为新值：newValuepublic final int getAndIncrement(int i)//获取 index=i 位置元素的值，并让该位置的元素自增public final int getAndDecrement(int i) //获取 index=i 位置元素的值，并让该位置的元素自减public final int getAndAdd(int delta) //获取 index=i 位置元素的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将 index=i 位置的元素值设置为输入值（update）public final void lazySet(int i, int newValue)//最终 将index=i 位置的元素设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 3.2 AtomicIntegerArray 常见方法使用12345678910111213141516171819202122import java.util.concurrent.atomic.AtomicIntegerArray;public class AtomicIntegerArrayTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub int temvalue = 0; int[] nums = &#123; 1, 2, 3, 4, 5, 6 &#125;; AtomicIntegerArray i = new AtomicIntegerArray(nums); for (int j = 0; j &lt; nums.length; j++) &#123; System.out.println(i.get(j)); &#125; temvalue = i.getAndSet(0, 2); System.out.println("temvalue:" + temvalue + "; i:" + i); temvalue = i.getAndIncrement(0); System.out.println("temvalue:" + temvalue + "; i:" + i); temvalue = i.getAndAdd(0, 5); System.out.println("temvalue:" + temvalue + "; i:" + i); &#125;&#125; 4 引用类型原子类4.1 引用类型原子类介绍基本类型原子类只能更新一个变量，如果需要原子更新多个变量，需要使用 引用类型原子类。 AtomicReference：引用类型原子类 AtomicStampedRerence：原子更新引用类型里的字段原子类 AtomicMarkableReference ：原子更新带有标记位的引用类型 上面三个类提供的方法几乎相同，所以我们这里以 AtomicReference 为例子来介绍。 4.2 AtomicReference 类使用示例12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.concurrent.atomic.AtomicReference;public class AtomicReferenceTest &#123; public static void main(String[] args) &#123; AtomicReference&lt;Person&gt; ar = new AtomicReference&lt;Person&gt;(); Person person = new Person("SnailClimb", 22); ar.set(person); Person updatePerson = new Person("Daisy", 20); ar.compareAndSet(person, updatePerson); System.out.println(ar.get().getName()); System.out.println(ar.get().getAge()); &#125;&#125;class Person &#123; private String name; private int age; public Person(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 上述代码首先创建了一个 Person 对象，然后把 Person 对象设置进 AtomicReference 对象中，然后调用 compareAndSet 方法，该方法就是通过通过 CAS 操作设置 ar。如果 ar 的值为 person 的话，则将其设置为 updatePerson。实现原理与 AtomicInteger 类中的 compareAndSet 方法相同。运行上面的代码后的输出结果如下： 12Daisy20 4.3 AtomicStampedReference 类使用示例12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.concurrent.atomic.AtomicStampedReference;public class AtomicStampedReferenceDemo &#123; public static void main(String[] args) &#123; // 实例化、取当前值和 stamp 值 final Integer initialRef = 0, initialStamp = 0; final AtomicStampedReference&lt;Integer&gt; asr = new AtomicStampedReference&lt;&gt;(initialRef, initialStamp); System.out.println("currentValue=" + asr.getReference() + ", currentStamp=" + asr.getStamp()); // compare and set final Integer newReference = 666, newStamp = 999; final boolean casResult = asr.compareAndSet(initialRef, newReference, initialStamp, newStamp); System.out.println("currentValue=" + asr.getReference() + ", currentStamp=" + asr.getStamp() + ", casResult=" + casResult); // 获取当前的值和当前的 stamp 值 int[] arr = new int[1]; final Integer currentValue = asr.get(arr); final int currentStamp = arr[0]; System.out.println("currentValue=" + currentValue + ", currentStamp=" + currentStamp); // 单独设置 stamp 值 final boolean attemptStampResult = asr.attemptStamp(newReference, 88); System.out.println("currentValue=" + asr.getReference() + ", currentStamp=" + asr.getStamp() + ", attemptStampResult=" + attemptStampResult); // 重新设置当前值和 stamp 值 asr.set(initialRef, initialStamp); System.out.println("currentValue=" + asr.getReference() + ", currentStamp=" + asr.getStamp()); // [不推荐使用，除非搞清楚注释的意思了] weak compare and set // 困惑！weakCompareAndSet 这个方法最终还是调用 compareAndSet 方法。[版本: jdk-8u191] // 但是注释上写着 "May fail spuriously and does not provide ordering guarantees, // so is only rarely an appropriate alternative to compareAndSet." // todo 感觉有可能是 jvm 通过方法名在 native 方法里面做了转发 final boolean wCasResult = asr.weakCompareAndSet(initialRef, newReference, initialStamp, newStamp); System.out.println("currentValue=" + asr.getReference() + ", currentStamp=" + asr.getStamp() + ", wCasResult=" + wCasResult); &#125;&#125; 输出结果如下： 123456currentValue=0, currentStamp=0currentValue=666, currentStamp=999, casResult=truecurrentValue=666, currentStamp=999currentValue=666, currentStamp=88, attemptStampResult=truecurrentValue=0, currentStamp=0currentValue=666, currentStamp=999, wCasResult=true 4.4 AtomicStampedReference 类使用示例12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.concurrent.atomic.AtomicMarkableReference;public class AtomicMarkableReferenceDemo &#123; public static void main(String[] args) &#123; // 实例化、取当前值和 mark 值 final Boolean initialRef = null, initialMark = false; final AtomicMarkableReference&lt;Boolean&gt; amr = new AtomicMarkableReference&lt;&gt;(initialRef, initialMark); System.out.println("currentValue=" + amr.getReference() + ", currentMark=" + amr.isMarked()); // compare and set final Boolean newReference1 = true, newMark1 = true; final boolean casResult = amr.compareAndSet(initialRef, newReference1, initialMark, newMark1); System.out.println("currentValue=" + amr.getReference() + ", currentMark=" + amr.isMarked() + ", casResult=" + casResult); // 获取当前的值和当前的 mark 值 boolean[] arr = new boolean[1]; final Boolean currentValue = amr.get(arr); final boolean currentMark = arr[0]; System.out.println("currentValue=" + currentValue + ", currentMark=" + currentMark); // 单独设置 mark 值 final boolean attemptMarkResult = amr.attemptMark(newReference1, false); System.out.println("currentValue=" + amr.getReference() + ", currentMark=" + amr.isMarked() + ", attemptMarkResult=" + attemptMarkResult); // 重新设置当前值和 mark 值 amr.set(initialRef, initialMark); System.out.println("currentValue=" + amr.getReference() + ", currentMark=" + amr.isMarked()); // [不推荐使用，除非搞清楚注释的意思了] weak compare and set // 困惑！weakCompareAndSet 这个方法最终还是调用 compareAndSet 方法。[版本: jdk-8u191] // 但是注释上写着 "May fail spuriously and does not provide ordering guarantees, // so is only rarely an appropriate alternative to compareAndSet." // todo 感觉有可能是 jvm 通过方法名在 native 方法里面做了转发 final boolean wCasResult = amr.weakCompareAndSet(initialRef, newReference1, initialMark, newMark1); System.out.println("currentValue=" + amr.getReference() + ", currentMark=" + amr.isMarked() + ", wCasResult=" + wCasResult); &#125;&#125; 输出结果如下： 123456currentValue=null, currentMark=falsecurrentValue=true, currentMark=true, casResult=truecurrentValue=true, currentMark=truecurrentValue=true, currentMark=false, attemptMarkResult=truecurrentValue=null, currentMark=falsecurrentValue=true, currentMark=true, wCasResult=true 5 对象的属性修改类型原子类5.1 对象的属性修改类型原子类介绍如果需要原子更新某个类里的某个字段时，需要用到对象的属性修改类型原子类。 AtomicIntegerFieldUpdater:原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 要想原子地更新对象的属性需要两步。第一步，因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法 newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新的对象属性必须使用 public volatile 修饰符。 上面三个类提供的方法几乎相同，所以我们这里以 AtomicIntegerFieldUpdater为例子来介绍。 5.2 AtomicIntegerFieldUpdater 类使用示例123456789101112131415161718192021222324252627282930313233343536373839import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;public class AtomicIntegerFieldUpdaterTest &#123; public static void main(String[] args) &#123; AtomicIntegerFieldUpdater&lt;User&gt; a = AtomicIntegerFieldUpdater.newUpdater(User.class, "age"); User user = new User("Java", 22); System.out.println(a.getAndIncrement(user));// 22 System.out.println(a.get(user));// 23 &#125;&#125;class User &#123; private String name; public volatile int age; public User(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 输出结果： 122223]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发基础常见面试题总结2]]></title>
    <url>%2Fblog%2F2019%2F08%2F25%2F%E9%AB%98%E5%B9%B6%E5%8F%91%2FJavaConcurrencyBasicsCommonInterviewQuestionsSummary%2F</url>
    <content type="text"><![CDATA[1. 什么是线程和进程?1.1. 何为进程?进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。 如下图所示，在 windows 中通过查看任务管理器的方式，我们就可以清楚看到 window 当前运行的进程（.exe 文件的运行）。 1.2. 何为线程?线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 Java 程序天生就是多线程程序，我们可以通过 JMX 来看一下一个普通的 Java 程序有哪些线程，代码如下。 123456789101112public class MultiThread &#123; public static void main(String[] args) &#123; // 获取 Java 线程管理 MXBean ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean(); // 不需要获取同步的 monitor 和 synchronizer 信息，仅获取线程和线程堆栈信息 ThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false); // 遍历线程信息，仅打印线程 ID 和线程名称信息 for (ThreadInfo threadInfo : threadInfos) &#123; System.out.println("[" + threadInfo.getThreadId() + "] " + threadInfo.getThreadName()); &#125; &#125;&#125; 上述程序输出如下（输出内容可能不同，不用太纠结下面每个线程的作用，只用知道 main 线程执行 main 方法即可）： 12345[5] Attach Listener //添加事件[4] Signal Dispatcher // 分发处理给 JVM 信号的线程[3] Finalizer //调用对象 finalize 方法的线程[2] Reference Handler //清除 reference 线程[1] main //main 线程,程序入口 从上面的输出内容可以看出：一个 Java 程序的运行是 main 线程和多个其他线程同时运行。 2. 请简要描述线程与进程的关系,区别及优缺点？从 JVM 角度说进程和线程之间的关系 2.1. 图解进程和线程的关系下图是 Java 内存区域，通过下图我们从 JVM 的角度来说一下线程和进程之间的关系。如果你对 Java 内存区域 (运行时数据区) 这部分知识不太了解的话可以阅读一下这篇文章：[《可能是把 Java 内存区域讲的最清楚的一篇文章》](https://snailclimb.gitee.io/javaguide/#/java/可能是把 Java 内存区域讲的最清楚的一篇文章) 从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的堆和方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的程序计数器、虚拟机栈 和 本地方法栈。 总结： 线程 是 进程 划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反 下面是该知识点的扩展内容！ 下面来思考这样一个问题：为什么程序计数器、虚拟机栈和本地方法栈是线程私有的呢？为什么堆和方法区是线程共享的呢？ 2.2. 程序计数器为什么是私有的?程序计数器主要有下面两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。 所以，程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。 2.3. 虚拟机栈和本地方法栈为什么是私有的? 虚拟机栈：每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。 本地方法栈：和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 所以，为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。 2.4. 一句话简单了解堆和方法区堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 3. 说说并发与并行的区别? 并发： 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)； 并行： 单位时间内，多个任务同时执行。 4. 为什么要使用多线程呢?先从总体上来说： 从计算机底层来说： 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。 从当代互联网发展趋势来说： 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。 再深入到计算机底层来探讨： 单核时代： 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。 多核时代: 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。 5. 使用多线程可能带来什么问题?并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、死锁还有受限于硬件和软件的资源闲置问题。 6. 说说线程的生命周期和状态?Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4 节）。 线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4 节）： 由上图可以看出：线程创建之后它将处于 NEW（新建） 状态，调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 RUNNING（运行） 状态。 操作系统隐藏 Java 虚拟机（JVM）中的 RUNNABLE 和 RUNNING 状态，它只能看到 RUNNABLE 状态（图源：HowToDoInJava：Java Thread Life Cycle and Thread States），所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。 当线程执行 wait()方法之后，线程进入 WAITING（等待）状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。线程在执行 Runnable 的run()方法之后将会进入到 TERMINATED（终止） 状态。 7. 什么是上下文切换?多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换会这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。 Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。 8. 什么是线程死锁?如何避免死锁?8.1. 认识线程死锁多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。 ![线程死锁示意图 ](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-4/2019-4 死锁 1.png) 下面通过一个例子来说明线程死锁,代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》)： 123456789101112131415161718192021222324252627282930313233343536public class DeadLockDemo &#123; private static Object resource1 = new Object();//资源 1 private static Object resource2 = new Object();//资源 2 public static void main(String[] args) &#123; new Thread(() -&gt; &#123; synchronized (resource1) &#123; System.out.println(Thread.currentThread() + "get resource1"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + "waiting get resource2"); synchronized (resource2) &#123; System.out.println(Thread.currentThread() + "get resource2"); &#125; &#125; &#125;, "线程 1").start(); new Thread(() -&gt; &#123; synchronized (resource2) &#123; System.out.println(Thread.currentThread() + "get resource2"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + "waiting get resource1"); synchronized (resource1) &#123; System.out.println(Thread.currentThread() + "get resource1"); &#125; &#125; &#125;, "线程 2").start(); &#125;&#125; Output 1234Thread[线程 1,5,main]get resource1Thread[线程 2,5,main]get resource2Thread[线程 1,5,main]waiting get resource2Thread[线程 2,5,main]waiting get resource1 线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过Thread.sleep(1000);让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。 学过操作系统的朋友都知道产生死锁必须具备以下四个条件： 互斥条件：该资源任意一个时刻只由一个线程占用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 8.2. 如何避免线程死锁?我们只要破坏产生死锁的四个条件中的其中一个就可以了。 破坏互斥条件 这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。 破坏请求与保持条件 一次性申请所有的资源。 破坏不剥夺条件 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 破坏循环等待条件 靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 我们对线程 2 的代码修改成下面这样就不会产生死锁了。 1234567891011121314new Thread(() -&gt; &#123; synchronized (resource1) &#123; System.out.println(Thread.currentThread() + "get resource1"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + "waiting get resource2"); synchronized (resource2) &#123; System.out.println(Thread.currentThread() + "get resource2"); &#125; &#125;&#125;, "线程 2").start(); Output 12345678Thread[线程 1,5,main]get resource1Thread[线程 1,5,main]waiting get resource2Thread[线程 1,5,main]get resource2Thread[线程 2,5,main]get resource1Thread[线程 2,5,main]waiting get resource2Thread[线程 2,5,main]get resource2Process finished with exit code 0 我们分析一下上面的代码为什么避免了死锁的发生? 线程 1 首先获得到 resource1 的监视器锁,这时候线程 2 就获取不到了。然后线程 1 再去获取 resource2 的监视器锁，可以获取到。然后线程 1 释放了对 resource1、resource2 的监视器锁的占用，线程 2 获取到就可以执行了。这样就破坏了破坏循环等待条件，因此避免了死锁。 9. 说说 sleep() 方法和 wait() 方法区别和共同点? 两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。 两者都可以暂停线程的执行。 Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。 10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？这是另一个非常经典的 java 多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！ new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发进阶常见面试题总结1]]></title>
    <url>%2Fblog%2F2019%2F08%2F25%2F%E9%AB%98%E5%B9%B6%E5%8F%91%2FJavaConcurrencyAdvancedCommonInterviewQuestions%2F</url>
    <content type="text"><![CDATA[1. synchronized 关键字1.1. 说一说自己对于 synchronized 关键字的了解synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗synchronized关键字最主要的三种使用方式： 修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁 修饰静态方法: :也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 修饰代码块: 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 总结： synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到静态方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！ 下面我以一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。 面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！” 双重校验锁实现对象单例（线程安全） 1234567891011121314151617181920public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) &#123; //类对象加锁 synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。 uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出先问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 1.3. 讲一下 synchronized 关键字的底层原理synchronized 关键字底层原理属于 JVM 层面。 ① synchronized 同步语句块的情况 1234567public class SynchronizedDemo &#123; public void method() &#123; synchronized (this) &#123; System.out.println("synchronized 代码块"); &#125; &#125;&#125; 通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 javac SynchronizedDemo.java 命令生成编译后的 .class 文件，然后执行javap -c -s -v -l SynchronizedDemo.class。 从上面我们可以看出： synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。 ② synchronized 修饰方法的的情况 12345public class SynchronizedDemo2 &#123; public synchronized void method() &#123; System.out.println("synchronized 方法"); &#125;&#125; synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。 锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 关于这几种优化的详细信息可以查看：synchronized 关键字使用、底层原理、JDK1.6 之后的底层优化以及 和ReenTrantLock 的对比 1.5. 谈谈 synchronized和ReentrantLock 的区别① 两者都是可重入锁 两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。 ② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。 ③ ReentrantLock 比 synchronized 增加了一些高级功能 相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件） ReentrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。 ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。 synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。 如果你想使用上述功能，那么选择ReentrantLock是一个不错的选择。 ④ 性能已不是选择标准 2. volatile关键字2.1. 讲一下Java内存模型在 JDK1.2 之前，Java的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存本地内存比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。 要解决这个问题，就需要把变量声明为volatile，这就指示 JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。 说白了， volatile 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。 2.2. 说说 synchronized 关键字和 volatile 关键字的区别 synchronized关键字和volatile关键字比较 volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞 volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。 volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。 3. ThreadLocal3.1. ThreadLocal简介通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK中提供的ThreadLocal类正是为了解决这样的问题。 ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。 如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get（） 和 set（） 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。 再举个简单的例子： 比如有两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么ThreadLocal就是用来这两个线程竞争的。 3.2. ThreadLocal示例相信看了上面的解释，大家已经搞懂 ThreadLocal 类是个什么东西了。 1234567891011121314151617181920212223242526272829303132import java.text.SimpleDateFormat;import java.util.Random;public class ThreadLocalExample implements Runnable&#123; // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本 private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat("yyyyMMdd HHmm")); public static void main(String[] args) throws InterruptedException &#123; ThreadLocalExample obj = new ThreadLocalExample(); for(int i=0 ; i&lt;10; i++)&#123; Thread t = new Thread(obj, ""+i); Thread.sleep(new Random().nextInt(1000)); t.start(); &#125; &#125; @Override public void run() &#123; System.out.println("Thread Name= "+Thread.currentThread().getName()+" default Formatter = "+formatter.get().toPattern()); try &#123; Thread.sleep(new Random().nextInt(1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //formatter pattern is changed here by thread, but it won't reflect to other threads formatter.set(new SimpleDateFormat()); System.out.println("Thread Name= "+Thread.currentThread().getName()+" formatter = "+formatter.get().toPattern()); &#125;&#125; Output: 1234567891011121314151617181920Thread Name= 0 default Formatter = yyyyMMdd HHmmThread Name= 0 formatter = yy-M-d ah:mmThread Name= 1 default Formatter = yyyyMMdd HHmmThread Name= 2 default Formatter = yyyyMMdd HHmmThread Name= 1 formatter = yy-M-d ah:mmThread Name= 3 default Formatter = yyyyMMdd HHmmThread Name= 2 formatter = yy-M-d ah:mmThread Name= 4 default Formatter = yyyyMMdd HHmmThread Name= 3 formatter = yy-M-d ah:mmThread Name= 4 formatter = yy-M-d ah:mmThread Name= 5 default Formatter = yyyyMMdd HHmmThread Name= 5 formatter = yy-M-d ah:mmThread Name= 6 default Formatter = yyyyMMdd HHmmThread Name= 6 formatter = yy-M-d ah:mmThread Name= 7 default Formatter = yyyyMMdd HHmmThread Name= 7 formatter = yy-M-d ah:mmThread Name= 8 default Formatter = yyyyMMdd HHmmThread Name= 9 default Formatter = yyyyMMdd HHmmThread Name= 8 formatter = yy-M-d ah:mmThread Name= 9 formatter = yy-M-d ah:mm 从输出中可以看出，Thread-0已经改变了formatter的值，但仍然是thread-2默认格式化程序与初始化值相同，其他线程也一样。 上面有一段代码用到了创建 ThreadLocal 变量的那段代码用到了 Java8 的知识，它等于下面这段代码，如果你写了下面这段代码的话，IDEA会提示你转换为Java8的格式(IDEA真的不错！)。因为ThreadLocal类在Java 8中扩展，使用一个新的方法withInitial()，将Supplier功能接口作为参数。 1234567private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = new ThreadLocal&lt;SimpleDateFormat&gt;()&#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat("yyyyMMdd HHmm"); &#125; &#125;; 3.3. ThreadLocal原理从 Thread类源代码入手。 123456789public class Thread implements Runnable &#123; ......//与此线程有关的ThreadLocal值。由ThreadLocal类维护ThreadLocal.ThreadLocalMap threadLocals = null;//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ......&#125; 从上面Thread类 源代码可以看出Thread 类中有一个 threadLocals 和 一个 inheritableThreadLocals 变量，它们都是 ThreadLocalMap 类型的变量,我们可以把 ThreadLocalMap 理解为ThreadLocal 类实现的定制化的 HashMap。默认情况下这两个变量都是null，只有当前线程调用 ThreadLocal 类的 set或get方法时才创建它们，实际上调用这两个方法的时候，我们调用的是ThreadLocalMap类对应的 get()、set()方法。 ThreadLocal类的set()方法 1234567891011public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 通过上面这些内容，我们足以通过猜测得出结论：最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。 每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为key的键值对。这里解释了为什么每个线程访问同一个ThreadLocal，得到的确是不同的数值。另外，ThreadLocal 是 map结构是为了让每个线程可以关联多个 ThreadLocal变量。 ThreadLocalMap是ThreadLocal的静态内部类。 3.4. ThreadLocal 内存泄露问题ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候会 key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; 弱引用介绍： 如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 4. 线程池4.1. 为什么要用线程池？线程池提供了一种限制和管理资源（包括执行一个任务）。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。 这里借用《Java并发编程的艺术》提到的来说一下使用线程池的好处： 降低资源消耗。 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。 当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 4.2. 实现Runnable接口和Callable接口的区别如果想让线程池执行任务的话需要实现的Runnable接口或Callable接口。 Runnable接口或Callable接口实现类都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。两者的区别在于 Runnable 接口不会返回结果但是 Callable 接口可以返回结果。 备注： 工具类Executors可以实现Runnable对象和Callable对象之间的相互转换。（Executors.callable（Runnable task）或Executors.callable（Runnable task，Object resule））。 4.3. 执行execute()方法和submit()方法的区别是什么呢？ 1)execute() 方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否； 2)submit() 方法用于提交需要返回值的任务。线程池会返回一个Future类型的对象，通过这个Future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。 4.4. 如何创建线程池《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。 方式一：通过构造方法实现方式二：通过Executor 框架的工具类Executors来实现我们可以创建三种类型的ThreadPoolExecutor： FixedThreadPool ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。 SingleThreadExecutor： 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。 CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。 对应Executors工具类中的方法如图所示： 5. Atomic 原子类5.1. 介绍一下Atomic 原子类Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。 所以，所谓原子类说简单点就是具有原子/原子操作特征的类。 并发包 java.util.concurrent 的原子类都存放在java.util.concurrent.atomic下,如下图所示。 5.2. JUC 包中的原子类是哪4类?基本类型 使用原子的方式更新基本类型 AtomicInteger：整形原子类 AtomicLong：长整型原子类 AtomicBoolean：布尔型原子类 数组类型 使用原子的方式更新数组里的某个元素 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray：引用类型数组原子类 引用类型 AtomicReference：引用类型原子类 AtomicStampedRerence：原子更新引用类型里的字段原子类 AtomicMarkableReference ：原子更新带有标记位的引用类型 对象的属性修改类型 AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 5.3. 讲讲 AtomicInteger 的使用 AtomicInteger 类常用方法 1234567public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并自增public final int getAndDecrement() //获取当前的值，并自减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 AtomicInteger 类的使用示例 使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。 1234567891011class AtomicIntegerTest &#123; private AtomicInteger count = new AtomicInteger(); //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。 public void increment() &#123; count.incrementAndGet(); &#125; public int getCount() &#123; return count.get(); &#125;&#125; 5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理AtomicInteger 线程安全原理简单分析 AtomicInteger 类的部分源码： 123456789101112// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。 关于 Atomic 原子类这部分更多内容可以查看我的这篇文章：并发编程面试必备：JUC 中的 Atomic 原子类总结 6. AQS6.1. AQS 介绍AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。 AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。 6.2. AQS 原理分析AQS 原理这部分参考了部分博客，在5.2节末尾放了链接。 在面试中被问到并发知识的时候，大多都会被问到“请你说一下自己对于AQS原理的理解”。下面给大家一个示例供大家参加，面试不是背题，大家一定要假如自己的思想，即使加入不了自己的思想也要保证自己能够通俗的讲出来而不是背出来。 下面大部分内容其实在AQS类注释上已经给出了，不过是英语看着比较吃力一点，感兴趣的话可以看看源码。 6.2.1. AQS 原理概览AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。 看个AQS(AbstractQueuedSynchronizer)原理图： AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。 1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 状态信息通过protected类型的getState，setState，compareAndSetState进行操作 12345678910111213//返回同步状态的当前值protected final int getState() &#123; return state;&#125; // 设置同步状态的值protected final void setState(int newState) &#123; state = newState;&#125;//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 6.2.2. AQS 对资源的共享方式AQS定义两种资源共享方式 Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。 ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。 6.2.3. AQS底层使用了模板方法模式同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）： 使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放） 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。 这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。 AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法： 12345isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 推荐两篇 AQS 原理和相关源码分析的文章： http://www.cnblogs.com/waterystone/p/4920797.html https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html 6.3. AQS 组件总结 Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。 CountDownLatch （倒计时器）： CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。 CyclicBarrier(循环栅栏)： CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 7 Reference 《深入理解 Java 虚拟机》 《实战 Java 高并发程序设计》 《Java并发编程的艺术》 http://www.cnblogs.com/waterystone/p/4920797.html https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html https://www.journaldev.com/1076/java-threadlocal-example]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fblog%2F2019%2F08%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[oAuth2]]></title>
    <url>%2Fblog%2F2019%2F08%2F13%2F%E4%BA%91%E8%AE%A1%E7%AE%97%2FoAuth2%2F</url>
    <content type="text"><![CDATA[一、什么是 oAuth2oAuth 协议为用户资源的授权提供了一个安全的、开放而又简易的标准。与以往的授权方式不同之处是 oAuth 的授权不会使第三方触及到用户的帐号信息（如用户名与密码），即第三方无需使用用户的用户名与密码就可以申请获得该用户资源的授权，因此 oAuth 是安全的。二、什么是 Spring Security Spring Security 是一个安全框架，前身是 Acegi Security，能够为 Spring 企业应用系统提供声明式的安全访问控制。Spring Security 基于 Servlet 过滤器、IoC 和 AOP，为 Web 请求和方法调用提供身份确认和授权处理，避免了代码耦合，减少了大量重复代码工作。 三、为什么需要 oAuth21、应用场景我们假设你有一个“云笔记”产品，并提供了“云笔记服务”和“云相册服务”，此时用户需要在不同的设备（PC、Android、iPhone、TV、Watch）上去访问这些“资源”（笔记，图片），一切皆资源（restfull）。 那么用户如何才能访问属于自己的那部分资源呢？此时传统的做法就是提供自己的账号和密码给我们的“云笔记”，登录成功后就可以获取资源了。但这样的做法会有以下几个问题： “云笔记服务”和“云相册服务”会分别部署，难道我们要分别登录吗？ 如果有第三方应用程序想要接入我们的“云笔记”，难道需要用户提供账号和密码给第三方应用程序，让他记录后再访问我们的资源吗？ 用户如何限制第三方应用程序在我们“云笔记”的授权范围和使用期限？难道把所有资料都永久暴露给它吗？ 如果用户修改了密码收回了权限，那么所有第三方应用程序会全部失效。 只要有一个接入的第三方应用程序遭到破解，那么用户的密码就会泄露，后果不堪设想。 为了解决如上问题，oAuth 应用而生。 2、名词解释 第三方应用程序（Third-party application）： 又称之为客户端（client），比如上节中提到的设备（PC、Android、iPhone、TV、Watch），我们会在这些设备中安装我们自己研发的 APP。又比如我们的产品想要使用 QQ、微信等第三方登录。对我们的产品来说，QQ、微信登录是第三方登录系统。我们又需要第三方登录系统的资源（头像、昵称等）。对于 QQ、微信等系统我们又是第三方应用程序。 HTTP 服务提供商（HTTP service）： 我们的云笔记产品以及 QQ、微信等都可以称之为“服务提供商”。 资源所有者（Resource Owner）： 又称之为用户（user）。 用户代理（User Agent）： 比如浏览器，代替用户去访问这些资源。 认证服务器（Authorization server）： 即服务提供商专门用来处理认证的服务器，简单点说就是登录功能（验证用户的账号密码是否正确以及分配相应的权限） 资源服务器（Resource server）： 即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。简单点说就是资源的访问入口，比如上节中提到的“云笔记服务”和“云相册服务”都可以称之为资源服务器。 四、交互过程oAuth 在 “客户端” 与 “服务提供商” 之间，设置了一个授权层（authorization layer）。”客户端” 不能直接登录 “服务提供商”，只能登录授权层，以此将用户与客户端区分开来。”客户端” 登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。”客户端” 登录授权层以后，”服务提供商” 根据令牌的权限范围和有效期，向 “客户端” 开放用户储存的资料。 五、交互模型交互模型涉及三方： 资源拥有者：用户 客户端：APP 服务提供方：包含两个角色 认证服务器 资源服务器 六、认证服务器认证服务器负责对用户进行认证，并授权给客户端权限。认证很容易实现（验证账号密码即可），问题在于如何授权。比如我们使用第三方登录 “有道云笔记”，你可以看到如使用 QQ 登录的授权页面上有 “有道云笔记将获得以下权限” 的字样以及权限信息 认证服务器需要知道请求授权的客户端的身份以及该客户端请求的权限。我们可以为每一个客户端预先分配一个 id，并给每个 id 对应一个名称以及权限信息。这些信息可以写在认证服务器上的配置文件里。然后，客户端每次打开授权页面的时候，把属于自己的 id 传过来，如： 1http://www.funtl.com/login?client_id=yourClientId 随着时间的推移和业务的增长，会发现，修改配置的工作消耗了太多的人力。有没有办法把这个过程自动化起来，把人工从这些繁琐的操作中解放出来？当开始考虑这一步，开放平台的成型也就是水到渠成的事情了。 六、oAuth2 开放平台开放平台是由 oAuth2.0 协议衍生出来的一个产品。它的作用是让客户端自己去这上面进行注册、申请，通过之后系统自动分配 client_id ，并完成配置的自动更新（通常是写进数据库）。 客户端要完成申请，通常需要填写客户端程序的类型（Web、App 等）、企业介绍、执照、想要获取的权限等等信息。这些信息在得到服务提供方的人工审核通过后，开发平台就会自动分配一个 client_id 给客户端了。 到这里，已经实现了登录认证、授权页的信息展示。那么接下来，当用户成功进行授权之后，认证服务器需要把产生的 access_token 发送给客户端，方案如下： 让客户端在开放平台申请的时候，填写一个 URL，例如：http://www.funtl.com 每次当有用户授权成功之后，认证服务器将页面重定向到这个 URL（回调），并带上 access_token，例如：http://www.funtl.com?access_token=123456789 客户端接收到了这个 access_token，而且认证服务器的授权动作已经完成，刚好可以把程序的控制权转交回客户端，由客户端决定接下来向用户展示什么内容 七、令牌的访问与刷新1、Access TokenAccess Token 是客户端访问资源服务器的令牌。拥有这个令牌代表着得到用户的授权。然而，这个授权应该是 临时 的，有一定有效期。这是因为，Access Token 在使用的过程中 可能会泄露。给 Access Token 限定一个 较短的有效期 可以降低因 Access Token 泄露而带来的风险。 然而引入了有效期之后，客户端使用起来就不那么方便了。每当 Access Token 过期，客户端就必须重新向用户索要授权。这样用户可能每隔几天，甚至每天都需要进行授权操作。这是一件非常影响用户体验的事情。希望有一种方法，可以避免这种情况。 于是 oAuth2.0 引入了 Refresh Token 机制 2、Refresh TokenRefresh Token 的作用是用来刷新 Access Token。认证服务器提供一个刷新接口，例如： 1http://www.funtl.com/refresh?refresh_token=&amp;client_id= 传入 refresh_token 和 client_id，认证服务器验证通过后，返回一个新的 Access Token。为了安全，oAuth2.0 引入了两个措施： oAuth2.0 要求，Refresh Token 一定是保存在客户端的服务器上 ，而绝不能存放在狭义的客户端（例如 App、PC 端软件）上。调用 refresh 接口的时候，一定是从服务器到服务器的访问。 oAuth2.0 引入了 client_secret 机制。即每一个 client_id 都对应一个 client_secret。这个 client_secret 会在客户端申请 client_id 时，随 client_id 一起分配给客户端。客户端必须把 client_secret 妥善保管在服务器上，决不能泄露。刷新 Access Token 时，需要验证这个 client_secret。 实际上的刷新接口类似于： 1http://www.funtl.com/refresh?refresh_token=&amp;client_id=&amp;client_secret= 以上就是 Refresh Token 机制。Refresh Token 的有效期非常长，会在用户授权时，随 Access Token 一起重定向到回调 URL，传递给客户端。 八、客户端授权模式1、概述客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。oAuth 2.0 定义了四种授权方式。 implicit：简化模式，不推荐使用 authorization code：授权码模式 resource owner password credentials：密码模式 client credentials：客户端模式 2、简化模式简化模式适用于纯静态页面应用。所谓纯静态页面应用，也就是应用没有在服务器上执行代码的权限（通常是把代码托管在别人的服务器上），只有前端 JS 代码的控制权。 这种场景下，应用是没有持久化存储的能力的。因此，按照 oAuth2.0 的规定，这种应用是拿不到 Refresh Token 的。其整个授权流程如下： 该模式下，access_token 容易泄露且不可刷新 3、授权码模式授权码模式适用于有自己的服务器的应用，它是一个一次性的临时凭证，用来换取 access_token 和 refresh_token。认证服务器提供了一个类似这样的接口： 你用一开始的操作首先是获取了一个code，然后再用code获取token 1https://www.funtl.com/exchange?code=&amp;client_id=&amp;client_secret= 需要传入 code、client_id 以及 client_secret。验证通过后，返回 access_token 和 refresh_token。一旦换取成功，code 立即作废，不能再使用第二次。流程图如下： ​ 这个 code 的作用是保护 token 的安全性。上一节说到，简单模式下，token 是不安全的。这是因为在第 4 步当中直接把 token 返回给应用。而这一步容易被拦截、窃听。引入了 code 之后，即使攻击者能够窃取到 code，但是由于他无法获得应用保存在服务器的 `client_secret`，因此也无法通过 code 换取 token。而第 5 步，为什么不容易被拦截、窃听呢？这是因为，首先，这是一个从服务器到服务器的访问，黑客比较难捕捉到；其次，这个请求通常要求是 https 的实现。即使能窃听到数据包也无法解析出内容。 有了这个 code，token 的安全性大大提高。因此，oAuth2.0 鼓励使用这种方式进行授权，而简单模式则是在不得已情况下才会使用。 4、密码模式密码模式中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向 “服务商提供商” 索要授权。在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分。 一个典型的例子是同一个企业内部的不同产品要使用本企业的 oAuth2.0 体系。在有些情况下，产品希望能够定制化授权页面。由于是同个企业，不需要向用户展示“xxx将获取以下权限”等字样并询问用户的授权意向，而只需进行用户的身份认证即可。这个时候，由具体的产品团队开发定制化的授权界面，接收用户输入账号密码，并直接传递给鉴权服务器进行授权即可。 有一点需要特别注意的是，在第 2 步中，认证服务器需要对客户端的身份进行验证，确保是受信任的客户端。 5、客户端模式如果信任关系再进一步，或者调用者是一个后端的模块，没有用户界面的时候，可以使用客户端模式。鉴权服务器直接对客户端进行身份验证，验证通过后，返回 token。 九、基于Spring Security oAuth21、创建案例工程项目123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-samples&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;modules&gt; &lt;!-- 工程模块请随着项目的不断完善自行添加 --&gt; &lt;/modules&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;maven.compiler.source&gt;$&#123;java.version&#125;&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;$&#123;java.version&#125;&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;/properties&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-samples-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;default&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;spring-javaformat.version&gt;0.0.7&lt;/spring-javaformat.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-javaformat.version&#125;&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt;**/*Tests.java&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/Abstract*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;systemPropertyVariables&gt; &lt;java.security.egd&gt;file:/dev/./urandom&lt;/java.security.egd&gt; &lt;java.awt.headless&gt;true&lt;/java.awt.headless&gt; &lt;/systemPropertyVariables&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-enforcer-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;enforce-rules&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;enforce&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;rules&gt; &lt;bannedDependencies&gt; &lt;excludes&gt; &lt;exclude&gt;commons-logging:*:*&lt;/exclude&gt; &lt;/excludes&gt; &lt;searchTransitive&gt;true&lt;/searchTransitive&gt; &lt;/bannedDependencies&gt; &lt;/rules&gt; &lt;fail&gt;true&lt;/fail&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;name&gt;Spring Milestone&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;name&gt;Spring Milestone&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; 2、创建统一的依赖管理模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-samples-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;properties&gt; &lt;spring-cloud.version&gt;Greenwich.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;name&gt;Spring Milestone&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;name&gt;Spring Milestone&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; 3、创建 oAuth2 案例模块1234567891011121314151617181920212223242526272829303132333435&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-samples&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;modules&gt; &lt;!-- 工程模块请随着项目的不断完善自行添加 --&gt; &lt;/modules&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt;&lt;/project&gt; 4、创建认证服务器模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-security-oauth2-server&lt;/artifactId&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencies&gt; &lt;!-- Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.oauth2.OAuth2ServerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 5、Application123456789101112131415161718192021222324package com.funtl.oauth2;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * 认证服务器，用于获取 Token * &lt;p&gt; * Description: * &lt;/p&gt; * * @author Lusifer * @version v1.0.0 * @date 2019-04-01 16:06:45 * @see com.funtl.oauth2 */@SpringBootApplicationpublic class OAuth2ServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OAuth2ServerApplication.class, args); &#125;&#125; 6、基于内存存储令牌1、概述本章节基于 内存存储令牌 的模式用于演示最基本的操作，帮助大家快速理解 oAuth2 认证服务器中 “认证”、”授权”、”访问令牌” 的基本概念 2、操作流程 配置认证服务器 配置客户端信息： 1ClientDetailsServiceConfigurer inMemory：内存配置 withClient：客户端标识 secret：客户端安全码 authorizedGrantTypes：客户端授权类型 scopes：客户端授权范围 redirectUris：注册回调地址 配置 Web 安全 通过 GET 请求访问认证服务器获取授权码 端点：/oauth/authorize 通过 POST 请求利用授权码访问认证服务器获取令牌 端点：/oauth/token 附：默认的端点 URL /oauth/authorize：授权端点 /oauth/token：令牌端点 /oauth/confirm_access：用户确认授权提交端点 /oauth/error：授权服务错误信息端点 /oauth/check_token：用于资源服务访问的令牌解析端点 /oauth/token_key：提供公有密匙的端点，如果你使用 JWT 令牌的话 6、配置认证服务器创建一个类继承 AuthorizationServerConfigurerAdapter 并添加相关注解： @Configuration @EnableAuthorizationServer 12345678910111213141516171819202122232425262728package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;@Configuration@EnableAuthorizationServerpublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; // 配置客户端 clients // 使用内存设置 .inMemory() // client_id .withClient("client") // client_secret .secret("secret") // 授权类型 .authorizedGrantTypes("authorization_code") // 授权范围 .scopes("app") // 注册回调地址 .redirectUris("http://www.funtl.com"); &#125;&#125; 7、服务器安全配置创建一个类继承 WebSecurityConfigurerAdapter 并添加相关注解： @Configuration @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)：全局方法拦截 12345678910111213package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123;&#125; 8、application.yml123456789101112spring: application: name: oauth2-server security: user: # 账号 name: root # 密码 password: 123456server: port: 8080 9、访问获取授权码打开浏览器，输入地址： 1http://localhost:8080/oauth/authorize?client_id=client&amp;response_type=code 第一次访问会跳转到登录页面 验证成功后会询问用户是否授权客户端 选择授权后会跳转到我的博客，浏览器地址上还会包含一个授权码（code=1JuO6V），浏览器地址栏会显示如下地址： 1http://www.funtl.com/?code=1JuO6V 有了这个授权码就可以获取访问令牌了 10、通过授权码向服务器申请令牌通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 注意：此时无法请求到令牌，访问服务器会报错 There is no PasswordEncoder mapped for the id “null”解决方案请移步 这里 （1）问题描述按照 基于内存存储令牌 配置成功后，携授权码使用 POST 请求认证服务器时，服务器返回错误信息 版本 Spring Boot: 2.1.3.RELEASE Spring Security: 5.1.4.RELEASE 日志 1java.lang.IllegalArgumentException: There is no PasswordEncoder mapped for the id &quot;null&quot; （2）解决方案Spring Security 5.0 之前版本的 PasswordEncoder 接口默认实现为 NoOpPasswordEncoder 此时是可以使用明文密码的，在 5.0 之后默认实现类改为 DelegatingPasswordEncoder 此时密码必须以加密形式存储。 （3）application.yml删除 spring.security 相关配置，修改为 123456spring: application: name: oauth2-serverserver: port: 8080 （4）WebSecurityConfiguration1234567891011121314151617181920212223242526272829303132package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication() // 在内存中创建用户并为密码加密 .withUser("user").password(passwordEncoder().encode("123456")).roles("USER") .and() .withUser("admin").password(passwordEncoder().encode("123456")).roles("ADMIN"); &#125;&#125; （5）AuthorizationServerConfiguration123456789101112131415161718192021222324252627282930package com.funtl.oauth2.server.config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;@Configuration@EnableAuthorizationServerpublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; // 注入 WebSecurityConfiguration 中配置的 BCryptPasswordEncoder @Autowired private BCryptPasswordEncoder passwordEncoder; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; clients .inMemory() .withClient("client") // 还需要为 secret 加密 .secret(passwordEncoder.encode("secret")) .authorizedGrantTypes("authorization_code") .scopes("app") .redirectUris("http://www.funtl.com"); &#125;&#125; （6）测试访问通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 1 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; 11、基于 JDBC 存储令牌本章节 基于 JDBC 存储令牌 的模式用于演示最基本的操作，帮助大家快速理解 oAuth2 认证服务器中 “认证”、”授权”、”访问令牌” 的基本概念 操作流程 初始化 oAuth2 相关表 在数据库中配置客户端 配置认证服务器 配置数据源：DataSource 配置令牌存储方式：TokenStore -&gt; JdbcTokenStore 配置客户端读取方式：ClientDetailsService -&gt; JdbcClientDetailsService 配置服务端点信息： 1AuthorizationServerEndpointsConfigurer tokenStore：设置令牌存储方式 配置客户端信息： 1ClientDetailsServiceConfigurer withClientDetails：设置客户端配置读取方式 配置 Web 安全 配置密码加密方式：BCryptPasswordEncoder 配置认证信息：AuthenticationManagerBuilder 通过 GET 请求访问认证服务器获取授权码 端点：/oauth/authorize 通过 POST 请求利用授权码访问认证服务器获取令牌 端点：/oauth/token 附：默认的端点 URL /oauth/authorize：授权端点 /oauth/token：令牌端点 /oauth/confirm_access：用户确认授权提交端点 /oauth/error：授权服务错误信息端点 /oauth/check_token：用于资源服务访问的令牌解析端点 /oauth/token_key：提供公有密匙的端点，如果你使用 JWT 令牌的话 （1）初始化 oAuth2 相关表使用官方提供的建表脚本初始化 oAuth2 相关表，地址如下： 1https://github.com/spring-projects/spring-security-oauth/blob/master/spring-security-oauth2/src/test/resources/schema.sql 由于我们使用的是 MySQL 数据库，默认建表语句中主键为 VARCHAR(256)，这超过了最大的主键长度，请手动修改为 128，并用 BLOB 替换语句中的 LONGVARBINARY 类型，修改后的建表脚本如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869CREATE TABLE `clientdetails` ( `appId` varchar(128) NOT NULL, `resourceIds` varchar(256) DEFAULT NULL, `appSecret` varchar(256) DEFAULT NULL, `scope` varchar(256) DEFAULT NULL, `grantTypes` varchar(256) DEFAULT NULL, `redirectUrl` varchar(256) DEFAULT NULL, `authorities` varchar(256) DEFAULT NULL, `access_token_validity` int(11) DEFAULT NULL, `refresh_token_validity` int(11) DEFAULT NULL, `additionalInformation` varchar(4096) DEFAULT NULL, `autoApproveScopes` varchar(256) DEFAULT NULL, PRIMARY KEY (`appId`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_access_token` ( `token_id` varchar(256) DEFAULT NULL, `token` blob, `authentication_id` varchar(128) NOT NULL, `user_name` varchar(256) DEFAULT NULL, `client_id` varchar(256) DEFAULT NULL, `authentication` blob, `refresh_token` varchar(256) DEFAULT NULL, PRIMARY KEY (`authentication_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_approvals` ( `userId` varchar(256) DEFAULT NULL, `clientId` varchar(256) DEFAULT NULL, `scope` varchar(256) DEFAULT NULL, `status` varchar(10) DEFAULT NULL, `expiresAt` timestamp NULL DEFAULT NULL, `lastModifiedAt` timestamp NULL DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_client_details` ( `client_id` varchar(128) NOT NULL, `resource_ids` varchar(256) DEFAULT NULL, `client_secret` varchar(256) DEFAULT NULL, `scope` varchar(256) DEFAULT NULL, `authorized_grant_types` varchar(256) DEFAULT NULL, `web_server_redirect_uri` varchar(256) DEFAULT NULL, `authorities` varchar(256) DEFAULT NULL, `access_token_validity` int(11) DEFAULT NULL, `refresh_token_validity` int(11) DEFAULT NULL, `additional_information` varchar(4096) DEFAULT NULL, `autoapprove` varchar(256) DEFAULT NULL, PRIMARY KEY (`client_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_client_token` ( `token_id` varchar(256) DEFAULT NULL, `token` blob, `authentication_id` varchar(128) NOT NULL, `user_name` varchar(256) DEFAULT NULL, `client_id` varchar(256) DEFAULT NULL, PRIMARY KEY (`authentication_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_code` ( `code` varchar(256) DEFAULT NULL, `authentication` blob) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_refresh_token` ( `token_id` varchar(256) DEFAULT NULL, `token` blob, `authentication` blob) ENGINE=InnoDB DEFAULT CHARSET=utf8; （2）在数据库中配置客户端在表 oauth_client_details 中增加一条客户端配置记录，需要设置的字段如下： client_id：客户端标识 client_secret：客户端安全码，此处不能是明文，需要加密 scope：客户端授权范围 authorized_grant_types：客户端授权类型 web_server_redirect_uri：服务器回调地址 使用 BCryptPasswordEncoder 为客户端安全码加密，代码如下： 1System.out.println(new BCryptPasswordEncoder().encode("secret")); 数据库配置客户端效果图如下： 由于使用了 JDBC 存储，我们需要增加相关依赖，数据库连接池部分弃用 Druid 改为 HikariCP （号称全球最快连接池） 123456789101112131415161718192021&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;$&#123;hikaricp.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 排除 tomcat-jdbc 以使用 HikariCP --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt;&lt;/dependency&gt; （3）配置认证服务器创建一个类继承 AuthorizationServerConfigurerAdapter 并添加相关注解： @Configuration @EnableAuthorizationServer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.funtl.oauth2.server.config;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.jdbc.DataSourceBuilder;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer;import org.springframework.security.oauth2.provider.ClientDetailsService;import org.springframework.security.oauth2.provider.client.JdbcClientDetailsService;import org.springframework.security.oauth2.provider.token.TokenStore;import org.springframework.security.oauth2.provider.token.store.JdbcTokenStore;import javax.sql.DataSource;@Configuration@EnableAuthorizationServerpublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; @Bean @Primary @ConfigurationProperties(prefix = "spring.datasource") public DataSource dataSource() &#123; // 配置数据源（注意，我使用的是 HikariCP 连接池），以上注解是指定数据源，否则会有冲突 return DataSourceBuilder.create().build(); &#125; @Bean public TokenStore tokenStore() &#123; // 基于 JDBC 实现，令牌保存到数据 return new JdbcTokenStore(dataSource()); &#125; @Bean public ClientDetailsService jdbcClientDetails() &#123; // 基于 JDBC 实现，需要事先在数据库配置客户端信息 return new JdbcClientDetailsService(dataSource()); &#125; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; // 设置令牌 endpoints.tokenStore(tokenStore()); &#125; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; // 读取客户端配置 clients.withClientDetails(jdbcClientDetails()); &#125;&#125; （4）服务器安全配置创建一个类继承 WebSecurityConfigurerAdapter 并添加相关注解： @Configuration @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)：全局方法拦截 1234567891011121314151617181920212223242526272829303132package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication() // 在内存中创建用户并为密码加密 .withUser("user").password(passwordEncoder().encode("123456")).roles("USER") .and() .withUser("admin").password(passwordEncoder().encode("123456")).roles("ADMIN"); &#125;&#125; （5）application.yml123456789101112131415161718192021spring: application: name: oauth2-server datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://192.168.141.128:3307/oauth2?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 hikari: minimum-idle: 5 idle-timeout: 600000 maximum-pool-size: 10 auto-commit: true pool-name: MyHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1server: port: 8080 （6）访问获取授权码打开浏览器，输入地址： 1http://localhost:8080/oauth/authorize?client_id=client&amp;response_type=code 第一次访问会跳转到登录页面 验证成功后会询问用户是否授权客户端 选择授权后会跳转到我的博客，浏览器地址上还会包含一个授权码（code=1JuO6V），浏览器地址栏会显示如下地址： 1http://www.funtl.com/?code=1JuO6V 有了这个授权码就可以获取访问令牌了 （7）通过授权码向服务器申请令牌通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 1 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; 操作成功后数据库 oauth_access_token 表中会增加一笔记录，效果图如下： 十、RBAC 基于角色的权限控制RBAC（Role-Based Access Control，基于角色的访问控制），就是用户通过角色与权限进行关联。简单地说，一个用户拥有若干角色，每一个角色拥有若干权限。这样，就构造成“用户-角色-权限”的授权模型。在这种模型中，用户与角色之间，角色与权限之间，一般是多对多的关系。（如下图） 1、目的在我们的 oAuth2 系统中，我们需要对系统的所有资源进行权限控制，系统中的资源包括： 静态资源（对象资源）：功能操作、数据列 动态资源（数据资源）：数据 系统的目的就是对应用系统的所有对象资源和数据资源进行权限控制，比如：功能菜单、界面按钮、数据显示的列、各种行级数据进行权限的操控 2、对象关系3、权限系统的所有权限信息。权限具有上下级关系，是一个树状的结构。如： 系统管理 用户管理 查看用户 新增用户 修改用户 删除用户 4、用户系统的具体操作者，可以归属于一个或多个角色，它与角色的关系是多对多的关系 5、角色为了对许多拥有相似权限的用户进行分类管理，定义了角色的概念，例如系统管理员、管理员、用户、访客等角色。角色具有上下级关系，可以形成树状视图，父级角色的权限是自身及它的所有子角色的权限的综合。父级角色的用户、父级角色的组同理可推。 6、关系图 7、模块图8、表结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950CREATE TABLE `tb_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父权限', `name` varchar(64) NOT NULL COMMENT '权限名称', `enname` varchar(64) NOT NULL COMMENT '权限英文名称', `url` varchar(255) NOT NULL COMMENT '授权路径', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='权限表';CREATE TABLE `tb_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父角色', `name` varchar(64) NOT NULL COMMENT '角色名称', `enname` varchar(64) NOT NULL COMMENT '角色英文名称', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='角色表';CREATE TABLE `tb_role_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `role_id` bigint(20) NOT NULL COMMENT '角色 ID', `permission_id` bigint(20) NOT NULL COMMENT '权限 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='角色权限表';CREATE TABLE `tb_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `username` varchar(50) NOT NULL COMMENT '用户名', `password` varchar(64) NOT NULL COMMENT '密码，加密存储', `phone` varchar(20) DEFAULT NULL COMMENT '注册手机号', `email` varchar(50) DEFAULT NULL COMMENT '注册邮箱', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`) USING BTREE, UNIQUE KEY `phone` (`phone`) USING BTREE, UNIQUE KEY `email` (`email`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='用户表';CREATE TABLE `tb_user_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `user_id` bigint(20) NOT NULL COMMENT '用户 ID', `role_id` bigint(20) NOT NULL COMMENT '角色 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='用户角色表'; 十一、基于 RBAC 的自定义认证在实际开发中，我们的用户信息都是存在数据库里的，本章节基于 RBAC 模型 将用户的认证信息与数据库对接，实现真正的用户认证与授权 操作流程 继续 基于 JDBC 存储令牌 章节的代码开发 初始化 RBAC 相关表 在数据库中配置“用户”、“角色”、“权限”相关信息 数据库操作使用 tk.mybatis 框架，故需要增加相关依赖 配置 Web 安全 配置使用自定义认证与授权 通过 GET 请求访问认证服务器获取授权码 端点：/oauth/authorize 通过 POST 请求利用授权码访问认证服务器获取令牌 端点：/oauth/token 附：默认的端点 URL /oauth/authorize：授权端点 /oauth/token：令牌端点 /oauth/confirm_access：用户确认授权提交端点 /oauth/error：授权服务错误信息端点 /oauth/check_token：用于资源服务访问的令牌解析端点 /oauth/token_key：提供公有密匙的端点，如果你使用 JWT 令牌的话 1、初始化 RBAC 相关表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970CREATE TABLE `tb_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父权限', `name` varchar(64) NOT NULL COMMENT '权限名称', `enname` varchar(64) NOT NULL COMMENT '权限英文名称', `url` varchar(255) NOT NULL COMMENT '授权路径', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=44 DEFAULT CHARSET=utf8 COMMENT='权限表';insert into `tb_permission`(`id`,`parent_id`,`name`,`enname`,`url`,`description`,`created`,`updated`) values (37,0,'系统管理','System','/',NULL,'2019-04-04 23:22:54','2019-04-04 23:22:56'),(38,37,'用户管理','SystemUser','/users/',NULL,'2019-04-04 23:25:31','2019-04-04 23:25:33'),(39,38,'查看用户','SystemUserView','',NULL,'2019-04-04 15:30:30','2019-04-04 15:30:43'),(40,38,'新增用户','SystemUserInsert','',NULL,'2019-04-04 15:30:31','2019-04-04 15:30:44'),(41,38,'编辑用户','SystemUserUpdate','',NULL,'2019-04-04 15:30:32','2019-04-04 15:30:45'),(42,38,'删除用户','SystemUserDelete','',NULL,'2019-04-04 15:30:48','2019-04-04 15:30:45');CREATE TABLE `tb_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父角色', `name` varchar(64) NOT NULL COMMENT '角色名称', `enname` varchar(64) NOT NULL COMMENT '角色英文名称', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='角色表';insert into `tb_role`(`id`,`parent_id`,`name`,`enname`,`description`,`created`,`updated`) values (37,0,'超级管理员','admin',NULL,'2019-04-04 23:22:03','2019-04-04 23:22:05');CREATE TABLE `tb_role_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `role_id` bigint(20) NOT NULL COMMENT '角色 ID', `permission_id` bigint(20) NOT NULL COMMENT '权限 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=43 DEFAULT CHARSET=utf8 COMMENT='角色权限表';insert into `tb_role_permission`(`id`,`role_id`,`permission_id`) values (37,37,37),(38,37,38),(39,37,39),(40,37,40),(41,37,41),(42,37,42);CREATE TABLE `tb_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `username` varchar(50) NOT NULL COMMENT '用户名', `password` varchar(64) NOT NULL COMMENT '密码，加密存储', `phone` varchar(20) DEFAULT NULL COMMENT '注册手机号', `email` varchar(50) DEFAULT NULL COMMENT '注册邮箱', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`) USING BTREE, UNIQUE KEY `phone` (`phone`) USING BTREE, UNIQUE KEY `email` (`email`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='用户表';insert into `tb_user`(`id`,`username`,`password`,`phone`,`email`,`created`,`updated`) values (37,'admin','$2a$10$9ZhDOBp.sRKat4l14ygu/.LscxrMUcDAfeVOEPiYwbcRkoB09gCmi','15888888888','lee.lusifer@gmail.com','2019-04-04 23:21:27','2019-04-04 23:21:29');CREATE TABLE `tb_user_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `user_id` bigint(20) NOT NULL COMMENT '用户 ID', `role_id` bigint(20) NOT NULL COMMENT '角色 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='用户角色表';insert into `tb_user_role`(`id`,`user_id`,`role_id`) values (37,37,37); 由于使用了 BCryptPasswordEncoder 的加密方式，故用户密码需要加密，代码如下： 1System.out.println(new BCryptPasswordEncoder().encode("123456")); 数据库操作采用 tk.mybatis 框架，需增加相关依赖 1234&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 2、关键步骤由于本次增加了 MyBatis 相关操作，代码增加较多，可以参考我 GitHub 上的源码，下面仅列出关键步骤及代码 （1）获取用户信息目的是为了实现自定义认证授权时可以通过数据库查询用户信息，Spring Security oAuth2 要求使用 username 的方式查询，提供相关用户信息后，认证工作由框架自行完成 1234567891011121314151617181920212223package com.funtl.oauth2.server.service.impl;import com.funtl.oauth2.server.domain.TbUser;import com.funtl.oauth2.server.mapper.TbUserMapper;import com.funtl.oauth2.server.service.TbUserService;import org.springframework.stereotype.Service;import tk.mybatis.mapper.entity.Example;import javax.annotation.Resource;@Servicepublic class TbUserServiceImpl implements TbUserService &#123; @Resource private TbUserMapper tbUserMapper; @Override public TbUser getByUsername(String username) &#123; Example example = new Example(TbUser.class); example.createCriteria().andEqualTo("username", username); return tbUserMapper.selectOneByExample(example); &#125;&#125; （2）获取用户权限信息认证成功后需要给用户授权，具体的权限已经存储在数据库里了，SQL 语句如下： 12345678910111213SELECT p.*FROM tb_user AS u LEFT JOIN tb_user_role AS ur ON u.id = ur.user_id LEFT JOIN tb_role AS r ON r.id = ur.role_id LEFT JOIN tb_role_permission AS rp ON r.id = rp.role_id LEFT JOIN tb_permission AS p ON p.id = rp.permission_idWHERE u.id = &lt;yourUserId&gt; （3）自定义认证授权实现类创建一个类，实现 UserDetailsService 接口，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.funtl.oauth2.server.config.service;import com.funtl.oauth2.server.domain.TbPermission;import com.funtl.oauth2.server.domain.TbUser;import com.funtl.oauth2.server.service.TbPermissionService;import com.funtl.oauth2.server.service.TbUserService;import org.assertj.core.util.Lists;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.security.core.GrantedAuthority;import org.springframework.security.core.authority.SimpleGrantedAuthority;import org.springframework.security.core.userdetails.User;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.core.userdetails.UsernameNotFoundException;import org.springframework.stereotype.Service;import java.util.List;/** * 自定义用户认证与授权 * &lt;p&gt; * Description: * &lt;/p&gt; * * @author Lusifer * @version v1.0.0 * @date 2019-04-04 23:57:04 * @see com.funtl.oauth2.server.config */@Servicepublic class UserDetailsServiceImpl implements UserDetailsService &#123; @Autowired private TbUserService tbUserService; @Autowired private TbPermissionService tbPermissionService; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; // 查询用户信息 TbUser tbUser = tbUserService.getByUsername(username); List&lt;GrantedAuthority&gt; grantedAuthorities = Lists.newArrayList(); if (tbUser != null) &#123; // 获取用户授权 List&lt;TbPermission&gt; tbPermissions = tbPermissionService.selectByUserId(tbUser.getId()); // 声明用户授权 tbPermissions.forEach(tbPermission -&gt; &#123; if (tbPermission != null &amp;&amp; tbPermission.getEnname() != null) &#123; GrantedAuthority grantedAuthority = new SimpleGrantedAuthority(tbPermission.getEnname()); grantedAuthorities.add(grantedAuthority); &#125; &#125;); &#125; // 由框架完成认证工作 return new User(tbUser.getUsername(), tbUser.getPassword(), grantedAuthorities); &#125;&#125; （4）服务器安全配置创建一个类继承 WebSecurityConfigurerAdapter 并添加相关注解： @Configuration @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)：全局方法拦截 1234567891011121314151617181920212223242526272829303132333435package com.funtl.oauth2.server.config;import com.funtl.oauth2.server.config.service.UserDetailsServiceImpl;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Bean @Override public UserDetailsService userDetailsService() &#123; return new UserDetailsServiceImpl(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; // 使用自定义认证与授权 auth.userDetailsService(userDetailsService()); &#125;&#125; （5）Application增加了 Mapper 的包扫描配置 1234567891011121314151617181920212223242526package com.funtl.oauth2;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import tk.mybatis.spring.annotation.MapperScan;/** * 认证服务器，用于获取 Token * &lt;p&gt; * Description: * &lt;/p&gt; * * @author Lusifer * @version v1.0.0 * @date 2019-04-01 16:06:45 * @see com.funtl.oauth2 */@SpringBootApplication@MapperScan(basePackages = "com.funtl.oauth2.server.mapper")public class OAuth2ServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OAuth2ServerApplication.class, args); &#125;&#125; （6）application.yml增加了 MyBatis 配置 12345678910111213141516171819202122232425spring: application: name: oauth2-server datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://192.168.141.128:3307/oauth2?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 hikari: minimum-idle: 5 idle-timeout: 600000 maximum-pool-size: 10 auto-commit: true pool-name: MyHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1server: port: 8080mybatis: type-aliases-package: com.funtl.oauth2.server.domain mapper-locations: classpath:mapper/*.xml （7）访问获取授权码打开浏览器，输入地址： 1http://localhost:8080/oauth/authorize?client_id=client&amp;response_type=code 第一次访问会跳转到登录页面 验证成功后会询问用户是否授权客户端 选择授权后会跳转到我的博客，浏览器地址上还会包含一个授权码（code=1JuO6V），浏览器地址栏会显示如下地址： 1http://www.funtl.com/?code=1JuO6V 有了这个授权码就可以获取访问令牌了 （8）通过授权码向服务器申请令牌通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 1 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; 操作成功后数据库 oauth_access_token 表中会增加一笔记录，效果图如下： here is no PasswordEncoder mapped 3、问题描述按照 基于内存存储令牌 配置成功后，携授权码使用 POST 请求认证服务器时，服务器返回错误信息 版本 Spring Boot: 2.1.3.RELEASE Spring Security: 5.1.4.RELEASE 日志 1java.lang.IllegalArgumentException: There is no PasswordEncoder mapped for the id &quot;null&quot; （1）解决方案Spring Security 5.0 之前版本的 PasswordEncoder 接口默认实现为 NoOpPasswordEncoder 此时是可以使用明文密码的，在 5.0 之后默认实现类改为 DelegatingPasswordEncoder 此时密码必须以加密形式存储。 （2）application.yml删除 spring.security 相关配置，修改为 123456spring: application: name: oauth2-serverserver: port: 8080 （3）WebSecurityConfiguration1234567891011121314151617181920212223242526272829303132package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication() // 在内存中创建用户并为密码加密 .withUser("user").password(passwordEncoder().encode("123456")).roles("USER") .and() .withUser("admin").password(passwordEncoder().encode("123456")).roles("ADMIN"); &#125;&#125; （4）AuthorizationServerConfiguration123456789101112131415161718192021222324252627282930package com.funtl.oauth2.server.config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;@Configuration@EnableAuthorizationServerpublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; // 注入 WebSecurityConfiguration 中配置的 BCryptPasswordEncoder @Autowired private BCryptPasswordEncoder passwordEncoder; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; clients .inMemory() .withClient("client") // 还需要为 secret 加密 .secret(passwordEncoder.encode("secret")) .authorizedGrantTypes("authorization_code") .scopes("app") .redirectUris("http://www.funtl.com"); &#125;&#125; （5）测试访问通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; 十二、对认证服务器的修改在开发资源服务器之前，我们需要对 创建认证服务器 章节的配置进行小量修改，需要修改的内容如下： 删除 spring-boot-starter-security 依赖，因为 spring-cloud-starter-oauth2 包含了该依赖 解决访问 /oauth/check_token 端点的 403 问题 优化 RBAC 模型数据，以便更好的演示资源服务器的概念 修改 spring-security-oauth2-server 项目的 pom.xml，删除 spring-boot-starter-security 依赖，因为 spring-cloud-starter-oauth2 包含了该依赖，完整 POM 如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-security-oauth2-server&lt;/artifactId&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencies&gt; &lt;!-- Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 数据库 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 排除 tomcat-jdbc 以使用 HikariCP --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.oauth2.OAuth2ServerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 1、服务器安全配置资源服务器需要访问 /oauth/check_token 端点来检查 access_token 的有效性，此时该端点是受保护的资源，当我们访问该端点时会遇到 403 问题，将该端点暴露出来即可，暴露端点的关键代码为： 12345@Overridepublic void configure(WebSecurity web) throws Exception &#123; // 将 check_token 暴露出去，否则资源服务器访问时报 403 错误 web.ignoring().antMatchers("/oauth/check_token");&#125; 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142package com.funtl.oauth2.server.config;import com.funtl.oauth2.server.config.service.UserDetailsServiceImpl;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.builders.WebSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Bean @Override public UserDetailsService userDetailsService() &#123; return new UserDetailsServiceImpl(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; // 使用自定义认证与授权 auth.userDetailsService(userDetailsService()); &#125; @Override public void configure(WebSecurity web) throws Exception &#123; // 将 check_token 暴露出去，否则资源服务器访问时报 403 错误 web.ignoring().antMatchers("/oauth/check_token"); &#125;&#125; 2、初始化 RBAC 相关表增加了内容管理权限的数据，以便于我演示资源服务器的用法，SQL 语句如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980CREATE TABLE `tb_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父权限', `name` varchar(64) NOT NULL COMMENT '权限名称', `enname` varchar(64) NOT NULL COMMENT '权限英文名称', `url` varchar(255) NOT NULL COMMENT '授权路径', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=49 DEFAULT CHARSET=utf8 COMMENT='权限表';insert into `tb_permission`(`id`,`parent_id`,`name`,`enname`,`url`,`description`,`created`,`updated`) values (37,0,'系统管理','System','/',NULL,'2019-04-04 23:22:54','2019-04-04 23:22:56'),(38,37,'用户管理','SystemUser','/users/',NULL,'2019-04-04 23:25:31','2019-04-04 23:25:33'),(39,38,'查看用户','SystemUserView','/users/view/**',NULL,'2019-04-04 15:30:30','2019-04-04 15:30:43'),(40,38,'新增用户','SystemUserInsert','/users/insert/**',NULL,'2019-04-04 15:30:31','2019-04-04 15:30:44'),(41,38,'编辑用户','SystemUserUpdate','/users/update/**',NULL,'2019-04-04 15:30:32','2019-04-04 15:30:45'),(42,38,'删除用户','SystemUserDelete','/users/delete/**',NULL,'2019-04-04 15:30:48','2019-04-04 15:30:45'),(44,37,'内容管理','SystemContent','/contents/',NULL,'2019-04-06 18:23:58','2019-04-06 18:24:00'),(45,44,'查看内容','SystemContentView','/contents/view/**',NULL,'2019-04-06 23:49:39','2019-04-06 23:49:41'),(46,44,'新增内容','SystemContentInsert','/contents/insert/**',NULL,'2019-04-06 23:51:00','2019-04-06 23:51:02'),(47,44,'编辑内容','SystemContentUpdate','/contents/update/**',NULL,'2019-04-06 23:51:04','2019-04-06 23:51:06'),(48,44,'删除内容','SystemContentDelete','/contents/delete/**',NULL,'2019-04-06 23:51:08','2019-04-06 23:51:10');CREATE TABLE `tb_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父角色', `name` varchar(64) NOT NULL COMMENT '角色名称', `enname` varchar(64) NOT NULL COMMENT '角色英文名称', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='角色表';insert into `tb_role`(`id`,`parent_id`,`name`,`enname`,`description`,`created`,`updated`) values (37,0,'超级管理员','admin',NULL,'2019-04-04 23:22:03','2019-04-04 23:22:05');CREATE TABLE `tb_role_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `role_id` bigint(20) NOT NULL COMMENT '角色 ID', `permission_id` bigint(20) NOT NULL COMMENT '权限 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=48 DEFAULT CHARSET=utf8 COMMENT='角色权限表';insert into `tb_role_permission`(`id`,`role_id`,`permission_id`) values (37,37,37),(38,37,38),(39,37,39),(40,37,40),(41,37,41),(42,37,42),(43,37,44),(44,37,45),(45,37,46),(46,37,47),(47,37,48);CREATE TABLE `tb_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `username` varchar(50) NOT NULL COMMENT '用户名', `password` varchar(64) NOT NULL COMMENT '密码，加密存储', `phone` varchar(20) DEFAULT NULL COMMENT '注册手机号', `email` varchar(50) DEFAULT NULL COMMENT '注册邮箱', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`) USING BTREE, UNIQUE KEY `phone` (`phone`) USING BTREE, UNIQUE KEY `email` (`email`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='用户表';insert into `tb_user`(`id`,`username`,`password`,`phone`,`email`,`created`,`updated`) values (37,'admin','$2a$10$9ZhDOBp.sRKat4l14ygu/.LscxrMUcDAfeVOEPiYwbcRkoB09gCmi','15888888888','lee.lusifer@gmail.com','2019-04-04 23:21:27','2019-04-04 23:21:29');CREATE TABLE `tb_user_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `user_id` bigint(20) NOT NULL COMMENT '用户 ID', `role_id` bigint(20) NOT NULL COMMENT '角色 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='用户角色表';insert into `tb_user_role`(`id`,`user_id`,`role_id`) values (37,37,37); 十三、创建资源服务器模块在 为什么需要 oAuth2 和 RBAC 基于角色的权限控制 章节，我们介绍过资源的概念，简单点说就是需要被访问的业务数据或是静态资源文件都可以被称作资源。 为了让大家更好的理解资源服务器的概念，我们单独创建一个名为 spring-security-oauth2-resource 资源服务器的项目，该项目的主要目的就是对数据表的 CRUD 操作，而这些操作就是对资源的操作了。 操作流程 初始化资源服务器数据库 POM 所需依赖同认证服务器 配置资源服务器 配置资源(Controller) 1、初始化资源服务器数据库12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849CREATE TABLE `tb_content` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `category_id` bigint(20) NOT NULL COMMENT '内容类目ID', `title` varchar(200) DEFAULT NULL COMMENT '内容标题', `sub_title` varchar(100) DEFAULT NULL COMMENT '子标题', `title_desc` varchar(500) DEFAULT NULL COMMENT '标题描述', `url` varchar(500) DEFAULT NULL COMMENT '链接', `pic` varchar(300) DEFAULT NULL COMMENT '图片绝对路径', `pic2` varchar(300) DEFAULT NULL COMMENT '图片2', `content` text COMMENT '内容', `created` datetime DEFAULT NULL, `updated` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `category_id` (`category_id`), KEY `updated` (`updated`)) ENGINE=InnoDB AUTO_INCREMENT=42 DEFAULT CHARSET=utf8;insert into `tb_content`(`id`,`category_id`,`title`,`sub_title`,`title_desc`,`url`,`pic`,`pic2`,`content`,`created`,`updated`) values (28,89,'标题','子标题','标题说明','http://www.jd.com',NULL,NULL,NULL,'2019-04-07 00:56:09','2019-04-07 00:56:11'),(29,89,'ad2','ad2','ad2','http://www.baidu.com',NULL,NULL,NULL,'2019-04-07 00:56:13','2019-04-07 00:56:15'),(30,89,'ad3','ad3','ad3','http://www.sina.com.cn',NULL,NULL,NULL,'2019-04-07 00:56:17','2019-04-07 00:56:19'),(31,89,'ad4','ad4','ad4','http://www.funtl.com',NULL,NULL,NULL,'2019-04-07 00:56:22','2019-04-07 00:56:25');CREATE TABLE `tb_content_category` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '类目ID', `parent_id` bigint(20) DEFAULT NULL COMMENT '父类目ID=0时，代表的是一级的类目', `name` varchar(50) DEFAULT NULL COMMENT '分类名称', `status` int(1) DEFAULT '1' COMMENT '状态。可选值:1(正常),2(删除)', `sort_order` int(4) DEFAULT NULL COMMENT '排列序号，表示同级类目的展现次序，如数值相等则按名称次序排列。取值范围:大于零的整数', `is_parent` tinyint(1) DEFAULT '1' COMMENT '该类目是否为父类目，1为true，0为false', `created` datetime DEFAULT NULL COMMENT '创建时间', `updated` datetime DEFAULT NULL COMMENT '创建时间', PRIMARY KEY (`id`), KEY `parent_id` (`parent_id`,`status`) USING BTREE, KEY `sort_order` (`sort_order`)) ENGINE=InnoDB AUTO_INCREMENT=98 DEFAULT CHARSET=utf8 COMMENT='内容分类';insert into `tb_content_category`(`id`,`parent_id`,`name`,`status`,`sort_order`,`is_parent`,`created`,`updated`) values (30,0,'LeeShop',1,1,1,'2015-04-03 16:51:38','2015-04-03 16:51:40'),(86,30,'首页',1,1,1,'2015-06-07 15:36:07','2015-06-07 15:36:07'),(87,30,'列表页面',1,1,1,'2015-06-07 15:36:16','2015-06-07 15:36:16'),(88,30,'详细页面',1,1,1,'2015-06-07 15:36:27','2015-06-07 15:36:27'),(89,86,'大广告',1,1,0,'2015-06-07 15:36:38','2015-06-07 15:36:38'),(90,86,'小广告',1,1,0,'2015-06-07 15:36:45','2015-06-07 15:36:45'),(91,86,'商城快报',1,1,0,'2015-06-07 15:36:55','2015-06-07 15:36:55'),(92,87,'边栏广告',1,1,0,'2015-06-07 15:37:07','2015-06-07 15:37:07'),(93,87,'页头广告',1,1,0,'2015-06-07 15:37:17','2015-06-07 15:37:17'),(94,87,'页脚广告',1,1,0,'2015-06-07 15:37:31','2015-06-07 15:37:31'),(95,88,'边栏广告',1,1,0,'2015-06-07 15:37:56','2015-06-07 15:37:56'),(96,86,'中广告',1,1,1,'2015-07-25 18:58:52','2015-07-25 18:58:52'),(97,96,'中广告1',1,1,0,'2015-07-25 18:59:43','2015-07-25 18:59:43'); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-security-oauth2-resource&lt;/artifactId&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencies&gt; &lt;!-- Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 数据库 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 排除 tomcat-jdbc 以使用 HikariCP --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.oauth2.OAuth2ResourceApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2、关键步骤由于代码较多，可以参考我 GitHub 上的源码，下面仅列出关键步骤及代码 （1）配置资源服务器创建一个类继承 ResourceServerConfigurerAdapter 并添加相关注解： @Configuration @EnableResourceServer：资源服务器 @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)：全局方法拦截 12345678910111213141516171819202122232425262728293031package com.funtl.oauth2.resource.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.http.SessionCreationPolicy;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableResourceServer;import org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfigurerAdapter;@Configuration@EnableResourceServer@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class ResourceServerConfiguration extends ResourceServerConfigurerAdapter &#123; @Override public void configure(HttpSecurity http) throws Exception &#123; http .exceptionHandling() .and() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() // 以下为配置所需保护的资源路径及权限，需要与认证服务器配置的授权部分对应 .antMatchers("/").hasAuthority("SystemContent") .antMatchers("/view/**").hasAuthority("SystemContentView") .antMatchers("/insert/**").hasAuthority("SystemContentInsert") .antMatchers("/update/**").hasAuthority("SystemContentUpdate") .antMatchers("/delete/**").hasAuthority("SystemContentDelete"); &#125;&#125; （2）Application1234567891011121314package com.funtl.oauth2;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import tk.mybatis.spring.annotation.MapperScan;@SpringBootApplication@MapperScan(basePackages = "com.funtl.oauth2.resource.mapper")public class OAuth2ResourceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OAuth2ResourceApplication.class, args); &#125;&#125; （3）application.yml1234567891011121314151617181920212223242526272829303132333435363738394041424344spring: application: name: oauth2-resource datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://192.168.141.128:3307/oauth2_resource?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 hikari: minimum-idle: 5 idle-timeout: 600000 maximum-pool-size: 10 auto-commit: true pool-name: MyHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1security: oauth2: client: client-id: client client-secret: secret access-token-uri: http://localhost:8080/oauth/token user-authorization-uri: http://localhost:8080/oauth/authorize resource: token-info-uri: http://localhost:8080/oauth/check_tokenserver: port: 8081 servlet: context-path: /contentsmybatis: type-aliases-package: com.funtl.oauth2.resource.domain mapper-locations: classpath:mapper/*.xmllogging: level: root: INFO org.springframework.web: INFO org.springframework.security: INFO org.springframework.security.oauth2: INFO 3、访问资源（1）访问获取授权码打开浏览器，输入地址： 1http://localhost:8080/oauth/authorize?client_id=client&amp;response_type=code 第一次访问会跳转到登录页面 验证成功后会询问用户是否授权客户端 选择授权后会跳转到我的博客，浏览器地址上还会包含一个授权码（code=1JuO6V），浏览器地址栏会显示如下地址： 1http://www.funtl.com/?code=1JuO6V 有了这个授权码就可以获取访问令牌了 （2）通过授权码向服务器申请令牌通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 1 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; （3）携带令牌访问资源服务器此处以获取全部资源为例，其它请求方式一样，可以参考我源码中的单元测试代码。可以使用以下方式请求： 使用 Headers 方式：需要在请求头增加 Authorization: Bearer yourAccessToken 直接请求带参数方式：http://localhost:8081/contents?access_token=yourAccessToken 使用 Headers 方式，通过 CURL 或是 Postman 请求 1curl --location --request GET "http://localhost:8081/contents" --header "Content-Type: application/json" --header "Authorization: Bearer yourAccessToken" OAuth（开放授权）是一个开放标准，允许用户让第三方应用访问该用户在某一网站上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和密码提供给第三方应用。OAuth协议为用户资源的授权提供了一个安全的、开放而又简易的标准。与以往的授权方式不同之处是OAuth的授权不会使第三方触及到用户的帐号信息（如用户名与密码），即第三方无需使用用户的用户名与密码就可以申请获得该用户资源的授权，因此OAuth是安全的。同时，任何第三方都可以使用OAuth认证服务，任何服务提供商都可以实现自身的OAuth认证服务，因而OAuth是开放的。Shiro是一个强大的，易用的Java安全框架。它被用作于认证，授权，加密，session管理。依赖于Shiro简单易懂的API，就可以快速的构建包括手机，大型web和商业应用。 十四、shiro 简单整合oauth2.0服务端使用了shiro，如果用户在授权过程中，密码连续错误5次将冻结账号，登录时有验证码,但是并没有使用,可以忽略。客户端就是纯粹的http请求。 1、服务端（1）初始化数据库12345678910111213141516171819202122DROP TABLE IF EXISTS `user_info`;CREATE TABLE `user_info` ( `uid` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(50) DEFAULT '' COMMENT '用户名', `password` varchar(256) DEFAULT NULL COMMENT '登录密码', `name` varchar(256) DEFAULT NULL COMMENT '用户真实姓名', `id_card_num` varchar(256) DEFAULT NULL COMMENT '用户身份证号', `state` char(1) DEFAULT '0' COMMENT '用户状态：0:正常状态,1：用户被锁定', PRIMARY KEY (`uid`), UNIQUE KEY `username` (`username`) USING BTREE, UNIQUE KEY `id_card_num` (`id_card_num`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8;DROP TABLE IF EXISTS `oauth2_client`;CREATE TABLE `oauth2_client` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `client_name` varchar(100) DEFAULT NULL COMMENT '客戶端名稱', `client_id` varchar(100) DEFAULT NULL COMMENT '客戶端ID', `client_secret` varchar(100) DEFAULT NULL COMMENT '客户端安全key', PRIMARY KEY (`id`), KEY `idx_oauth2_client_client_id` (`client_id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; 12345#插入用户信息表INSERT INTO user_info(uid,username,`password`,`name`,id_card_num) VALUES (null,'admin','123456','超哥','133333333333333333');#插入client表insert into oauth2_client values(1,'oauth-client','c1ebe466-1cdc-4bd3-ab69-77c3561b9dee','d8346ea2-6017-43ed-ad68-19c0f971738b');12345 （2）pom添加依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.oltu.oauth2&lt;/groupId&gt; &lt;artifactId&gt;org.apache.oltu.oauth2.authzserver&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.oltu.oauth2&lt;/groupId&gt; &lt;artifactId&gt;org.apache.oltu.oauth2.resourceserver&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt; （3）相关实体类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.springboot.test.shiro.oauthserver.entity;import java.io.Serializable;import java.util.HashSet;import java.util.Set;/** * @author: wangsaichao * @date: 2018/5/11 * @description: 用户信息 */public class User implements Serializable&#123; /** * 用户id(主键 自增) */ private Integer uid; /** * 用户名 */ private String username; /** * 登录密码 */ private String password; /** * 用户真实姓名 */ private String name; /** * 身份证号 */ private String id_card_num; /** * 用户状态：0:正常状态,1：用户被锁定 */ private String state;&#125;package com.springboot.test.shiro.oauthserver.entity;/** * @author: wangsaichao * @date: 2018/5/11 * @description: 客户端信息 */public class Client &#123; private String id; private String clientName; private String clientId; private String clientSecret;&#125; （5）相关service层1234567891011121314151617181920212223242526272829303132public interface AuthorizeService &#123; /** 根据客户端id 查询客户端是否存在 */ public boolean checkClientId(String clientId); /** 添加 auth code */ public void addAuthCode(String authCode, String username); /** 检查客户端安全Key是否正确 */ public boolean checkClientSecret(String clientSecret); /** 检查authCode是否可用 */ public boolean checkAuthCode(String authCode); /** 根据 authCode 获取用户名 */ public String getUsernameByAuthCode(String authCode); /** 添加accessToken */ public void addAccessToken(String accessToken, String username); /** access token 过期时间 */ public long getExpireIn(); /** 检查 accessToken 是否可用 */ public boolean checkAccessToken(String accessToken); /** 根据 accessToken 获取用户名 */ public String getUsernameByAccessToken(String accessToken);&#125;public interface ClientService &#123; /** 根据clientId查询Client信息 */ public Client findByClientId(String clientId); /** 根据clientSecret查询client信息 */ public Client findByClientSecret(String clientSecret);&#125;public interface UserService &#123; /** 根据用户名 查询用户 */ public User findByUserName(String username); /** 修改用户信息 */ public int updateUser(User user);&#125; 相关dao和数据库操作请参考代码代码中并没有有关资源的维护,只是授权服务。资源服务相关操作没有写。只拿插入数据库的那一条基础数据测试。 以下代码参考开涛博客：http://jinnianshilongnian.iteye.com/blog/2038646 （6）授权控制器AuthorizeController123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162package com.springboot.test.shiro.oauthserver.controller;import com.springboot.test.shiro.oauthserver.service.AuthorizeService;import com.springboot.test.shiro.oauthserver.service.ClientService;import org.apache.oltu.oauth2.as.issuer.MD5Generator;import org.apache.oltu.oauth2.as.issuer.OAuthIssuerImpl;import org.apache.oltu.oauth2.as.request.OAuthAuthzRequest;import org.apache.oltu.oauth2.as.response.OAuthASResponse;import org.apache.oltu.oauth2.common.OAuth;import org.apache.oltu.oauth2.common.error.OAuthError;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.apache.oltu.oauth2.common.message.OAuthResponse;import org.apache.oltu.oauth2.common.message.types.ResponseType;import org.apache.oltu.oauth2.common.utils.OAuthUtils;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.IncorrectCredentialsException;import org.apache.shiro.authc.LockedAccountException;import org.apache.shiro.authc.UnknownAccountException;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.subject.Subject;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.util.StringUtils;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.net.URI;import java.net.URISyntaxException;/** * @author: wangsaichao * @date: 2018/5/27 * @description: 授权控制器 * * 代码的作用: * 1、首先通过如 http://localhost:9090/oauth-server/authorize?response_type=code&amp;redirect_uri=http%3A%2F%2Flocalhost%3A9080%2Foauth-client%2FcallbackCode&amp;client_id=c1ebe466-1cdc-4bd3-ab69-77c3561b9dee * 2、该控制器首先检查clientId是否正确；如果错误将返回相应的错误信息 * 3、然后判断用户是否登录了，如果没有登录首先到登录页面登录 * 4、登录成功后生成相应的auth code即授权码，然后重定向到客户端地址，如http://localhost:9080/oauth-client/oauth2-login?code=52b1832f5dff68122f4f00ae995da0ed；在重定向到的地址中会带上code参数（授权码），接着客户端可以根据授权码去换取access token。 */@Controller@RequestMapping("/oauth-server")public class AuthorizeController &#123; @Autowired private AuthorizeService authorizeService; @Autowired private ClientService clientService; @RequestMapping("/authorize") public Object authorize(Model model, HttpServletRequest request) throws OAuthSystemException, URISyntaxException &#123; try &#123; //构建OAuth 授权请求 OAuthAuthzRequest oauthRequest = new OAuthAuthzRequest(request); //根据传入的clientId 判断 客户端是否存在 if (!authorizeService.checkClientId(oauthRequest.getClientId())) &#123; //生成错误信息,告知客户端不存在 OAuthResponse response = OAuthASResponse .errorResponse(HttpServletResponse.SC_BAD_REQUEST) .setError(OAuthError.TokenResponse.INVALID_CLIENT) .setErrorDescription("客户端验证失败，如错误的client_id/client_secret") .buildJSONMessage(); return new ResponseEntity( response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; // 判断用户是否登录 Subject subject = SecurityUtils.getSubject(); //如果用户没有登录,跳转到登录页面 if(!subject.isAuthenticated()) &#123; if(!login(subject, request)) &#123; //登录失败时跳转到登陆页面 model.addAttribute("client", clientService.findByClientId(oauthRequest.getClientId())); return "oauth2login"; &#125; &#125; String username = (String) subject.getPrincipal(); //生成授权码 String authorizationCode = null; String responseType = oauthRequest.getParam(OAuth.OAUTH_RESPONSE_TYPE); if(responseType.equals(ResponseType.CODE.toString())) &#123; OAuthIssuerImpl oAuthIssuer = new OAuthIssuerImpl(new MD5Generator()); authorizationCode = oAuthIssuer.authorizationCode(); //把授权码放到缓存中 authorizeService.addAuthCode(authorizationCode, username); &#125; // 进行OAuth响应构建 OAuthASResponse.OAuthAuthorizationResponseBuilder builder = OAuthASResponse.authorizationResponse(request, HttpServletResponse.SC_FOUND); // 设置授权码 builder.setCode(authorizationCode); // 根据客户端重定向地址 String redirectURI = oauthRequest.getParam(OAuth.OAUTH_REDIRECT_URI); // 构建响应 final OAuthResponse response = builder.location(redirectURI).buildQueryMessage(); // 根据OAuthResponse 返回 ResponseEntity响应 HttpHeaders headers = new HttpHeaders(); headers.setLocation(new URI(response.getLocationUri())); return new ResponseEntity(headers, HttpStatus.valueOf(response.getResponseStatus())); &#125; catch (OAuthProblemException e) &#123; // 出错处理 String redirectUri = e.getRedirectUri(); if(OAuthUtils.isEmpty(redirectUri)) &#123; // 告诉客户端没有传入redirectUri直接报错 return new ResponseEntity("告诉客户端没有传入redirectUri直接报错！", HttpStatus.NOT_FOUND); &#125; // 返回错误消息 final OAuthResponse response = OAuthASResponse.errorResponse(HttpServletResponse.SC_FOUND).error(e).location(redirectUri).buildQueryMessage(); HttpHeaders headers = new HttpHeaders(); headers.setLocation(new URI(response.getLocationUri())); return new ResponseEntity(headers, HttpStatus.valueOf(response.getResponseStatus())); &#125; &#125; private boolean login(Subject subject, HttpServletRequest request) &#123; if("get".equalsIgnoreCase(request.getMethod())) &#123; return false; &#125; String username = request.getParameter("username"); String password = request.getParameter("password"); if(StringUtils.isEmpty(username) || StringUtils.isEmpty(password)) &#123; return false; &#125; UsernamePasswordToken token = new UsernamePasswordToken(username, password); try &#123; subject.login(token); return true; &#125;catch(Exception e)&#123; if(e instanceof UnknownAccountException)&#123; request.setAttribute("msg","用户名或密码错误！"); &#125; if(e instanceof IncorrectCredentialsException)&#123; request.setAttribute("msg","用户名或密码错误！"); &#125; if(e instanceof LockedAccountException)&#123; request.setAttribute("msg","账号已被锁定,请联系管理员！"); &#125; return false; &#125; &#125;&#125; 1、首先通过如http://localhost:9090/oauth-server/authorize?response_type=code&amp;redirect_uri=http://localhost:9080/oauth-client/callbackCode&amp;client_id=c1ebe466-1cdc-4bd3-ab69-77c3561b9dee进入方法2、该控制器首先检查clientId是否正确；如果错误将返回相应的错误信息3、然后判断用户是否登录了，如果没有登录首先到登录页面登录4、登录成功后生成相应的auth code即授权码，然后重定向到客户端地址，如http://localhost:9080/oauth-client/oauth2-login？code=52b1832f5dff68122f4f00ae995da0ed；在重定向到的地址中会带上code参数（授权码），接着客户端可以根据授权码去换取access token。 （7）访问令牌控制器AccessTokenController123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596package com.springboot.test.shiro.oauthserver.controller;import com.springboot.test.shiro.oauthserver.service.AuthorizeService;import org.apache.oltu.oauth2.as.issuer.MD5Generator;import org.apache.oltu.oauth2.as.issuer.OAuthIssuer;import org.apache.oltu.oauth2.as.issuer.OAuthIssuerImpl;import org.apache.oltu.oauth2.as.request.OAuthTokenRequest;import org.apache.oltu.oauth2.as.response.OAuthASResponse;import org.apache.oltu.oauth2.common.OAuth;import org.apache.oltu.oauth2.common.error.OAuthError;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.apache.oltu.oauth2.common.message.OAuthResponse;import org.apache.oltu.oauth2.common.message.types.GrantType;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpEntity;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @author: wangsaichao * @date: 2018/5/27 * @description: 访问令牌控制器 * * 代码描述： * 1、首先通过如http://localhost:9090/accessToken，POST提交如下数据：client_id= c1ebe466-1cdc-4bd3-ab69-77c3561b9dee&amp; client_secret= d8346ea2-6017-43ed-ad68-19c0f971738b&amp;grant_type=authorization_code&amp;code=828beda907066d058584f37bcfd597b6&amp;redirect_uri=http://localhost:9080/oauth-client/oauth2-login访问。 * 2、该控制器会验证client_id、client_secret、auth code的正确性，如果错误会返回相应的错误； * 3、如果验证通过会生成并返回相应的访问令牌access token。 */@RestController@RequestMapping("/oauth-server")public class AccessTokenController &#123; @Autowired private AuthorizeService authorizeService; @RequestMapping("/accessToken") public HttpEntity token(HttpServletRequest request) throws OAuthSystemException &#123; try &#123; // 构建Oauth请求 OAuthTokenRequest oAuthTokenRequest = new OAuthTokenRequest(request); //检查提交的客户端id是否正确 if(!authorizeService.checkClientId(oAuthTokenRequest.getClientId())) &#123; OAuthResponse response = OAuthASResponse.errorResponse(HttpServletResponse.SC_BAD_REQUEST) .setError(OAuthError.TokenResponse.INVALID_CLIENT) .setErrorDescription("客户端验证失败，client_id错误！") .buildJSONMessage(); return new ResponseEntity(response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; // 检查客户端安全Key是否正确 if(!authorizeService.checkClientSecret(oAuthTokenRequest.getClientSecret()))&#123; OAuthResponse response = OAuthASResponse.errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setError(OAuthError.TokenResponse.UNAUTHORIZED_CLIENT) .setErrorDescription("客户端验证失败，client_secret错误！") .buildJSONMessage(); return new ResponseEntity(response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; String authCode = oAuthTokenRequest.getParam(OAuth.OAUTH_CODE); // 检查验证类型，此处只检查AUTHORIZATION类型，其他的还有PASSWORD或者REFRESH_TOKEN if(oAuthTokenRequest.getParam(OAuth.OAUTH_GRANT_TYPE).equals(GrantType.AUTHORIZATION_CODE.toString()))&#123; if(!authorizeService.checkAuthCode(authCode))&#123; OAuthResponse response = OAuthASResponse.errorResponse(HttpServletResponse.SC_BAD_REQUEST) .setError(OAuthError.TokenResponse.INVALID_GRANT) .setErrorDescription("auth_code错误！") .buildJSONMessage(); return new ResponseEntity(response.getBody(),HttpStatus.valueOf(response.getResponseStatus())); &#125; &#125; //生成Access Token OAuthIssuer issuer = new OAuthIssuerImpl(new MD5Generator()); final String accessToken = issuer.accessToken(); authorizeService.addAccessToken(accessToken, authorizeService.getUsernameByAuthCode(authCode)); // 生成OAuth响应 OAuthResponse response = OAuthASResponse.tokenResponse(HttpServletResponse.SC_OK) .setAccessToken(accessToken).setExpiresIn(String.valueOf(authorizeService.getExpireIn())) .buildJSONMessage(); return new ResponseEntity(response.getBody(),HttpStatus.valueOf(response.getResponseStatus())); &#125; catch(OAuthProblemException e) &#123; OAuthResponse res = OAuthASResponse.errorResponse(HttpServletResponse.SC_BAD_REQUEST).error(e).buildBodyMessage(); return new ResponseEntity(res.getBody(),HttpStatus.valueOf(res.getResponseStatus())); &#125; &#125;&#125; 1、首先通过如http://localhost:9090/accessToken，POST提交如下数据：client_id= c1ebe466-1cdc-4bd3-ab69-77c3561b9dee&amp;client_secret=d8346ea2-6017-43ed-ad68-19c0f971738b&amp;grant_type=authorization_code&amp;code=828beda907066d058584f37bcfd597b6&amp;redirect_uri=http://localhost:9080/oauth-client/oauth2-login访问。2、该控制器会验证client_id、client_secret、auth code的正确性，如果错误会返回相应的错误；3、如果验证通过会生成并返回相应的访问令牌access token。 （8）资源控制器UserInfoController12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package com.springboot.test.shiro.oauthserver.controller;import com.springboot.test.shiro.oauthserver.service.AuthorizeService;import org.apache.oltu.oauth2.common.OAuth;import org.apache.oltu.oauth2.common.error.OAuthError;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.apache.oltu.oauth2.common.message.OAuthResponse;import org.apache.oltu.oauth2.common.message.types.ParameterStyle;import org.apache.oltu.oauth2.common.utils.OAuthUtils;import org.apache.oltu.oauth2.rs.request.OAuthAccessResourceRequest;import org.apache.oltu.oauth2.rs.response.OAuthRSResponse;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @author: wangsaichao * @date: 2018/5/27 * @description: * 1、首先通过如http://localhost:9090/oauth-server/userInfo?access_token=828beda907066d058584f37bcfd597b6进行访问； * 2、该控制器会验证access token的有效性；如果无效了将返回相应的错误，客户端再重新进行授权； * 3、如果有效，则返回当前登录用户的用户名。 */@Controller@RequestMapping("/oauth-server")public class UserInfoController &#123; @Autowired private AuthorizeService authorizeService; @RequestMapping("/userInfo") public HttpEntity userInfo(HttpServletRequest request) throws OAuthSystemException &#123; try &#123; //构建OAuth资源请求 OAuthAccessResourceRequest oauthRequest = new OAuthAccessResourceRequest(request, ParameterStyle.QUERY); //获取Access Token String accessToken = oauthRequest.getAccessToken(); //验证Access Token if (!authorizeService.checkAccessToken(accessToken)) &#123; // 如果不存在/过期了，返回未验证错误，需重新验证 OAuthResponse oauthResponse = OAuthRSResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setRealm("oauth-server") .setError(OAuthError.ResourceResponse.INVALID_TOKEN) .buildHeaderMessage(); HttpHeaders headers = new HttpHeaders(); headers.add(OAuth.HeaderType.WWW_AUTHENTICATE, oauthResponse.getHeader(OAuth.HeaderType.WWW_AUTHENTICATE)); return new ResponseEntity(headers, HttpStatus.UNAUTHORIZED); &#125; //返回用户名 String username = authorizeService.getUsernameByAccessToken(accessToken); return new ResponseEntity(username, HttpStatus.OK); &#125; catch (OAuthProblemException e) &#123; //检查是否设置了错误码 String errorCode = e.getError(); if (OAuthUtils.isEmpty(errorCode)) &#123; OAuthResponse oauthResponse = OAuthRSResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setRealm("fxb") .buildHeaderMessage(); HttpHeaders headers = new HttpHeaders(); headers.add(OAuth.HeaderType.WWW_AUTHENTICATE, oauthResponse.getHeader(OAuth.HeaderType.WWW_AUTHENTICATE)); return new ResponseEntity(headers, HttpStatus.UNAUTHORIZED); &#125; OAuthResponse oauthResponse = OAuthRSResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setRealm("oauth-server") .setError(e.getError()) .setErrorDescription(e.getDescription()) .setErrorUri(e.getUri()) .buildHeaderMessage(); HttpHeaders headers = new HttpHeaders(); headers.add(OAuth.HeaderType.WWW_AUTHENTICATE, oauthResponse.getHeader(OAuth.HeaderType.WWW_AUTHENTICATE)); return new ResponseEntity(HttpStatus.BAD_REQUEST); &#125; &#125;&#125; 1、首先通过如http://localhost:9090/oauth-server/userInfo?access_token=828beda907066d058584f37bcfd597b6进行访问；2、该控制器会验证access token的有效性；如果无效了将返回相应的错误，客户端再重新进行授权；3、如果有效，则返回当前登录用户的用户名。 对于授权服务和资源服务的实现可以参考新浪微博开发平台的实现：http://open.weibo.com/wiki/授权机制说明http://open.weibo.com/wiki/微博API 2、客户端我是将客户端一系列流程直接跑完的，就是内部redirect没有使用shiro控制权限，只是为了理解这个流程 （1）pom添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.oltu.oauth2&lt;/groupId&gt; &lt;artifactId&gt;org.apache.oltu.oauth2.client&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt; （2）AuthCodeController获取code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.springboot.test.shiro.oauthclient.controller;import org.apache.oltu.oauth2.client.request.OAuthClientRequest;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;/** * @author: wangsaichao * @date: 2018/5/29 * @description: * 1、拼接url然后访问，获取code * 2、服务端检查成功,然后会回调到 另一个接口 /oauth-client/callbackCode */@Controller@RequestMapping("/oauth-client")public class AuthCodeController &#123; @Value("$&#123;clientId&#125;") private String clientId; @Value("$&#123;authorizeUrl&#125;") private String authorizeUrl; @Value("$&#123;redirectUrl&#125;") private String redirectUrl; @Value("$&#123;response_type&#125;") private String response_type; @RequestMapping("/getCode") public String getCode() throws OAuthProblemException &#123; String requestUrl = null; try &#123; //配置请求参数，构建oauthd的请求。设置请求服务地址（authorizeUrl）、clientId、response_type、redirectUrl OAuthClientRequest accessTokenRequest = OAuthClientRequest.authorizationLocation(authorizeUrl) .setResponseType(response_type) .setClientId(clientId) .setRedirectURI(redirectUrl) .buildQueryMessage(); requestUrl = accessTokenRequest.getLocationUri(); &#125; catch (OAuthSystemException e) &#123; e.printStackTrace(); &#125; System.out.println("==&gt; 客户端重定向到服务端获取auth_code： "+requestUrl); return "redirect:"+requestUrl ; &#125;&#125; 1、拼接url然后重定向到服务端，获取code2、服务端检查成功,然后会回调到 另一个接口 /oauth-client/callbackCode （3）AccessTokenController服务端回调1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.springboot.test.shiro.oauthclient.controller;import org.apache.oltu.oauth2.client.OAuthClient;import org.apache.oltu.oauth2.client.URLConnectionClient;import org.apache.oltu.oauth2.client.request.OAuthClientRequest;import org.apache.oltu.oauth2.client.response.OAuthAccessTokenResponse;import org.apache.oltu.oauth2.common.OAuth;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.apache.oltu.oauth2.common.message.types.GrantType;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;/** * @author: wangsaichao * @date: 2018/5/29 * @description: 服务端回调方法 * 1.服务端回调,传回code值 * 2.根据code值，调用服务端服务,根据code获取access_token * 3.拿到access_token重定向到客户端的服务 /oauth-client/getUserInfo 在该服务中 再调用服务端获取用户信息 */@Controller@RequestMapping("/oauth-client")public class AccessTokenController &#123; @Value("$&#123;clientId&#125;") private String clientId; @Value("$&#123;clientSecret&#125;") private String clientSecret; @Value("$&#123;accessTokenUrl&#125;") private String accessTokenUrl; @Value("$&#123;redirectUrl&#125;") private String redirectUrl; @Value("$&#123;response_type&#125;") private String response_type; //接受客户端返回的code，提交申请access token的请求 @RequestMapping("/callbackCode") public Object toLogin(HttpServletRequest request)throws OAuthProblemException &#123; String code = request.getParameter("code"); System.out.println("==&gt; 服务端回调，获取的code："+code); OAuthClient oAuthClient =new OAuthClient(new URLConnectionClient()); try &#123; OAuthClientRequest accessTokenRequest = OAuthClientRequest .tokenLocation(accessTokenUrl) .setGrantType(GrantType.AUTHORIZATION_CODE) .setClientId(clientId) .setClientSecret(clientSecret) .setCode(code) .setRedirectURI(redirectUrl) .buildQueryMessage(); //去服务端请求access token，并返回响应 OAuthAccessTokenResponse oAuthResponse =oAuthClient.accessToken(accessTokenRequest, OAuth.HttpMethod.POST); //获取服务端返回过来的access token String accessToken = oAuthResponse.getAccessToken(); //查看access token是否过期 Long expiresIn =oAuthResponse.getExpiresIn(); System.out.println("==&gt; 客户端根据 code值 "+code +" 到服务端获取的access_token为："+accessToken+" 过期时间为："+expiresIn); System.out.println("==&gt; 拿到access_token然后重定向到 客户端 /oauth-client/getUserInfo服务,传过去accessToken"); return"redirect:/oauth-client/getUserInfo?accessToken="+accessToken; &#125; catch (OAuthSystemException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 1、服务端回调,传回code值2、根据code值，调用服务端服务,根据code获取access_token3、拿到access_token重定向到客户端的服务 /oauth-client/getUserInfo 在该服务中 再调用服务端获取用户信息 （4）GetUserInfoController客户端根据access_token获取用户信息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.springboot.test.shiro.oauthclient.controller;import org.apache.oltu.oauth2.client.OAuthClient;import org.apache.oltu.oauth2.client.URLConnectionClient;import org.apache.oltu.oauth2.client.request.OAuthBearerClientRequest;import org.apache.oltu.oauth2.client.request.OAuthClientRequest;import org.apache.oltu.oauth2.client.response.OAuthResourceResponse;import org.apache.oltu.oauth2.common.OAuth;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;/** * @author: wangsaichao * @date: 2018/5/29 * @description: 通过access_token获取用户信息 */@Controller@RequestMapping("/oauth-client")public class GetUserInfoController &#123; @Value("$&#123;userInfoUrl&#125;") private String userInfoUrl; //接受服务端传回来的access token，由此token去请求服务端的资源（用户信息等） @RequestMapping("/getUserInfo") @ResponseBody public String accessToken(String accessToken) &#123; OAuthClient oAuthClient =new OAuthClient(new URLConnectionClient()); try &#123; OAuthClientRequest userInfoRequest =new OAuthBearerClientRequest(userInfoUrl) .setAccessToken(accessToken).buildQueryMessage(); OAuthResourceResponse resourceResponse =oAuthClient.resource(userInfoRequest, OAuth.HttpMethod.GET, OAuthResourceResponse.class); String body = resourceResponse.getBody(); System.out.println("==&gt; 客户端通过accessToken："+accessToken +" 从服务端获取用户信息为："+body); return body; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 3、测试1、首先访问客户端http://localhost:9080/oauth-client/getCode 会重定向到服务端让你输入账号密码授权2、输入用户名进行登录并授权；3、如果登录成功，服务端会重定向到客户端，即之前客户端提供的地址http://localhost:9080/oauth-client/callbackCode?code=98872aeb79889bc27be46da76a204aa3，并带着auth code过去；4、方法内部拿到code之后 会调用服务端获取access_token 然后重定向到客户端的获取用户信息方法5、获取用户信息方法内调用服务端 并传过去 access_token 获取用户名,然后展示到页面 控制台打印日志 到此流程结束,此处的客户端 服务端 比较简单,还有很多没有做 比如根据scope 获取不同的级别的用户信息,请求的验签等等。]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes使用教程]]></title>
    <url>%2Fblog%2F2019%2F07%2F13%2F%E4%BA%91%E8%AE%A1%E7%AE%97%2Fk8s%2F</url>
    <content type="text"><![CDATA[Kubernetes 是 Google 2014 年创建管理的，是 Google 10 多年大规模容器管理技术 Borg 的开源版本。Kubernetes 是容器集群管理系统，是一个开源的平台，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。使用 Kubernetes 我们可以： 快速部署应用 快速扩展应用 无缝对接新的应用功能 节省资源，优化硬件资源的使用 Kubernetes 的目标是促进完善组件和工具的生态系统，以减轻应用程序在公有云或私有云中运行的负担。 特点 可移植： 支持公有云，私有云，混合云，多重云（多个公共云） 可扩展： 模块化，插件化，可挂载，可组合 自动化： 自动部署，自动重启，自动复制，自动伸缩/扩展 从传统到容器化部署 传统的部署方式传统的应用部署方式是通过插件或脚本来安装应用。这样做的缺点是应用的运行、配置、管理、所有生存周期将与当前操作系统绑定，这样做并不利于应用的升级更新/回滚等操作，当然也可以通过创建虚机的方式来实现某些功能，但是虚拟机非常重，并不利于可移植性。 容器化部署的优势 快速创建/部署应用： 与虚拟机相比，容器镜像的创建更加容易。 持续开发、集成和部署： 提供可靠且频繁的容器镜像构建/部署，并使用快速和简单的回滚(由于镜像不可变性)。 开发和运行相分离： 在 build 或者 release 阶段创建容器镜像，使得应用和基础设施解耦。 开发，测试和生产环境一致性： 在本地或外网（生产环境）运行的一致性。 云平台或其他操作系统： 可以在 Ubuntu、RHEL、CoreOS、on-prem、Google Container Engine 或其它任何环境中运行。 分布式，弹性，微服务化： 应用程序分为更小的、独立的部件，可以动态部署和管理。 资源隔离 资源利用更高效 为什么需要 Kubernetes可以在物理或虚拟机的 Kubernetes 集群上运行容器化应用，Kubernetes 能提供一个以 “容器为中心的基础架构”，满足在生产环境中运行应用的一些常见需求，如： 多个进程协同工作 存储系统挂载 应用健康检查 应用实例的复制 自动伸缩/扩展 注册与发现 负载均衡 滚动更新 资源监控 日志访问 调试应用程序 提供认证和授权 Kubernetes 安装前的准备概述本次安装采用 Ubuntu Server X64 18.04 LTS 版本安装 kubernetes 集群环境，集群节点为 1 主 2 从模式，此次对虚拟机会有些基本要求，如下： OS：Ubuntu Server X64 18.04 LTS（16.04 版本步骤相同，再之前则不同） CPU：最低要求，1 CPU 2 核 内存：最低要求，2GB 磁盘：最低要求，20GB 创建三台虚拟机，分别命名如下： Ubuntu Server 18.04 X64 Kubernetes Master Ubuntu Server 18.04 X64 Kubernetes Slave1 Ubuntu Server 18.04 X64 Kubernetes Slave2 对虚拟机系统的配置： 关闭交换空间：sudo swapoff -a 避免开机启动交换空间：注释 /etc/fstab 中的 swap 关闭防火墙：ufw disable 使用 APT 安装 Docker安装123456789101112# 更新软件源sudo apt-get update# 安装所需依赖sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common# 安装 GPG 证书curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# 新增软件源信息sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"# 再次更新软件源sudo apt-get -y update# 安装 Docker CE 版sudo apt-get -y install docker-ce 验证12345678910111213141516171819docker versionClient: Version: 18.09.6 API version: 1.39 Go version: go1.10.8 Git commit: 481bc77 Built: Sat May 4 02:35:57 2019 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.6 API version: 1.39 (minimum version 1.12) Go version: go1.10.8 Git commit: 481bc77 Built: Sat May 4 01:59:36 2019 OS/Arch: linux/amd64 Experimental: false 配置加速器对于使用 systemd 的系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件） 12345&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125; 注意，一定要保证该文件符合 JSON 规范，否则 Docker 将不能启动。 验证加速器是否配置成功： 1234567sudo systemctl restart dockerdocker info...# 出现如下语句即表示配置成功Registry Mirrors: https://registry.docker-cn.com/... 修改主机名在同一局域网中主机名不应该相同，所以我们需要做修改，下列操作步骤为修改 18.04 版本的 Hostname，如果是 16.04 或以下版本则直接修改 /etc/hostname 里的名称即可 查看当前 Hostname 123456789101112# 查看当前主机名hostnamectl# 显示如下内容 Static hostname: ubuntu Icon name: computer-vm Chassis: vm Machine ID: 33011e0a95094672b99a198eff07f652 Boot ID: dc856039f0d24164a9f8a50c506be96d Virtualization: vmware Operating System: Ubuntu 18.04.2 LTS Kernel: Linux 4.15.0-48-generic Architecture: x86-64 修改 Hostname 12# 使用 hostnamectl 命令修改，其中 kubernetes-master 为新的主机名hostnamectl set-hostname kubernetes-master 修改 cloud.cfg 如果 cloud-init package 安装了，需要修改 cloud.cfg 文件。该软件包通常缺省安装用于处理 cloud 12345# 如果有该文件vi /etc/cloud/cloud.cfg# 该配置默认为 false，修改为 true 即可preserve_hostname: true 验证 12345678910root@kubernetes-master:~# hostnamectl Static hostname: kubernetes-master Icon name: computer-vm Chassis: vm Machine ID: 33011e0a95094672b99a198eff07f652 Boot ID: 8c0fd75d08c644abaad3df565e6e4cbd Virtualization: vmware Operating System: Ubuntu 18.04.2 LTS Kernel: Linux 4.15.0-48-generic Architecture: x86-64 安装 kubeadm概述kubeadm 是 kubernetes 的集群安装工具，能够快速安装 kubernetes 集群。 配置软件源12345678# 安装系统工具apt-get update &amp;&amp; apt-get install -y apt-transport-https# 安装 GPG 证书curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -# 写入软件源；注意：我们用系统代号为 bionic，但目前阿里云不支持，所以沿用 16.04 的 xenialcat &lt;&lt; EOF &gt;/etc/apt/sources.list.d/kubernetes.list&gt; deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main&gt; EOF 安装 kubeadm，kubelet，kubectl12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 安装apt-get update apt-get install -y kubelet kubeadm kubectl# 安装过程如下，注意 kubeadm 的版本号Reading package lists... DoneBuilding dependency tree Reading state information... DoneThe following additional packages will be installed: conntrack cri-tools kubernetes-cni socatThe following NEW packages will be installed: conntrack cri-tools kubeadm kubectl kubelet kubernetes-cni socat0 upgraded, 7 newly installed, 0 to remove and 96 not upgraded.Need to get 50.6 MB of archives.After this operation, 290 MB of additional disk space will be used.Get:1 http://mirrors.aliyun.com/ubuntu bionic/main amd64 conntrack amd64 1:1.4.4+snapshot20161117-6ubuntu2 [30.6 kB]Get:2 http://mirrors.aliyun.com/ubuntu bionic/main amd64 socat amd64 1.7.3.2-2ubuntu2 [342 kB]Get:3 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 cri-tools amd64 1.12.0-00 [5,343 kB]Get:4 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubernetes-cni amd64 0.7.5-00 [6,473 kB]Get:5 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubelet amd64 1.14.1-00 [21.5 MB]Get:6 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubectl amd64 1.14.1-00 [8,806 kB]Get:7 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubeadm amd64 1.14.1-00 [8,150 kB]Fetched 50.6 MB in 5s (9,912 kB/s) Selecting previously unselected package conntrack.(Reading database ... 67205 files and directories currently installed.)Preparing to unpack .../0-conntrack_1%3a1.4.4+snapshot20161117-6ubuntu2_amd64.deb ...Unpacking conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ...Selecting previously unselected package cri-tools.Preparing to unpack .../1-cri-tools_1.12.0-00_amd64.deb ...Unpacking cri-tools (1.12.0-00) ...Selecting previously unselected package kubernetes-cni.Preparing to unpack .../2-kubernetes-cni_0.7.5-00_amd64.deb ...Unpacking kubernetes-cni (0.7.5-00) ...Selecting previously unselected package socat.Preparing to unpack .../3-socat_1.7.3.2-2ubuntu2_amd64.deb ...Unpacking socat (1.7.3.2-2ubuntu2) ...Selecting previously unselected package kubelet.Preparing to unpack .../4-kubelet_1.14.1-00_amd64.deb ...Unpacking kubelet (1.14.1-00) ...Selecting previously unselected package kubectl.Preparing to unpack .../5-kubectl_1.14.1-00_amd64.deb ...Unpacking kubectl (1.14.1-00) ...Selecting previously unselected package kubeadm.Preparing to unpack .../6-kubeadm_1.14.1-00_amd64.deb ...Unpacking kubeadm (1.14.1-00) ...Setting up conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ...Setting up kubernetes-cni (0.7.5-00) ...Setting up cri-tools (1.12.0-00) ...Setting up socat (1.7.3.2-2ubuntu2) ...Setting up kubelet (1.14.1-00) ...Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /lib/systemd/system/kubelet.service.Setting up kubectl (1.14.1-00) ...Processing triggers for man-db (2.8.3-2ubuntu0.1) ...# 注意这里的版本号，我们使用的是 kubernetes v1.14.1Setting up kubeadm (1.14.1-00) ...# 设置 kubelet 自启动，并启动 kubeletsystemctl enable kubelet &amp;&amp; systemctl start kubelet kubeadm：用于初始化 Kubernetes 集群 kubectl：Kubernetes 的命令行工具，主要作用是部署和管理应用，查看各种资源，创建，删除和更新组件 kubelet：主要负责启动 Pod 和容器 配置 kubeadm安装 kubernetes 主要是安装它的各个镜像，而 kubeadm 已经为我们集成好了运行 kubernetes 所需的基本镜像。但由于国内的网络原因，在搭建环境时，无法拉取到这些镜像。此时我们只需要修改为阿里云提供的镜像服务即可解决该问题。 创建并修改配置12# 导出配置文件kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 修改配置为如下内容apiVersion: kubeadm.k8s.io/v1beta1bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: # 修改为主节点 IP advertiseAddress: 192.168.141.130 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: kubernetes-master taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta1certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrolPlaneEndpoint: ""controllerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcd# 国内不能访问 Google，修改为阿里云imageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfiguration# 修改版本号kubernetesVersion: v1.14.1networking: dnsDomain: cluster.local # 配置成 Calico 的默认网段 podSubnet: "192.168.0.0/16" serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;---# 开启 IPVS 模式apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs 查看和拉取镜像1234# 查看所需镜像列表kubeadm config images list --config kubeadm.yml# 拉取镜像kubeadm config images pull --config kubeadm.yml 使用 kubeadm 搭建 kubernetes 集群安装 kubernetes 主节点执行以下命令初始化主节点，该命令指定了初始化时需要使用的配置文件，其中添加 --experimental-upload-certs 参数可以在后续执行加入节点时自动分发证书文件。追加的 tee kubeadm-init.log 用以输出日志。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172kubeadm init --config=kubeadm.yml --experimental-upload-certs | tee kubeadm-init.log# 安装成功则会有如下输出[init] Using Kubernetes version: v1.14.1[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Activating the kubelet service[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "ca" certificate and key[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [kubernetes-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.141.130][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "front-proxy-ca" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "etcd/ca" certificate and key[certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [kubernetes-master localhost] and IPs [192.168.141.130 127.0.0.1 ::1][certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [kubernetes-master localhost] and IPs [192.168.141.130 127.0.0.1 ::1][certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "apiserver-etcd-client" certificate and key[certs] Generating "sa" key and public key[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[kubeconfig] Writing "admin.conf" kubeconfig file[kubeconfig] Writing "kubelet.conf" kubeconfig file[kubeconfig] Writing "controller-manager.conf" kubeconfig file[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s[apiclient] All control plane components are healthy after 20.003326 seconds[upload-config] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.14" in namespace kube-system with the configuration for the kubelets in the cluster[upload-certs] Storing the certificates in ConfigMap "kubeadm-certs" in the "kube-system" Namespace[upload-certs] Using certificate key:2cd5b86c4905c54d68cc7dfecc2bf87195e9d5d90b4fff9832d9b22fc5e73f96[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: abcdef.0123456789abcdef[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] creating the "cluster-info" ConfigMap in the "kube-public" namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:# 后面子节点加入需要如下命令kubeadm join 192.168.141.130:6443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:cab7c86212535adde6b8d1c7415e81847715cfc8629bb1d270b601744d662515 注意：如果安装 kubernetes 版本和下载的镜像版本不统一则会出现 timed out waiting for the condition 错误。中途失败或是想修改配置可以使用 kubeadm reset 命令重置配置，再做初始化操作即可。 配置 kubectl12345mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/config# 非 ROOT 用户执行chown $(id -u):$(id -g) $HOME/.kube/config 验证是否成功12345kubectl get node# 能够打印出节点信息即表示成功NAME STATUS ROLES AGE VERSIONkubernetes-master NotReady master 8m40s v1.14.1 至此主节点配置完成 kubeadm init 的执行过程 init：指定版本进行初始化操作 preflight：初始化前的检查和下载所需要的 Docker 镜像文件 kubelet-start：生成 kubelet 的配置文件 var/lib/kubelet/config.yaml，没有这个文件 kubelet 无法启动，所以初始化之前的 kubelet 实际上启动不会成功 certificates：生成 Kubernetes 使用的证书，存放在 /etc/kubernetes/pki 目录中 kubeconfig：生成 KubeConfig 文件，存放在 /etc/kubernetes 目录中，组件之间通信需要使用对应文件 control-plane：使用 /etc/kubernetes/manifest 目录下的 YAML 文件，安装 Master 组件 etcd：使用 /etc/kubernetes/manifest/etcd.yaml 安装 Etcd 服务 wait-control-plane：等待 control-plan 部署的 Master 组件启动 apiclient：检查 Master 组件服务状态。 uploadconfig：更新配置 kubelet：使用 configMap 配置 kubelet patchnode：更新 CNI 信息到 Node 上，通过注释的方式记录 mark-control-plane：为当前节点打标签，打了角色 Master，和不可调度标签，这样默认就不会使用 Master 节点来运行 Pod bootstrap-token：生成 token 记录下来，后边使用 kubeadm join 往集群中添加节点时会用到 addons：安装附加组件 CoreDNS 和 kube-proxy 使用 kubeadm 配置 slave 节点概述将 slave 节点加入到集群中很简单，只需要在 slave 服务器上安装 kubeadm，kubectl，kubelet 三个工具，然后使用 kubeadm join 命令加入即可。准备工作如下： 修改主机名 配置软件源 安装三个工具 由于之前章节已经说明了操作步骤，此处不再赘述。 将 slave 加入到集群123456789101112131415161718kubeadm join 192.168.141.130:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:cab7c86212535adde6b8d1c7415e81847715cfc8629bb1d270b601744d662515# 安装成功将看到如下信息[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.14" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Activating the kubelet service[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 说明： token 可以通过安装 master 时的日志查看 token 信息 可以通过 kubeadm token list 命令打印出 token 信息 如果 token 过期，可以使用 kubeadm token create 命令创建新的 token discovery-token-ca-cert-hash 可以通过安装 master 时的日志查看 sha256 信息 可以通过 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39;命令查看 sha256 信息 以上方式感谢群友 停 驻 提供。 验证是否成功回到 master 服务器 123456kubectl get nodes# 可以看到 slave 成功加入 masterNAME STATUS ROLES AGE VERSIONkubernetes-master NotReady master 9h v1.14.1kubernetes-slave1 NotReady &lt;none&gt; 22s v1.14.1 如果 slave 节点加入 master 时配置有问题可以在 slave 节点上使用 kubeadm reset 重置配置再使用 kubeadm join 命令重新加入即可。希望在 master 节点删除 node ，可以使用 kubeadm delete nodes &lt;NAME&gt; 删除。 查看 pod 状态1234567891011kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-8686dcc4fd-gwrmb 0/1 Pending 0 9h &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;coredns-8686dcc4fd-j6gfk 0/1 Pending 0 9h &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;etcd-kubernetes-master 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt;kube-apiserver-kubernetes-master 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt;kube-controller-manager-kubernetes-master 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt;kube-proxy-496dr 1/1 Running 0 17m 192.168.141.131 kubernetes-slave1 &lt;none&gt; &lt;none&gt;kube-proxy-rsnb6 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt;kube-scheduler-kubernetes-master 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt; 由此可以看出 coredns 尚未运行，此时我们还需要安装网络插件。 配置网络容器网络是容器选择连接到其他容器、主机和外部网络的机制。容器的 runtime 提供了各种网络模式，每种模式都会产生不同的体验。例如，Docker 默认情况下可以为容器配置以下网络： none： 将容器添加到一个容器专门的网络堆栈中，没有对外连接。 host： 将容器添加到主机的网络堆栈中，没有隔离。 default bridge： 默认网络模式。每个容器可以通过 IP 地址相互连接。 自定义网桥： 用户定义的网桥，具有更多的灵活性、隔离性和其他便利功能。 什么是 CNICNI(Container Network Interface) 是一个标准的，通用的接口。在容器平台，Docker，Kubernetes，Mesos 容器网络解决方案 flannel，calico，weave。只要提供一个标准的接口，就能为同样满足该协议的所有容器平台提供网络功能，而 CNI 正是这样的一个标准接口协议。 Kubernetes 中的 CNI 插件CNI 的初衷是创建一个框架，用于在配置或销毁容器时动态配置适当的网络配置和资源。插件负责为接口配置和管理 IP 地址，并且通常提供与 IP 管理、每个容器的 IP 分配、以及多主机连接相关的功能。容器运行时会调用网络插件，从而在容器启动时分配 IP 地址并配置网络，并在删除容器时再次调用它以清理这些资源。 运行时或协调器决定了容器应该加入哪个网络以及它需要调用哪个插件。然后，插件会将接口添加到容器网络命名空间中，作为一个 veth 对的一侧。接着，它会在主机上进行更改，包括将 veth 的其他部分连接到网桥。再之后，它会通过调用单独的 IPAM（IP地址管理）插件来分配 IP 地址并设置路由。 在 Kubernetes 中，kubelet 可以在适当的时间调用它找到的插件，为通过 kubelet 启动的 pod进行自动的网络配置。 Kubernetes 中可选的 CNI 插件如下： Flannel Calico Canal Weave 什么是 CalicoCalico 为容器和虚拟机提供了安全的网络连接解决方案，并经过了大规模生产验证（在公有云和跨数千个集群节点中），可与 Kubernetes，OpenShift，Docker，Mesos，DC / OS 和 OpenStack 集成。 Calico 还提供网络安全规则的动态实施。使用 Calico 的简单策略语言，您可以实现对容器，虚拟机工作负载和裸机主机端点之间通信的细粒度控制。 安装网络插件 Calico 注意：截止到文章发表日期 2019 年 05 月 11 日，Calico 官方版本为 3.7 参考官方文档安装：https://docs.projectcalico.org/v3.7/getting-started/kubernetes/ 123456789101112131415161718192021222324252627# 在 Master 节点操作即可kubectl apply -f https://docs.projectcalico.org/v3.7/manifests/calico.yaml# 安装时显示如下输出configmap/calico-config createdcustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org createdclusterrole.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrole.rbac.authorization.k8s.io/calico-node createdclusterrolebinding.rbac.authorization.k8s.io/calico-node createddaemonset.extensions/calico-node createdserviceaccount/calico-node createddeployment.extensions/calico-kube-controllers createdserviceaccount/calico-kube-controllers created 确认安装是否成功 123456789101112131415watch kubectl get pods --all-namespaces# 需要等待所有状态为 Running，注意时间可能较久，3 - 5 分钟的样子Every 2.0s: kubectl get pods --all-namespaces kubernetes-master: Fri May 10 18:16:51 2019NAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-8646dd497f-g2lln 1/1 Running 0 50mkube-system calico-node-8jrtp 1/1 Running 0 50mkube-system coredns-8686dcc4fd-mhwfn 1/1 Running 0 51mkube-system coredns-8686dcc4fd-xsxwk 1/1 Running 0 51mkube-system etcd-kubernetes-master 1/1 Running 0 50mkube-system kube-apiserver-kubernetes-master 1/1 Running 0 51mkube-system kube-controller-manager-kubernetes-master 1/1 Running 0 51mkube-system kube-proxy-p8mdw 1/1 Running 0 51mkube-system kube-scheduler-kubernetes-master 1/1 Running 0 51m 至此基本环境已部署完毕。 解决 ImagePullBackOff在使用 watch kubectl get pods --all-namespaces 命令观察 Pods 状态时如果出现 ImagePullBackOff 无法 Running 的情况，请尝试使用如下步骤处理： Master 中删除 Nodes：kubeadm delete nodes &lt;NAME&gt; Slave 中重置配置：kubeadm reset Slave 重启计算机：reboot Slave 重新加入集群：kubeadm join 附：配置固定 IP 和 DNS当关机后再启动虚拟机有时 IP 地址会自动更换，导致之前的配置不可用；配置完 Kubernetes 网络后虚拟机还会出现无法联网的情况，后经研究发现是 DNS 会被自动重写所致，Ubuntu Server 18.04 LTS 版本的 IP 和 DNS 配置也与之前的版本配置大相径庭，故在此说明下如何修改 IP 和 DNS 修改固定 IP编辑 vi /etc/netplan/50-cloud-init.yaml 配置文件，注意这里的配置文件名未必和你机器上的相同，请根据实际情况修改。修改内容如下： 12345678network: ethernets: ens33: addresses: [192.168.141.134/24] gateway4: 192.168.141.2 nameservers: addresses: [192.168.141.2] version: 2 使配置生效 netplan apply 修改 DNS方法一 停止 systemd-resolved 服务：systemctl stop systemd-resolved 修改 DNS：vi /etc/resolv.conf，将 nameserver 修改为如 114.114.114.114 可以正常使用的 DNS 地址 方法二1vi /etc/systemd/resolved.conf 把 DNS 取消注释，添加 DNS，保存退出，重启即可 第一个 Kubernetes 容器检查组件运行状态12345678910kubectl get cs# 输出如下NAME STATUS MESSAGE ERROR# 调度服务，主要作用是将 POD 调度到 Nodescheduler Healthy ok # 自动化修复服务，主要作用是 Node 宕机后自动修复 Node 回到正常的工作状态controller-manager Healthy ok # 服务注册与发现etcd-0 Healthy &#123;"health":"true"&#125; 检查 Master 状态123456789kubectl cluster-info# 输出如下# 主节点状态Kubernetes master is running at https://192.168.141.130:6443# DNS 状态KubeDNS is running at https://192.168.141.130:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxyTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. 检查 Nodes 状态1234567kubectl get nodes# 输出如下，STATUS 为 Ready 即为正常状态NAME STATUS ROLES AGE VERSIONkubernetes-master Ready master 44h v1.14.1kubernetes-slave1 Ready &lt;none&gt; 3h38m v1.14.1kubernetes-slave2 Ready &lt;none&gt; 3h37m v1.14.1 运行第一个容器实例1234567# 使用 kubectl 命令创建两个监听 80 端口的 Nginx Pod（Kubernetes 运行容器的最小单元）# 80是内网的端口，启动两个副本kubectl run nginx --image=nginx --replicas=2 --port=80# 输出如下kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.deployment.apps/nginx created 查看全部 Pods 的状态123456kubectl get pods# 输出如下，需要等待一小段实践，STATUS 为 Running 即为运行成功NAME READY STATUS RESTARTS AGEnginx-755464dd6c-qnmwp 1/1 Running 0 90mnginx-755464dd6c-shqrp 1/1 Running 0 90m 查看已部署的服务12345kubectl get deployment# 输出如下NAME READY UP-TO-DATE AVAILABLE AGEnginx 2/2 2 2 91m 映射服务，让用户可以访问12345#暴露80端口以负载均衡方式kubectl expose deployment nginx --port=80 --type=LoadBalancer# 输出如下service/nginx exposed 查看已发布的服务1234567kubectl get services# 输出如下NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 44h# 由此可见，Nginx 服务已成功发布并将 80 端口映射为 31738nginx LoadBalancer 10.108.121.244 &lt;pending&gt; 80:31738/TCP 88m 查看服务详情1234567891011121314151617kubectl describe service nginx# 输出如下Name: nginxNamespace: defaultLabels: run=nginxAnnotations: &lt;none&gt;Selector: run=nginxType: LoadBalancerIP: 10.108.121.244Port: &lt;unset&gt; 80/TCPTargetPort: 80/TCPNodePort: &lt;unset&gt; 31738/TCPEndpoints: 192.168.17.5:80,192.168.8.134:80Session Affinity: NoneExternal Traffic Policy: ClusterEvents: &lt;none&gt; 验证是否成功通过浏览器访问 Master 服务器 1http://192.168.141.130:31738/ 此时 Kubernetes 会以负载均衡的方式访问部署的 Nginx 服务，能够正常看到 Nginx 的欢迎页即表示成功。容器实际部署在其它 Node 节点上，通过访问 Node 节点的 IP:Port 也是可以的。 停止服务1234kubectl delete deployment nginx# 输出如下deployment.extensions "nginx" deleted 1234kubectl delete service nginx# 输出如下service "nginx" deleted 概念总结 总结什么是 KubernetesKubernetes 是一个开源的 Docker 容器编排系统，它可以调度计算集群的节点，动态管理上面的作业，保证它们按用户期望的状态运行。通过使用「labels」和「pods」的概念，Kubernetes 将应用按逻辑单元进行分组，方便管理和服务发现。 容器编排工具，为了实现高可用，容器隔离 pods： 是一组紧密关联的容器集合，它们共享 IPC(进程间通信)、Network(网络) 和 UTS namespace(UTS 命名空间是 Linux 命名空间的一个子系统，主要作用是完成对容器 Hostname 和 Domain 的隔离，同时保存内核名称、版本、以及底层体系结构类型等信息)，是 Kubernetes 调度的基本单位。 labels： 键值对(key/value)标签，可以被关联到如 Pod 这样的对象上，主要作用是给用户一个直观的感受，比如这个 Pod 是用来放置数据库的 GUI： 用户图形界面，可以是 Web 用户界面，比如使用 kubernetes-dashboard 组件，用户可以通过 Dashboard 在 Kubernetes 集群中部署容器化的应用，可以查看集群中应用的运行情况，同时也能够基于 Dashboard 创建或修改部署、任务、服务等 Kubernetes 的资源。通过部署向导，用户能够对部署进行扩缩容，进行滚动更新、重启 Pod 和部署新应用。当然，通过 Dashboard 也能够查看 Kubernetes 资源的状态 kubectl： 用于管理 Kubernetes 集群的命令行工具 kube-apiserver： 提供了资源操作的唯一入口，并提供认证、授权（RBCA）、访问控制、API 注册和发现等机制 Kubernetes Master： Kubernetes 集群主节点，主要由 kube-apiserver、kube-scheduler（调度）、kube-controller-manager（管理pods生命周期）、etcd（服务注册与发现） 四个模块组成 Kubernetes Node： Kubernetes 集群子节点，主要由 kubelet（也是容器生命周期管理，帮助你在外界因素容器挂掉后自动重启）、kube-proxy（k8s组成一个巨大的内网，内网的端口是不向外暴露的，进入需要代理）、runtime（容器引擎，docker） 三个模块组成 Image Registry： 镜像仓库，比如：Ducker HUB 或 Docker 私服 Kubernetes Master kube-apiserver： 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制 kube-scheduler： 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上 kube-controller-manager： 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 etcd： CoreOS 基于 Raft 开发的分布式 key-value 存储，可用于服务发现、共享配置以及一致性保障（如数据库选主、分布式锁等） Kubernetes Node runtime： 负责镜像管理以及 Pod 和容器的真正运行（CRI，Container Runtime Interface），默认的容器运行时为 Docker，还支持 RKT 容器 kubelet： 负责维持容器的生命周期，同时也负责 Volume数据卷（CVI，Container Volume Interface）和网络（CNI，Container Network Interface）的管理 kube-proxy： 负责为 Service 提供 cluster 内部的服务发现和负载均衡 job Kubernetes 架构 Kubernetes 高可用集群概述在入门课程中我们部署的 Kubernetes 是 集群模式，但在实际生产中我们需要部署 高可用集群 ，本章内容旨在指导大家如何部署 Kubernetes 高可用集群 统一环境配置节点配置 主机名 IP 角色 系统 CPU/内存 磁盘 kubernetes-master-01 192.168.141.150 Master Ubuntu Server 18.04 2核2G 20G kubernetes-master-02 192.168.141.151 Master Ubuntu Server 18.04 2核2G 20G kubernetes-master-03 192.168.141.152 Master Ubuntu Server 18.04 2核2G 20G kubernetes-node-01 192.168.141.160 Node Ubuntu Server 18.04 2核4G 20G kubernetes-node-02 192.168.141.161 Node Ubuntu Server 18.04 2核4G 20G kubernetes-node-03 192.168.141.162 Node Ubuntu Server 18.04 2核4G 20G Kubernetes VIP 192.168.141.200 - - - - 对操作系统的配置 特别注意：以下步骤请在制作 VMware 镜像时一并完成，避免逐台安装的痛苦 关闭交换空间1swapoff -a 避免开机启动交换空间12# 注释 swap 开头的行vi /etc/fstab 关闭防火墙1ufw disable 配置 DNS12# 取消 DNS 行注释，并增加 DNS 配置如：114.114.114.114，修改后重启下计算机vi /etc/systemd/resolved.conf 安装 Docker123456789101112# 更新软件源sudo apt-get update# 安装所需依赖sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common# 安装 GPG 证书curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# 新增软件源信息sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"# 再次更新软件源sudo apt-get -y update# 安装 Docker CE 版sudo apt-get -y install docker-ce 配置 Docker 加速器 特别注意：国内镜像加速器可能会很卡，请替换成你自己阿里云镜像加速器，地址如：https://yourself.mirror.aliyuncs.com，在阿里云控制台的 容器镜像服务 -&gt; 镜像加速器 菜单中可以找到 在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件） 12345&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125; 安装 kubeadm，kubelet，kubectl12345678910111213# 安装系统工具apt-get update &amp;&amp; apt-get install -y apt-transport-https# 安装 GPG 证书curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -# 写入软件源；注意：我们用系统代号为 bionic，但目前阿里云不支持，所以沿用 16.04 的 xenialcat &lt;&lt; EOF &gt;/etc/apt/sources.list.d/kubernetes.list&gt; deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main&gt; EOF# 安装apt-get update &amp;&amp; apt-get install -y kubelet kubeadm kubectl 同步时间设置时区 1dpkg-reconfigure tzdata 选择 Asia（亚洲） 选择 Shanghai（上海） 时间同步 12345678# 安装 ntpdateapt-get install ntpdate# 设置系统时间与网络时间同步（cn.pool.ntp.org 位于中国的公共 NTP 服务器）ntpdate cn.pool.ntp.org# 将系统时间写入硬件时间hwclock --systohc 确认时间 1234date# 输出如下（自行对照与系统时间是否一致）Sun Jun 2 22:02:35 CST 2019 配置 IPVS123456789101112131415161718192021222324252627# 安装系统工具apt-get install -y ipset ipvsadm# 配置并加载 IPVS 模块mkdir -p /etc/sysconfig/modules/vi /etc/sysconfig/modules/ipvs.modules# 输入如下内容#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4# 执行脚本，注意：如果重启则需要重新运行该脚本chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4# 执行脚本输出如下ip_vs_sh 16384 0ip_vs_wrr 16384 0ip_vs_rr 16384 0ip_vs 147456 6 ip_vs_rr,ip_vs_sh,ip_vs_wrrnf_conntrack_ipv4 16384 3nf_defrag_ipv4 16384 1 nf_conntrack_ipv4nf_conntrack 131072 8 xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_ipv4,nf_nat,ipt_MASQUERADE,nf_nat_ipv4,nf_conntrack_netlink,ip_vslibcrc32c 16384 4 nf_conntrack,nf_nat,raid456,ip_vs 配置内核参数123456789101112131415161718192021222324252627282930313233343536373839404142434445# 配置参数vi /etc/sysctl.d/k8s.conf# 输入如下内容net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_nonlocal_bind = 1net.ipv4.ip_forward = 1vm.swappiness=0# 应用参数sysctl --system# 应用参数输出如下（找到 Applying /etc/sysctl.d/k8s.conf 开头的日志）* Applying /etc/sysctl.d/10-console-messages.conf ...kernel.printk = 4 4 1 7* Applying /etc/sysctl.d/10-ipv6-privacy.conf ...* Applying /etc/sysctl.d/10-kernel-hardening.conf ...kernel.kptr_restrict = 1* Applying /etc/sysctl.d/10-link-restrictions.conf ...fs.protected_hardlinks = 1fs.protected_symlinks = 1* Applying /etc/sysctl.d/10-lxd-inotify.conf ...fs.inotify.max_user_instances = 1024* Applying /etc/sysctl.d/10-magic-sysrq.conf ...kernel.sysrq = 176* Applying /etc/sysctl.d/10-network-security.conf ...net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.all.rp_filter = 1net.ipv4.tcp_syncookies = 1* Applying /etc/sysctl.d/10-ptrace.conf ...kernel.yama.ptrace_scope = 1* Applying /etc/sysctl.d/10-zeropage.conf ...vm.mmap_min_addr = 65536* Applying /usr/lib/sysctl.d/50-default.conf ...net.ipv4.conf.all.promote_secondaries = 1net.core.default_qdisc = fq_codel* Applying /etc/sysctl.d/99-sysctl.conf ...* Applying /etc/sysctl.d/k8s.conf ...net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_nonlocal_bind = 1net.ipv4.ip_forward = 1vm.swappiness = 0* Applying /etc/sysctl.conf ... 修改 cloud.cfg1234vi /etc/cloud/cloud.cfg# 该配置默认为 false，修改为 true 即可preserve_hostname: true 单独节点配置 特别注意：为 Master 和 Node 节点单独配置对应的 IP 和 主机名 配置 IP编辑 vi /etc/netplan/50-cloud-init.yaml 配置文件，修改内容如下 123456789network: ethernets: ens33: # 我的 Master 是 150 - 152，Node 是 160 - 162 addresses: [192.168.141.150/24] gateway4: 192.168.141.2 nameservers: addresses: [192.168.141.2] version: 2 使用 netplan apply 命令让配置生效 配置主机名1234567# 修改主机名hostnamectl set-hostname kubernetes-master-01# 配置 hostscat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.141.150 kubernetes-master-01EOF 安装 HAProxy + Keepalived概述Kubernetes Master 节点运行组件如下： kube-apiserver： 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制 kube-scheduler： 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上 kube-controller-manager： 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 etcd： CoreOS 基于 Raft 开发的分布式 key-value 存储，可用于服务发现、共享配置以及一致性保障（如数据库选主、分布式锁等） kube-scheduler 和 kube-controller-manager 可以以集群模式运行，通过 leader 选举产生一个工作进程，其它进程处于阻塞模式。 kube-apiserver 可以运行多个实例，但对其它组件需要提供统一的访问地址，本章节部署 Kubernetes 高可用集群实际就是利用 HAProxy + Keepalived 配置该组件 配置的思路就是利用 HAProxy + Keepalived 实现 kube-apiserver 虚拟 IP 访问从而实现高可用和负载均衡，拆解如下： Keepalived 提供 kube-apiserver 对外服务的虚拟 IP（VIP） HAProxy 监听 Keepalived VIP 运行 Keepalived 和 HAProxy 的节点称为 LB（负载均衡） 节点 Keepalived 是一主多备运行模式，故至少需要两个 LB 节点 Keepalived 在运行过程中周期检查本机的 HAProxy 进程状态，如果检测到 HAProxy 进程异常，则触发重新选主的过程，VIP 将飘移到新选出来的主节点，从而实现 VIP 的高可用 所有组件（如 kubeclt、apiserver、controller-manager、scheduler 等）都通过 VIP +HAProxy 监听的 6444 端口访问 kube-apiserver 服务（注意：kube-apiserver 默认端口为 6443，为了避免冲突我们将 HAProxy 端口设置为 6444，其它组件都是通过该端口统一请求 apiserver） 创建 HAProxy 启动脚本 该步骤在 kubernetes-master-01 执行 12345678910111213141516171819202122mkdir -p /usr/local/kubernetes/lbvi /usr/local/kubernetes/lb/start-haproxy.sh# 输入内容如下#!/bin/bash# 修改为你自己的 Master 地址MasterIP1=192.168.141.150MasterIP2=192.168.141.151MasterIP3=192.168.141.152# 这是 kube-apiserver 默认端口，不用修改MasterPort=6443# 容器将 HAProxy 的 6444 端口暴露出去docker run -d --restart=always --name HAProxy-K8S -p 6444:6444 \ -e MasterIP1=$MasterIP1 \ -e MasterIP2=$MasterIP2 \ -e MasterIP3=$MasterIP3 \ -e MasterPort=$MasterPort \ wise2c/haproxy-k8s# 设置权限chmod +x start-haproxy.sh 创建 Keepalived 启动脚本 该步骤在 kubernetes-master-01 执行 123456789101112131415161718192021222324252627282930313233mkdir -p /usr/local/kubernetes/lbvi /usr/local/kubernetes/lb/start-keepalived.sh# 输入内容如下#!/bin/bash# 修改为你自己的虚拟 IP 地址VIRTUAL_IP=192.168.141.200# 虚拟网卡设备名INTERFACE=ens33# 虚拟网卡的子网掩码NETMASK_BIT=24# HAProxy 暴露端口，内部指向 kube-apiserver 的 6443 端口CHECK_PORT=6444# 路由标识符RID=10# 虚拟路由标识符VRID=160# IPV4 多播地址，默认 224.0.0.18MCAST_GROUP=224.0.0.18docker run -itd --restart=always --name=Keepalived-K8S \ --net=host --cap-add=NET_ADMIN \ -e VIRTUAL_IP=$VIRTUAL_IP \ -e INTERFACE=$INTERFACE \ -e CHECK_PORT=$CHECK_PORT \ -e RID=$RID \ -e VRID=$VRID \ -e NETMASK_BIT=$NETMASK_BIT \ -e MCAST_GROUP=$MCAST_GROUP \ wise2c/keepalived-k8s# 设置权限chmod +x start-keepalived.sh 复制脚本到其它 Master 地址分别在 kubernetes-master-02 和 kubernetes-master-03 执行创建工作目录命令 1mkdir -p /usr/local/kubernetes/lb 将 kubernetes-master-01 中的脚本拷贝至其它 Master 12scp start-haproxy.sh start-keepalived.sh 192.168.141.151:/usr/local/kubernetes/lbscp start-haproxy.sh start-keepalived.sh 192.168.141.152:/usr/local/kubernetes/lb 分别在 3 个 Master 中启动容器（执行脚本） 1sh /usr/local/kubernetes/lb/start-haproxy.sh &amp;&amp; sh /usr/local/kubernetes/lb/start-keepalived.sh 验证是否成功查看容器123456docker ps# 输出如下CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf50df479ecae wise2c/keepalived-k8s "/usr/bin/keepalived…" About an hour ago Up About an hour Keepalived-K8S75066a7ed2fb wise2c/haproxy-k8s "/docker-entrypoint.…" About an hour ago Up About an hour 0.0.0.0:6444-&gt;6444/tcp HAProxy-K8S 查看网卡绑定的虚拟 IP123456ip a | grep ens33# 输出如下2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 inet 192.168.141.151/24 brd 192.168.141.255 scope global ens33 inet 192.168.141.200/24 scope global secondary ens33 特别注意：Keepalived 会对 HAProxy 监听的 6444 端口进行检测，如果检测失败即认定本机 HAProxy 进程异常，会将 VIP 漂移到其他节点，所以无论本机 Keepalived 容器异常或 HAProxy 容器异常都会导致 VIP 漂移到其他节点 部署 Kubernetes 集群初始化 Master 创建工作目录并导出配置文件 12345# 创建工作目录mkdir -p /usr/local/kubernetes/cluster# 导出配置文件到工作目录kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml 修改配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152apiVersion: kubeadm.k8s.io/v1beta1bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: # 修改为主节点 IP advertiseAddress: 192.168.141.150 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: kubernetes-master taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta1certificatesDir: /etc/kubernetes/pkiclusterName: kubernetes# 配置 Keepalived 地址和 HAProxy 端口controlPlaneEndpoint: "192.168.141.200:6444"controllerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcd# 国内不能访问 Google，修改为阿里云imageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfiguration# 修改版本号kubernetesVersion: v1.14.2networking: dnsDomain: cluster.local # 配置成 Calico 的默认网段 podSubnet: "192.168.0.0/16" serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;---# 开启 IPVS 模式apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs kubeadm 初始化 12345678910# kubeadm 初始化kubeadm init --config=kubeadm.yml --experimental-upload-certs | tee kubeadm-init.log# 配置 kubectlmkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config# 验证是否成功kubectl get node 安装网络插件 12345# 安装 Calicokubectl apply -f https://docs.projectcalico.org/v3.7/manifests/calico.yaml# 验证安装是否成功watch kubectl get pods --all-namespaces 加入 Master 节点从 kubeadm-init.log 中获取命令，分别将 kubernetes-master-02 和 kubernetes-master-03 加入 Master 1234# 以下为示例命令kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:56d53268517c132ae81c868ce99c44be797148fb2923e59b49d73c99782ff21f \ --experimental-control-plane --certificate-key c4d1525b6cce4b69c11c18919328c826f92e660e040a46f5159431d5ff0545bd 加入 Node 节点从 kubeadm-init.log 中获取命令，分别将 kubernetes-node-01 至 kubernetes-node-03 加入 Node 123# 以下为示例命令kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:56d53268517c132ae81c868ce99c44be797148fb2923e59b49d73c99782ff21f 验证集群状态 查看 Node 1kubectl get nodes -o wide 查看 Pod 1kubectl -n kube-system get pod -o wide 查看 Service 1kubectl -n kube-system get svc 验证 IPVS 查看 kube-proxy 日志，server_others.go:176] Using ipvs Proxier. 1kubectl -n kube-system logs -f &lt;kube-proxy 容器名&gt; 查看代理规则 1ipvsadm -ln 查看生效的配置 1kubectl -n kube-system get cm kubeadm-config -oyaml 查看 etcd 集群 1234567891011kubectl -n kube-system exec etcd-kubernetes-master-01 -- etcdctl \ --endpoints=https://192.168.141.150:2379 \ --ca-file=/etc/kubernetes/pki/etcd/ca.crt \ --cert-file=/etc/kubernetes/pki/etcd/server.crt \ --key-file=/etc/kubernetes/pki/etcd/server.key cluster-health# 输出如下member 1dfaf07371bb0cb6 is healthy: got healthy result from https://192.168.141.152:2379member 2da85730b52fbeb2 is healthy: got healthy result from https://192.168.141.150:2379member 6a3153eb4faaaffa is healthy: got healthy result from https://192.168.141.151:2379cluster is healthy 验证高可用 特别注意：Keepalived 要求至少 2 个备用节点，故想测试高可用至少需要 1 主 2 从模式验证，否则可能出现意想不到的问题 对任意一台 Master 机器执行关机操作 1shutdown -h now 在任意一台 Master 节点上查看 Node 状态 1234567kubectl get node# 输出如下，除已关机那台状态为 NotReady 其余正常便表示成功NAME STATUS ROLES AGE VERSIONkubernetes-master-01 NotReady master 18m v1.14.2kubernetes-master-02 Ready master 17m v1.14.2kubernetes-master-03 Ready master 16m v1.14.2 查看 VIP 漂移 123456ip a |grep ens33# 输出如下2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 inet 192.168.141.151/24 brd 192.168.141.255 scope global ens33 inet 192.168.141.200/24 scope global secondary ens33 解决 Node 无法加入的问题问题描述当我们使用 kubeadm join 命令将 Node 节点加入集群时，你会发现所有 kubectl 命令均不可用（呈现阻塞状态，并不会返回响应结果），我们可以在 Node 节点中通过 kubeadm reset 命令将 Node 节点下线，此时回到 Master 节点再使用 watch kubectl get pods --all-namespaces 可以看到下图中报错了，coredns-xxx-xxx 状态为 CrashLoopBackOff 解决方案从上面的错误信息不难看出应该是出现了网络问题，而我们在安装过程中只使用了一个网络插件 Calico ，那么该错误是不是由 Calico 引起的呢？带着这个疑问我们去到 Calico 官网再看一下它的说明，官网地址：https://docs.projectcalico.org/v3.7/getting-started/kubernetes/ 在它的 Quickstart 里有两段话（属于特别提醒），截图如下： 上面这段话的主要意思是：当 kubeadm 安装完成后不要关机，继续完成后续的安装步骤；这也说明了安装 Kubernetes 的过程不要出现中断一口气搞定（不过这不是重点）(*￣rǒ￣) 上面这段话的主要意思是：如果你的网络在 192.168.0.0/16 网段中，则必须选择一个不同的 Pod 网络；恰巧咱们的网络范围（我虚拟机的 IP 范围是 192.168.141.0/24）和该网段重叠 (ノへ￣、)；好吧，当时做单节点集群时因为没啥问题而忽略了 ♪(^∇^*) so，能够遇到这个问题主要是因为虚拟机 IP 范围刚好和 Calico 默认网段重叠导致的，所以想要解决这个问题，咱们就需要修改 Calico 的网段了（当然也可以改虚拟机的），换句话说就是大家重装一下 o (一︿一 +) o 按照以下标准步骤重装即可 重置 Kubernetes12345678910111213141516171819202122kubeadm reset# 输出如下[reset] WARNING: Changes made to this host by 'kubeadm init' or 'kubeadm join' will be reverted.[reset] Are you sure you want to proceed? [y/N]: y[preflight] Running pre-flight checksW0604 01:55:28.517280 22688 reset.go:234] [reset] No kubeadm config, using etcd pod spec to get data directory[reset] No etcd config found. Assuming external etcd[reset] Please manually reset etcd to prevent further issues[reset] Stopping the kubelet service[reset] unmounting mounted directories in "/var/lib/kubelet"[reset] Deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/run/kubernetes][reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki][reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]The reset process does not reset or clean up iptables rules or IPVS tables.If you wish to reset iptables, you must do so manually.For example:iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -XIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)to reset your system's IPVS tables. 删除 kubectl 配置1rm -fr ~/.kube/ 启用 IPVS12345modprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4 导出并修改配置文件1kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml 配置文件修改如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647apiVersion: kubeadm.k8s.io/v1beta1bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 192.168.141.150 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: kubernetes-master-01 taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta1certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrolPlaneEndpoint: "192.168.141.200:6444"controllerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfigurationkubernetesVersion: v1.14.2networking: dnsDomain: cluster.local # 主要修改在这里，替换 Calico 网段为我们虚拟机不重叠的网段（这里用的是 Flannel 默认网段） podSubnet: "10.244.0.0/16" serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs kubeadm 初始化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586kubeadm init --config=kubeadm.yml --experimental-upload-certs | tee kubeadm-init.log# 输出如下[init] Using Kubernetes version: v1.14.2[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Activating the kubelet service[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "front-proxy-ca" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "etcd/ca" certificate and key[certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [kubernetes-master-01 localhost] and IPs [192.168.141.150 127.0.0.1 ::1][certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "apiserver-etcd-client" certificate and key[certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [kubernetes-master-01 localhost] and IPs [192.168.141.150 127.0.0.1 ::1][certs] Generating "ca" certificate and key[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [kubernetes-master-01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.141.150 192.168.141.200][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "sa" key and public key[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "admin.conf" kubeconfig file[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "kubelet.conf" kubeconfig file[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "controller-manager.conf" kubeconfig file[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s[apiclient] All control plane components are healthy after 24.507568 seconds[upload-config] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.14" in namespace kube-system with the configuration for the kubelets in the cluster[upload-certs] Storing the certificates in ConfigMap "kubeadm-certs" in the "kube-system" Namespace[upload-certs] Using certificate key:a662b8364666f82c93cc5cd4fb4fabb623bbe9afdb182da353ac40f1752dfa4a[mark-control-plane] Marking the node kubernetes-master-01 as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node kubernetes-master-01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: abcdef.0123456789abcdef[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] creating the "cluster-info" ConfigMap in the "kube-public" namespace[addons] Applied essential addon: CoreDNS[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of the control-plane node running the following command on each as root: kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad \ --experimental-control-plane --certificate-key a662b8364666f82c93cc5cd4fb4fabb623bbe9afdb182da353ac40f1752dfa4aPlease note that the certificate-key gives access to cluster sensitive data, keep it secret!As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use "kubeadm init phase upload-certs --experimental-upload-certs" to reload certs afterward.Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad 配置 kubectl1234567# 配置 kubectlmkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config# 验证是否成功kubectl get node 下载 Calico 配置文件并修改1wget https://docs.projectcalico.org/v3.7/manifests/calico.yaml 1vi calico.yaml 修改第 611 行，将 192.168.0.0/16 修改为 10.244.0.0/16，可以通过如下命令快速查找 显示行号：:set number 查找字符：/要查找的字符，输入小写 n 下一个匹配项，输入大写 N 上一个匹配项 安装 Calico1234567891011121314151617181920212223242526kubectl apply -f calico.yaml# 输出如下configmap/calico-config createdcustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org createdclusterrole.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrole.rbac.authorization.k8s.io/calico-node createdclusterrolebinding.rbac.authorization.k8s.io/calico-node createddaemonset.extensions/calico-node createdserviceaccount/calico-node createddeployment.extensions/calico-kube-controllers createdserviceaccount/calico-kube-controllers created 加入 Master 节点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 示例如下，别忘记两个备用节点都要加入哦kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad \ --experimental-control-plane --certificate-key a662b8364666f82c93cc5cd4fb4fabb623bbe9afdb182da353ac40f1752dfa4a# 输出如下[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[preflight] Running pre-flight checks before initializing the new control plane instance[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[download-certs] Downloading the certificates in Secret "kubeadm-certs" in the "kube-system" Namespace[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [kubernetes-master-02 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.141.151 192.168.141.200][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [kubernetes-master-02 localhost] and IPs [192.168.141.151 127.0.0.1 ::1][certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [kubernetes-master-02 localhost] and IPs [192.168.141.151 127.0.0.1 ::1][certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "apiserver-etcd-client" certificate and key[certs] Valid certificates and keys now exist in "/etc/kubernetes/pki"[certs] Using the existing "sa" key[kubeconfig] Generating kubeconfig files[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "admin.conf" kubeconfig file[kubeconfig] Writing "controller-manager.conf" kubeconfig file[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"[check-etcd] Checking that the etcd cluster is healthy[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.14" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Activating the kubelet service[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...[etcd] Announced new etcd member joining to the existing etcd cluster[etcd] Wrote Static Pod manifest for a local etcd member to "/etc/kubernetes/manifests/etcd.yaml"[etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s[upload-config] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[mark-control-plane] Marking the node kubernetes-master-02 as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node kubernetes-master-02 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]This node has joined the cluster and a new control plane instance was created:* Certificate signing request was sent to apiserver and approval was received.* The Kubelet was informed of the new secure connection details.* Control plane (master) label and taint were applied to the new node.* The Kubernetes control plane instances scaled up.* A new etcd member was added to the local/stacked etcd cluster.To start administering your cluster from this node, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configRun 'kubectl get nodes' to see this node join the cluster. 加入 Node 节点123456789101112131415161718192021# 示例如下kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad# 输出如下&gt; --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.14" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Activating the kubelet service[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 验证是否可用12345678kubectl get node# 输出如下，我们可以看到 Node 节点已经成功上线 ━━(￣ー￣*|||━━NAME STATUS ROLES AGE VERSIONkubernetes-master-01 Ready master 19m v1.14.2kubernetes-master-02 Ready master 4m46s v1.14.2kubernetes-master-03 Ready master 3m23s v1.14.2kubernetes-node-01 Ready &lt;none&gt; 74s v1.14.2 1234567891011121314151617181920212223242526272829watch kubectl get pods --all-namespaces# 输出如下，coredns 也正常运行了Every 2.0s: kubectl get pods --all-namespaces kubernetes-master-01: Tue Jun 4 02:31:43 2019NAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-8646dd497f-hz5xp 1/1 Running 0 9m9skube-system calico-node-2z892 1/1 Running 0 9m9skube-system calico-node-fljxv 1/1 Running 0 6m39skube-system calico-node-vprlw 1/1 Running 0 5m16skube-system calico-node-xvqcx 1/1 Running 0 3m7skube-system coredns-8686dcc4fd-5ndjm 1/1 Running 0 21mkube-system coredns-8686dcc4fd-zxtql 1/1 Running 0 21mkube-system etcd-kubernetes-master-01 1/1 Running 0 20mkube-system etcd-kubernetes-master-02 1/1 Running 0 6m37skube-system etcd-kubernetes-master-03 1/1 Running 0 5m14skube-system kube-apiserver-kubernetes-master-01 1/1 Running 0 20mkube-system kube-apiserver-kubernetes-master-02 1/1 Running 0 6m37skube-system kube-apiserver-kubernetes-master-03 1/1 Running 0 5m14skube-system kube-controller-manager-kubernetes-master-01 1/1 Running 1 20mkube-system kube-controller-manager-kubernetes-master-02 1/1 Running 0 6m37skube-system kube-controller-manager-kubernetes-master-03 1/1 Running 0 5m14skube-system kube-proxy-68jqr 1/1 Running 0 3m7skube-system kube-proxy-69bnn 1/1 Running 0 6m39skube-system kube-proxy-vvhp5 1/1 Running 0 5m16skube-system kube-proxy-ws6wx 1/1 Running 0 21mkube-system kube-scheduler-kubernetes-master-01 1/1 Running 1 20mkube-system kube-scheduler-kubernetes-master-02 1/1 Running 0 6m37skube-system kube-scheduler-kubernetes-master-03 1/1 Running 0 5m14s 至此，Kubernetes 高可用集群算是彻底部署成功，撒花撒花 (゜-゜)つロ 干杯 通过资源配置运行容器我们知道通过 run 命令启动容器非常麻烦，Docker 提供了 Compose 为我们解决了这个问题。那 Kubernetes 是如何解决这个问题的呢？其实很简单，使用 kubectl create命令就可以做到和 Compose 一样的效果了，该命令可以通过配置文件快速创建一个集群资源对象。 创建 YAML 配置文件以部署 Nginx 为例 部署 Deployment创建一个名为 nginx-deployment.yml 的配置文件 123456789101112131415161718192021222324252627# API 版本号apiVersion: extensions/v1beta1# 类型，如：Pod/ReplicationController/Deployment/Service/Ingresskind: Deployment# 元数据metadata: # Kind 的名称 name: nginx-appspec: # 部署的实例数量 replicas: 2 template: metadata: labels: # 容器标签的名字，发布 Service 时，selector 需要和这里对应 name: nginx spec: # 配置容器，数组类型，说明可以配置多个容器 containers: # 容器名称 - name: nginx # 容器镜像 image: nginx # 暴露端口 ports: # Pod 端口 - containerPort: 80 12345# 部署kubectl create -f nginx-deployment.yml# 删除kubectl delete -f nginx-deployment.yml 发布 Service创建一个名为 nginx-service.yml 的配置文件 123456789101112131415161718192021# API 版本号apiVersion: v1# 类型，如：Pod/ReplicationController/Deployment/Service/Ingresskind: Service# 元数据metadata: # Kind 的名称 name: nginx-httpspec: # 暴露端口 ports: ## Service 暴露的端口 - port: 80 ## Pod 上的端口，这里是将 Service 暴露的端口转发到 Pod 端口上 targetPort: 80 # 类型 type: LoadBalancer # 标签选择器 selector: # 需要和上面部署的 Deployment 标签名对应 name: nginx 12345# 部署kubectl create -f nginx-service.yml# 删除kubectl delete -f nginx-service.yml 验证是否生效查看 Pod 列表123456kubectl get pods# 输出如下NAME READY STATUS RESTARTS AGEnginx-app-64bb598779-2pplx 1/1 Running 0 25mnginx-app-64bb598779-824lc 1/1 Running 0 25m 查看 Deployment 列表12345kubectl get deployment# 输出如下NAME READY UP-TO-DATE AVAILABLE AGEnginx-app 2/2 2 2 25m 查看 Service 列表123456kubectl get service# 输出如下NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 20hnginx-http LoadBalancer 10.98.49.142 &lt;pending&gt; 80:31631/TCP 14m 查看 Service 详情1234567891011121314151617kubectl describe service nginx-app# 输出如下Name: nginx-httpNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Selector: name=nginxType: LoadBalancerIP: 10.98.49.142Port: &lt;unset&gt; 80/TCPTargetPort: 80/TCPNodePort: &lt;unset&gt; 31631/TCPEndpoints: 10.244.141.205:80,10.244.2.4:80Session Affinity: NoneExternal Traffic Policy: ClusterEvents: &lt;none&gt; 通过浏览器访问通过浏览器访问 http://192.168.141.150:31631/ ，出现 Nginx 欢迎页即表示成功 集成环境部署也可以不区分配置文件，一次性部署 Deployment 和 Service，创建一个名为 nginx.yml的配置文件，配置内容如下： 123456789101112131415161718192021222324252627282930apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx-appspec: replicas: 2 template: metadata: labels: name: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: nginx-httpspec: ports: - port: 80 targetPort: 80 # 可以指定 NodePort 端口，默认范围是：30000-32767 # nodePort: 30080 type: LoadBalancer selector: name: nginx 12345# 部署kubectl create -f nginx.yml# 删除kubectl delete -f nginx.yml 附：修改默认的端口范围Kubernetes 服务的 NodePort 默认端口范围是 30000-32767，在某些场合下，这个限制不太适用，我们可以自定义它的端口范围，操作步骤如下： 编辑 vi /etc/kubernetes/manifests/kube-apiserver.yaml 配置文件，增加配置 --service-node-port-range=2-65535 123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: creationTimestamp: null labels: component: kube-apiserver tier: control-plane name: kube-apiserver namespace: kube-systemspec: containers: - command: - kube-apiserver # 在这里增加配置即可 - --service-node-port-range=2-65535 - --advertise-address=192.168.141.150 - --allow-privileged=true - --authorization-mode=Node,RBAC - --client-ca-file=/etc/kubernetes/pki/ca.crt - --enable-admission-plugins=NodeRestriction - --enable-bootstrap-token-auth=true - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt// 以下配置省略... 使用 docker ps 命令找到 kube-apiserver 容器，再使用 docker restart &lt;ApiServer 容器 ID&gt; 即可生效。 Ingress 统一访问入口术语 节点： Kubernetes 集群中的服务器 集群： Kubernetes 管理的一组服务器集合 边界路由器： 为局域网和 Internet 路由数据包的路由器，执行防火墙保护局域网络 集群网络： 遵循 Kubernetes 网络模型实现集群内的通信的具体实现，比如 Flannel 和 Calico 服务： Kubernetes 的服务 (Service) 是使用标签选择器标识的一组 Pod Service (Deployment)。 除非另有说明，否则服务的虚拟 IP 仅可在集群内部访问 内部访问方式 ClusterIPClusterIP 服务是 Kubernetes 的默认服务。它给你一个集群内的服务，集群内的其它应用都可以访问该服务。集群外部无法访问它。在某些场景下我们可以使用 Kubernetes 的 Proxy 模式来访问服务，比如调试服务时。 三种外部访问方式NodePortNodePort 服务是引导外部流量到你的服务的最原始方式。NodePort，正如这个名字所示，在所有节点（虚拟机）上开放一个特定端口，任何发送到该端口的流量都被转发到对应服务。 NodePort 服务特征如下： 每个端口只能是一种服务 端口范围只能是 30000-32767（可调） 不在 YAML 配置文件中指定则会分配一个默认端口 建议： 不要在生产环境中使用这种方式暴露服务，大多数时候我们应该让 Kubernetes 来选择端口 LoadBalancerLoadBalancer 服务是暴露服务到 Internet 的标准方式。所有通往你指定的端口的流量都会被转发到对应的服务。它没有过滤条件，没有路由等。这意味着你几乎可以发送任何种类的流量到该服务，像 HTTP，TCP，UDP，WebSocket，gRPC 或其它任意种类。 IngressIngress 事实上不是一种服务类型。相反，它处于多个服务的前端，扮演着 “智能路由” 或者集群入口的角色。你可以用 Ingress 来做许多不同的事情，各种不同类型的 Ingress 控制器也有不同的能力。它允许你基于路径或者子域名来路由流量到后端服务。 Ingress 可能是暴露服务的最强大方式，但同时也是最复杂的。Ingress 控制器有各种类型，包括 Google Cloud Load Balancer， Nginx，Contour，Istio，等等。它还有各种插件，比如 cert-manager (它可以为你的服务自动提供 SSL 证书)/ 如果你想要使用同一个 IP 暴露多个服务，这些服务都是使用相同的七层协议（典型如 HTTP），你还可以获取各种开箱即用的特性（比如 SSL、认证、路由等等） 什么是 Ingress通常情况下，Service 和 Pod 的 IP 仅可在集群内部访问。集群外部的请求需要通过负载均衡转发到 Service 在 Node 上暴露的 NodePort 上，然后再由 kube-proxy 通过边缘路由器 (edge router) 将其转发给相关的 Pod 或者丢弃。而 Ingress 就是为进入集群的请求提供路由规则的集合 Ingress 可以给 Service 提供集群外部访问的 URL、负载均衡、SSL 终止、HTTP 路由等。为了配置这些 Ingress 规则，集群管理员需要部署一个 Ingress Controller，它监听 Ingress 和 Service 的变化，并根据规则配置负载均衡并提供访问入口。 使用 Nginx Ingress Controller本次实践的主要目的就是将入口统一，不再通过 LoadBalancer 等方式将端口暴露出来，而是使用 Ingress 提供的反向代理负载均衡功能作为我们的唯一入口。通过以下步骤操作仔细体会。 注意： 下面包含资源配置的步骤都是自行创建 YAML 配置文件通过 kubectl create -f &lt;YAML&gt; 和 kubectl delete -f &lt;YAML&gt; 部署和删除 部署 Tomcat部署 Tomcat 但仅允许在内网访问，我们要通过 Ingress 提供的反向代理功能路由到 Tomcat 之上 1234567891011121314151617181920212223242526272829apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: tomcat-appspec: replicas: 2 template: metadata: labels: name: tomcat spec: containers: - name: tomcat image: tomcat ports: - containerPort: 8080---apiVersion: v1kind: Servicemetadata: name: tomcat-httpspec: ports: - port: 8080 targetPort: 8080 # ClusterIP, NodePort, LoadBalancer type: LoadBalancer selector: name: tomcat 安装 Nginx Ingress ControllerIngress Controller 有许多种，我们选择最熟悉的 Nginx 来处理请求，其它可以参考 官方文档 下载 Nginx Ingress Controller 配置文件 1wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml 1 修改配置文件，找到配置如下位置 (搜索 serviceAccountName) 在下面增加一句 hostNetwork: true 12345678910111213141516171819202122232425262728293031323334353637apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-ingress-controller namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: # 可以部署多个实例 replicas: 1 selector: matchLabels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx template: metadata: labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx annotations: prometheus.io/port: "10254" prometheus.io/scrape: "true" spec: serviceAccountName: nginx-ingress-serviceaccount # 增加 hostNetwork: true，意思是开启主机网络模式，暴露 Nginx 服务端口 80 hostNetwork: true containers: - name: nginx-ingress-controller image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.24.1 args: - /nginx-ingress-controller - --configmap=$(POD_NAMESPACE)/nginx-configuration - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services - --udp-services-configmap=$(POD_NAMESPACE)/udp-services - --publish-service=$(POD_NAMESPACE)/ingress-nginx// 以下代码省略... 部署 IngressIngress 翻译过来是入口的意思，说白了就是个 API 网关（想想之前学的 Zuul 和 Spring Cloud Gateway） 1234567891011121314151617181920212223242526272829303132apiVersion: networking.k8s.io/v1beta1kind: Ingressmetadata: name: nginx-web annotations: # 指定 Ingress Controller 的类型 kubernetes.io/ingress.class: "nginx" # 指定我们的 rules 的 path 可以使用正则表达式 nginx.ingress.kubernetes.io/use-regex: "true" # 连接超时时间，默认为 5s nginx.ingress.kubernetes.io/proxy-connect-timeout: "600" # 后端服务器回转数据超时时间，默认为 60s nginx.ingress.kubernetes.io/proxy-send-timeout: "600" # 后端服务器响应超时时间，默认为 60s nginx.ingress.kubernetes.io/proxy-read-timeout: "600" # 客户端上传文件，最大大小，默认为 20m nginx.ingress.kubernetes.io/proxy-body-size: "10m" # URL 重写 nginx.ingress.kubernetes.io/rewrite-target: /spec: # 路由规则 rules: # 主机名，只能是域名，修改为你自己的 - host: k8s.test.com http: paths: - path: backend: # 后台部署的 Service Name，与上面部署的 Tomcat 对应 serviceName: tomcat-http # 后台部署的 Service Port，与上面部署的 Tomcat 对应 servicePort: 8080 验证是否成功查看 Tomcat12345kubectl get deployment# 输出如下NAME READY UP-TO-DATE AVAILABLE AGEtomcat-app 2/2 2 2 88m 123456kubectl get service# 输出如下NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 2d5htomcat-http ClusterIP 10.97.222.179 &lt;none&gt; 8080/TCP 89m 查看 Nginx Ingress Controller12345kubectl get pods -n ingress-nginx -o wide# 输出如下，注意下面的 IP 地址，就是我们实际访问地址NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-ingress-controller-76f9fddcf8-vzkm5 1/1 Running 0 61m 192.168.141.160 kubernetes-node-01 &lt;none&gt; &lt;none&gt; 查看 Ingress12345kubectl get ingress# 输出如下NAME HOSTS ADDRESS PORTS AGEnginx-web k8s.test.com 80 61m 测试访问成功代理到 Tomcat 即表示成功 12# 不设置 Hosts 的方式请求地址，下面的 IP 和 Host 均在上面有配置curl -v http://192.168.141.160 -H 'host: k8s.test.com' 准备数据持久化在 Docker 中就有数据卷的概念，当容器删除时，数据也一起会被删除，想要持久化使用数据，需要把主机上的目录挂载到 Docker 中去，在 K8S 中，数据卷是通过 Pod 实现持久化的，如果 Pod 删除，数据卷也会一起删除，k8s 的数据卷是 docker 数据卷的扩展，K8S 适配各种存储系统，包括本地存储 EmptyDir，HostPath， 网络存储（NFS，GlusterFS，PV/PVC）等。 我们以部署 MySQL8 为例，采用 NFS + PV/PVC 网络存储方案实现我们的 Kubernetes 数据持久化。 什么是 NFSNFS 是 Network File System 的简写，即网络文件系统，NFS 是 FreeBSD 支持的文件系统中的一种。NFS 基于 RPC (Remote Procedure Call) 远程过程调用实现，其允许一个系统在网络上与它人共享目录和文件。通过使用 NFS，用户和程序就可以像访问本地文件一样访问远端系统上的文件。NFS 是一个非常稳定的，可移植的网络文件系统。具备可扩展和高性能等特性，达到了企业级应用质量标准。由于网络速度的增加和延迟的降低，NFS 系统一直是通过网络提供文件系统服务的有竞争力的选择 。 NFS 原理NFS 使用 RPC (Remote Procedure Call) 的机制进行实现，RPC 使得客户端可以调用服务端的函数。同时，由于有 VFS 的存在，客户端可以像使用其它普通文件系统一样使用 NFS 文件系统。经由操作系统的内核，将 NFS 文件系统的调用请求通过 TCP/IP 发送至服务端的 NFS 服务。NFS 服务器执行相关的操作，并将操作结果返回给客户端。 NFS 服务主要进程 rpc.nfsd：最主要的 NFS 进程，管理客户端是否可登录 rpc.mountd：挂载和卸载 NFS 文件系统，包括权限管理 rpc.lockd：非必要，管理文件锁，避免同时写出错 rpc.statd：非必要，检查文件一致性，可修复文件 NFS 的关键工具 主要配置文件：/etc/exports NFS 文件系统维护命令：/usr/bin/exportfs 共享资源的日志文件：/var/lib/nfs/*tab 客户端查询共享资源命令：/usr/sbin/showmount 端口配置：/etc/sysconfig/nfs NFS 服务端配置在 NFS 服务器端的主要配置文件为 /etc/exports 时，通过此配置文件可以设置共享文件目录。每条配置记录由 NFS 共享目录、NFS 客户端地址和参数这 3 部分组成，格式如下： 1[NFS 共享目录] [NFS 客户端地址 1 (参数 1, 参数 2, 参数 3……)] [客户端地址 2 (参数 1, 参数 2, 参数 3……)] NFS 共享目录：服务器上共享出去的文件目录 NFS 客户端地址：允许其访问的 NFS 服务器的客户端地址，可以是客户端 IP 地址，也可以是一个网段 (192.168.141.0/24) 访问参数：括号中逗号分隔项，主要是一些权限选项 访问权限参数 序号 选项 描述 1 ro 客户端对于共享文件目录为只读权限。默认 2 rw 客户端对于共享文件目录具有读写权限 用户映射参数 序号 选项 描述 1 root_squash 使客户端使用 root 账户访冋时，服务器映射为服务器本地的匿名账号 2 no_root_squash 客户端连接服务端时如果使用的是 root，那么也拥有对服务端分享的目录的 root 权限 3 all_squash 将所有客户端用户请求映射到匿名用户或用户组（nfsnobody) 4 no_all_squash 与上相反。默认 5 anonuid=xxx 将远程访问的所有用户都映射为匿名用户，并指定该用户为本地用户(UID=xxx) 6 anongid=xxx 将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户(GUI=xxx) 其它配置参数 序号 选项 描述 1 sync 同步写操作，数据写入存储设备后返回成功信息。默认 2 async 异步写提作，数据在未完全写入存储设备前就返回成功信息，实际还在内存， 3 wdelay 延迟写入选项，将多个写提请求合并后写入硬盘，减少 I/O 次数， NFS 非正常关闭数据可能丢失。默认 4 no_wdelay 与上相反，不与 async 同时生效，如果 NFS 服务器主要收到小且不相关的请求，该选项实际会降低性能 5 subtree 若输出目录是一个子目录，则 NFS 服务器将检查其父目录的权限。默认 6 no_subtree 即使输出目录是一个子目录， NFS 服务器也不检查其父目录的权限，这样可以提高效率 7 secure 限制客户端只能从小于 1024 的 TCP/IP 端口连接 NFS 服务器。默认 8 insecure 允许客户端从大于 1024 的 TCP/IP 端口连接服务器 安装 NFS 服务端由于 NFS 是一套分布式文件系统，我们再创建一台独立的虚拟机作为我们 NFS 服务端，配置如下 主机名 IP 系统 CPU/内存 磁盘 kubernetes-volumes 192.168.141.140 Ubuntu Server 18.04 2核2G 20G 创建一个目录作为共享文件目录 1mkdir -p /usr/local/kubernetes/volumes 给目录增加读写权限 1chmod a+rw /usr/local/kubernetes/volumes 安装 NFS 服务端 12apt-get updateapt-get install -y nfs-kernel-server 配置 NFS 服务目录，打开文件 1vi /etc/exports ，在尾部新增一行，内容如下 /usr/local/kubernetes/volumes：作为服务目录向客户端开放 *：表示任何 IP 都可以访问 rw：读写权限 sync：同步权限 no_subtree_check：表示如果输出目录是一个子目录，NFS 服务器不检查其父目录的权限 1/usr/local/kubernetes/volumes *(rw,sync,no_subtree_check) 重启服务，使配置生效 1/etc/init.d/nfs-kernel-server restart 安装 NFS 客户端安装客户端的目的是验证是否可以上传文件到服务端，安装命令如下 1apt-get install -y nfs-common 创建 NFS 客户端挂载目录 1mkdir -p /usr/local/kubernetes/volumes-mount 将 NFS 服务器的 /usr/local/kubernetes/volumes 目录挂载到 NFS 客户端的 /usr/local/kubernetes/volumes-mount 目录 1mount 192.168.141.140:/usr/local/kubernetes/volumes /usr/local/kubernetes/volumes-mount 使用 df 命令查看挂载信息 12345678910111213141516df# 输出如下Filesystem 1K-blocks Used Available Use% Mounted onudev 977556 0 977556 0% /devtmpfs 201732 1252 200480 1% /run/dev/mapper/ubuntu--vg-ubuntu--lv 19475088 5490916 12971848 30% /tmpfs 1008648 0 1008648 0% /dev/shmtmpfs 5120 0 5120 0% /run/locktmpfs 1008648 0 1008648 0% /sys/fs/cgroup/dev/loop0 90624 90624 0 100% /snap/core/6964/dev/loop1 93184 93184 0 100% /snap/core/6350/dev/sda2 999320 214252 716256 24% /boottmpfs 201728 0 201728 0% /run/user/0# 有此输出表示挂载成功193.192.168.141.140:/usr/local/kubernetes/volumes 19475200 5490944 12972032 30% /usr/local/kubernetes/volumes-mount 验证 NFS 服务 测试文件上传 1ip addr &gt; /usr/local/kubernetes/volumes-mount/test.txt 查看 /usr/local/kubernetes/volumes 目录下是否有 test.txt 文件，有则表示成功 取消 NFS 客户端挂载 注意： 不要直接在挂载目录下执行，否则会报错 1umount /usr/local/kubernetes/volumes-mount 实现数据持久化概述存储管理与计算管理是两个不同的问题。Persistent Volume 子系统，对存储的供应和使用做了抽象，以 API 形式提供给管理员和用户使用。要完成这一任务，我们引入了两个新的 API 资源：Persistent Volume（持久卷） 和 Persistent Volume Claim（持久卷消费者）。 Persistent Volume（PV）是集群之中的一块网络存储。跟 Node 一样，也是集群的资源。PV 跟 Volume (卷) 类似，不过会有独立于 Pod 的生命周期。这一 API 对象包含了存储的实现细节，例如 NFS、iSCSI 或者其他的云提供商的存储系统。Persistent Volume Claim (PVC) 是用户的一个请求。跟 Pod 类似，Pod 消费 Node 的资源，PVC 消费 PV 的资源。Pod 能够申请特定的资源（CPU 和内存）；Claim 能够请求特定的尺寸和访问模式（例如可以加载一个读写，以及多个只读实例） PV 与 PVCPV 是集群的资源。PVC 是对这一资源的请求，也是对资源的所有权的检验。PV 和 PVC 之间的互动遵循如下的生命周期。 供应： 集群管理员会创建一系列的 PV。这些 PV 包含了为集群用户提供的真实存储资源，它们可利用 Kubernetes API 来消费。 绑定： 用户创建一个包含了容量和访问模式的持久卷申请。Master 会监听 PVC 的产生，并尝试根据请求内容查找匹配的 PV，并把 PV 和 PVC 进行绑定。用户能够获取满足需要的资源，并且在使用过程中可能超出请求数量。如果找不到合适的卷，这一申请就会持续处于非绑定状态，一直到出现合适的 PV。例如一个集群准备了很多的 50G 大小的持久卷，（虽然总量足够）也是无法响应 100G 的申请的，除非把 100G 的 PV 加入集群。 使用： Pod 把申请作为卷来使用。集群会通过 PVC 查找绑定的 PV，并 Mount 给 Pod。对于支持多种访问方式的卷，用户在使用 PVC 作为卷的时候，可以指定需要的访问方式。一旦用户拥有了一个已经绑定的 PVC，被绑定的 PV 就归该用户所有了。用户的 Pods 能够通过在 Pod 的卷中包含的 PVC 来访问他们占有的 PV。 释放： 当用户完成对卷的使用时，就可以利用 API 删除 PVC 对象了，而且他还可以重新申请。删除 PVC 后，对应的卷被视为 “被释放”，但是这时还不能给其他的 PVC 使用。之前的 PVC 数据还保存在卷中，要根据策略来进行后续处理。 回收： PV 的回收策略向集群阐述了在 PVC 释放卷的时候，应如何进行后续工作。目前可以采用三种策略：保留，回收或者删除。保留策略允许重新申请这一资源。在持久卷能够支持的情况下，删除策略会同时删除持久卷以及 AWS EBS/GCE PD 或者 Cinder 卷中的存储内容。如果插件能够支持，回收策略会执行基础的擦除操作（rm -rf /thevolume/*），这一卷就能被重新申请了。 定义 PV持久卷插件持久卷是以插件方式实现的，目前支持的插件如下： GCEPersistentDisk AWSElasticBlockStore NFS（我们采用的是该方案） iSCSI RBD (Ceph Block Device) Glusterfs HostPath (单节点测试使用) 本地持久卷 YAML 配置创建一个名为 nfs-pv-mysql.yml 的配置文件 1234567891011121314151617181920apiVersion: v1kind: PersistentVolumemetadata: name: nfs-pv-mysqlspec: # 设置容量 capacity: storage: 5Gi # 访问模式 accessModes: # 该卷能够以读写模式被多个节点同时加载 - ReadWriteMany # 回收策略，这里是基础擦除 `rm-rf/thevolume/*` persistentVolumeReclaimPolicy: Recycle nfs: # NFS 服务端配置的路径 path: "/usr/local/kubernetes/volumes" # NFS 服务端地址 server: 192.168.141.140 readOnly: false 12345678# 部署kubectl create -f nfs-pv-mysql.yml# 删除kubectl delete -f nfs-pv-mysql.yml# 查看kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfs-pv-mysql 5Gi RWX Recycle Available 29m 配置说明Capacity（容量）一般来说，PV 会指定存储容量。这里需要使用 PV 的 capcity 属性。目前存储大小是唯一一个能够被申请的指标，今后会加入更多属性，例如 IOPS，吞吐能力等。 AccessModes（访问模式）只要资源提供者支持，持久卷能够被用任何方式加载到主机上。每种存储都会有不同的能力，每个 PV 的访问模式也会被设置成为该卷所支持的特定模式。例如 NFS 能够支持多个读写客户端，但是某个 NFS PV 可能会在服务器上以只读方式使用。每个 PV 都有自己的一系列的访问模式，这些访问模式取决于 PV 的能力。访问模式的可选范围如下： ReadWriteOnce：该卷能够以读写模式被加载到一个节点上 ReadOnlyMany：该卷能够以只读模式加载到多个节点上 ReadWriteMany：该卷能够以读写模式被多个节点同时加载 在 CLI 下，访问模式缩写为： RWO：ReadWriteOnce ROX：ReadOnlyMany RWX：ReadWriteMany 另外，一个卷不论支持多少种访问模式，同时只能以一种访问模式加载。例如一个 GCE Persistent Disk 既能支持 ReadWriteOnce，也能支持 ReadOnlyMany。 RecyclingPolicy（回收策略）当前的回收策略可选值包括： Retain：人工重新申请 Recycle：基础擦除（rm-rf/thevolume/*） Delete：相关的存储资产例如 AWS EBS，GCE PD 或者 OpenStack Cinder 卷一并删除 目前，只有 NFS 和 HostPath 支持 Recycle 策略，AWS EBS、GCE PD 以及 Cinder 卷支持 Delete 策略。 阶段（Phase）一个卷会处于如下阶段之一： Available：可用资源，尚未被绑定到 PVC 上 Bound：该卷已经被绑定 Released：PVC 已经被删除，但该资源尚未被集群回收 Failed：该卷的自动回收过程失败 定义 PVC创建一个名为 nfs-pvc-mysql-myshop.yml 的配置文件 123456789101112apiVersion: v1kind: PersistentVolumeClaimmetadata: name: nfs-pvc-mysql-myshopspec: accessModes: # 需要使用和 PV 一致的访问模式 - ReadWriteMany # 按需分配资源 resources: requests: storage: 1Gi 123456# 部署kubectl create -f nfs-pvc-mysql-myshop.yml# 删除kubectl delete -f nfs-pvc-mysql-myshop.yml# 查看kubectl get pvc 部署 MySQL8 注意： 要确保每台 Node 都安装了 NFS 客户端，apt-get install -y nfs-common 12345678910111213141516171819202122232425262728293031323334353637383940414243apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: mysql-myshopspec: replicas: 1 template: metadata: labels: name: mysql-myshop spec: containers: - name: mysql-myshop image: mysql # 只有镜像不存在时，才会进行镜像拉取 imagePullPolicy: IfNotPresent ports: - containerPort: 3306 # 同 Docker 配置中的 environment env: - name: MYSQL_ROOT_PASSWORD value: "123456" # 容器中的挂载目录 volumeMounts: - name: nfs-vol-myshop mountPath: /var/lib/mysql volumes: # 挂载到数据卷 - name: nfs-vol-myshop persistentVolumeClaim: claimName: nfs-pvc-mysql-myshop---apiVersion: v1kind: Servicemetadata: name: mysql-myshopspec: ports: - port: 3306 targetPort: 3306 type: LoadBalancer selector: name: mysql-myshop 解决权限问题当你使用 kubectl create -f &lt;YAML&gt; 部署后，你会发现 Pod 状态为 Error，容器无法正常启动的情况，我们可以使用 kubectl logs &lt;Pod Name&gt; 看到一条日志 1chown: changing ownership of &apos;/var/lib/mysql/&apos;: Operation not permitted 解决方案是在 NFS 服务端配置中增加一个参数 no_root_squash，即将配置修改为：/usr/local/kubernetes/volumes *(rw,sync,no_subtree_check,no_root_squash) 测试运行部署成功后可以使用 kubectl get service 查看我们 MySQL 的运行端口，再使用连接工具连接会报如下错误 意思为无法使用密码的方式登录，在 Docker 部署时我们可以在 YAML 中配置相关参数解决这个问题；下一节我们讲解在 Kubernetes 中采用 ConfigMap 的方式配置 MySQL 附：ImagePullPolicy支持三种 ImagePullPolicy Always： 不管镜像是否存在都会进行一次拉取 Never： 不管镜像是否存在都不会进行拉取 IfNotPresent： 只有镜像不存在时，才会进行镜像拉取 注意 默认为 IfNotPresent，但 :latest 标签的镜像默认为 Always 拉取镜像时 Docker 会进行校验，如果镜像中的 MD5 码没有变，则不会拉取镜像数据 生产环境中应该尽量避免使用 :latest 标签，而开发环境中可以借助 :latest 标签自动拉取最新的镜像 Kubernetes ConfigMap概述ConfigMap 是用来存储配置文件的 Kubernetes 资源对象，所有的配置内容都存储在 etcd 中。它可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制对象。ConfigMap API 资源提供了将配置数据注入容器的方式，同时保证该机制对容器来说是透明的。配置应该从 Image 内容中解耦，以此来保持容器化应用程序的可移植性。 使用 ConfigMap 配置 MySQL123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172apiVersion: v1kind: ConfigMapmetadata: name: mysql-myshop-configdata: # 这里是键值对数据 mysqld.cnf: | [client] port=3306 [mysql] no-auto-rehash [mysqld] skip-host-cache skip-name-resolve default-authentication-plugin=mysql_native_password character-set-server=utf8mb4 collation-server=utf8mb4_general_ci explicit_defaults_for_timestamp=true lower_case_table_names=1---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: mysql-myshopspec: replicas: 1 template: metadata: labels: name: mysql-myshop spec: containers: - name: mysql-myshop image: mysql imagePullPolicy: IfNotPresent ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: "123456" volumeMounts: # 以数据卷的形式挂载 MySQL 配置文件目录 - name: cm-vol-myshop mountPath: /etc/mysql/conf.d - name: nfs-vol-myshop mountPath: /var/lib/mysql volumes: # 将 ConfigMap 中的内容以文件形式挂载进数据卷 - name: cm-vol-myshop configMap: name: mysql-myshop-config items: # ConfigMap 中的 Key - key: mysqld.cnf # ConfigMap Key 匹配的 Value 写入名为 mysqld.cnf 的文件中 path: mysqld.cnf - name: nfs-vol-myshop persistentVolumeClaim: claimName: nfs-pvc-mysql-myshop---apiVersion: v1kind: Servicemetadata: name: mysql-myshopspec: ports: - port: 3306 targetPort: 3306 nodePort: 32036 type: LoadBalancer selector: name: mysql-myshop 123# 查看 ConfigMapkubectl get cmkubectl describe cm &lt;ConfigMap Name&gt; Kubernetes Dashboard本节视频Kubernetes Dashboard 是 Kubernetes 集群的 Web UI，用于管理集群。 安装GitHub 地址：Kubernetes Dashboard 下载配置文件 1wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml 修改配置如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# 省略部分代码...# ------------------- Dashboard Deployment ------------------- #kind: DeploymentapiVersion: apps/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: kubernetes-dashboard template: metadata: labels: k8s-app: kubernetes-dashboard spec: containers: - name: kubernetes-dashboard # 修改镜像地址为阿里云 image: registry.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1 ports: - containerPort: 8443 protocol: TCP args: - --auto-generate-certificates volumeMounts: - name: kubernetes-dashboard-certs mountPath: /certs - mountPath: /tmp name: tmp-volume livenessProbe: httpGet: scheme: HTTPS path: / port: 8443 initialDelaySeconds: 30 timeoutSeconds: 30 volumes: - name: kubernetes-dashboard-certs secret: secretName: kubernetes-dashboard-certs - name: tmp-volume emptyDir: &#123;&#125; serviceAccountName: kubernetes-dashboard tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule---# ------------------- Dashboard Service ------------------- #kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: # 修改类型为 NodePort 访问 type: NodePort ports: - port: 443 targetPort: 8443 # 设置端口号为 30001 nodePort: 30001 selector: k8s-app: kubernetes-dashboard 部署到集群 1234567# 部署kubectl create -f kubernetes-dashboard.yaml# 查看kubectl -n kube-system get podskubectl -n kube-system get service kubernetes-dashboardkubectl -n kube-system describe service kubernetes-dashboard 访问需要使用 NodeIP:30001 访问 Dashboard，因为证书原因除火狐浏览器外其它浏览器无法直接打开页面 Chrome 浏览器显示如下 Firefox 浏览器显示如下 点击 接受风险并继续 即可显示欢迎界面 登录我们采用 Token 方式登录 创建登录账号，创建一个名为 dashboard-adminuser.yaml 的配置文件 123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kube-system 1kubectl create -f dashboard-adminuser.yaml 打印 Token 信息 12345678910111213141516kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '&#123;print $1&#125;')# 输出如下Name: admin-user-token-86cz9Namespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: 3902d3d4-8b13-11e9-8089-000c29d49c77Type: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTg2Y3o5Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIzOTAyZDNkNC04YjEzLTExZTktODA4OS0wMDBjMjlkNDljNzciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pA44wyarsahOwqH7X7RVlcdB1k3_j-L3gwOYlTQ4_Lu5ZmfXDFlhqN-Q1tdryJes_V1Nj_utocnXBAxsGzOGaVR4Te4oli3htSepI9MrggQAyeC3C0_QANXGCE6V5L6B5tGZ6tDsY92VDnlvz2N6OrHaH2IJJd2DlxzYvAPvfAFuPeHWuPeVxUisMfXeW42S7US6skZwbZ06JrPYAFxHjqv3zoxRxI8-bmekltvOamsrL0pAXvIUzaowgbjiQb2NgeLAw9O6qfYcz5DAi2C-7G_yAcve6pgnWcIGhVpKoim9DfJUhe1SVx4H4X5Na6GVaaD6FdUIb7UOgsO1FVpTPw 将 Token 输入浏览器，成功登陆后效果如下 Kubernetes DashboardKubernetes Dashboard 是 Kubernetes 集群的 Web UI，用于管理集群。 安装GitHub 地址：Kubernetes Dashboard 下载配置文件 1wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml 修改配置如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# 省略部分代码...# ------------------- Dashboard Deployment ------------------- #kind: DeploymentapiVersion: apps/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: kubernetes-dashboard template: metadata: labels: k8s-app: kubernetes-dashboard spec: containers: - name: kubernetes-dashboard # 修改镜像地址为阿里云 image: registry.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1 ports: - containerPort: 8443 protocol: TCP args: - --auto-generate-certificates volumeMounts: - name: kubernetes-dashboard-certs mountPath: /certs - mountPath: /tmp name: tmp-volume livenessProbe: httpGet: scheme: HTTPS path: / port: 8443 initialDelaySeconds: 30 timeoutSeconds: 30 volumes: - name: kubernetes-dashboard-certs secret: secretName: kubernetes-dashboard-certs - name: tmp-volume emptyDir: &#123;&#125; serviceAccountName: kubernetes-dashboard tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule---# ------------------- Dashboard Service ------------------- #kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: # 修改类型为 NodePort 访问 type: NodePort ports: - port: 443 targetPort: 8443 # 设置端口号为 30001 nodePort: 30001 selector: k8s-app: kubernetes-dashboard 到集群 1234567# 部署kubectl create -f kubernetes-dashboard.yaml# 查看kubectl -n kube-system get podskubectl -n kube-system get service kubernetes-dashboardkubectl -n kube-system describe service kubernetes-dashboard 访问需要使用 NodeIP:30001 访问 Dashboard，因为证书原因除火狐浏览器外其它浏览器无法直接打开页面 Chrome 浏览器显示如下 Firefox 浏览器显示如下 点击 接受风险并继续 即可显示欢迎界面 登录我们采用 Token 方式登录 创建登录账号，创建一个名为 dashboard-adminuser.yaml 的配置文件 123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kube-system 1kubectl create -f dashboard-adminuser.yaml 打印 Token 信息 12345678910111213141516kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '&#123;print $1&#125;')# 输出如下Name: admin-user-token-86cz9Namespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: 3902d3d4-8b13-11e9-8089-000c29d49c77Type: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTg2Y3o5Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIzOTAyZDNkNC04YjEzLTExZTktODA4OS0wMDBjMjlkNDljNzciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pA44wyarsahOwqH7X7RVlcdB1k3_j-L3gwOYlTQ4_Lu5ZmfXDFlhqN-Q1tdryJes_V1Nj_utocnXBAxsGzOGaVR4Te4oli3htSepI9MrggQAyeC3C0_QANXGCE6V5L6B5tGZ6tDsY92VDnlvz2N6OrHaH2IJJd2DlxzYvAPvfAFuPeHWuPeVxUisMfXeW42S7US6skZwbZ06JrPYAFxHjqv3zoxRxI8-bmekltvOamsrL0pAXvIUzaowgbjiQb2NgeLAw9O6qfYcz5DAi2C-7G_yAcve6pgnWcIGhVpKoim9DfJUhe1SVx4H4X5Na6GVaaD6FdUIb7UOgsO1FVpTPw 将 Token 输入浏览器，成功登陆后效果如下 Kubectl 常用命令 小提示： 所有命令前都可以加上 watch 命令来观察状态的实时变化，如：watch kubectl get pods --all-namespaces 查看组件状态1kubectl get cs 查看环境信息1kubectl cluster-info 查看 Node1kubectl get nodes -o wide 查看集群配置1kubectl -n kube-system get cm kubeadm-config -oyaml 运行容器1kubectl run nginx --image=nginx --replicas=2 --port=80 暴露服务1kubectl expose deployment nginx --port=80 --type=LoadBalancer 查看命名空间1kubectl get namespace 创建命名空间1234apiVersion: v1kind: Namespacemetadata: name: development 查看容器12kubectl get pods -o widekubectl get deployment -o wide 查看服务1kubectl get service -o wide 查看详情123kubectl describe pod &lt;Pod Name&gt;kubectl describe deployment &lt;Deployment Name&gt;kubectl describe service &lt;Service Name&gt; 查看日志1kubectl logs -f &lt;Pod Name&gt; 删除容器和服务12kubectl delete deployment &lt;Deployment Name&gt;kubectl delete service &lt;Service Name&gt; 配置方式运行1kubectl create -f &lt;YAML&gt; 配置方式删除1kubectl delete -f &lt;YAML&gt; 查看配置12kubeadm config viewkubectl config view 查看 Ingress1kubectl get ingress 查看持久卷1kubectl get pv 查看持久卷消费者1kubectl get pvc 查看 ConfigMap1kubectl get cm &lt;ConfigMap Name&gt; 修改 ConfigMap1kubectl edit cm &lt;ConfigMap Name&gt;]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
</search>
