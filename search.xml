<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fblog%2F2019%2F08%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[oAuth2]]></title>
    <url>%2Fblog%2F2019%2F08%2F13%2F%E4%BA%91%E8%AE%A1%E7%AE%97%2FoAuth2%2F</url>
    <content type="text"><![CDATA[一、什么是 oAuth2oAuth 协议为用户资源的授权提供了一个安全的、开放而又简易的标准。与以往的授权方式不同之处是 oAuth 的授权不会使第三方触及到用户的帐号信息（如用户名与密码），即第三方无需使用用户的用户名与密码就可以申请获得该用户资源的授权，因此 oAuth 是安全的。二、什么是 Spring Security Spring Security 是一个安全框架，前身是 Acegi Security，能够为 Spring 企业应用系统提供声明式的安全访问控制。Spring Security 基于 Servlet 过滤器、IoC 和 AOP，为 Web 请求和方法调用提供身份确认和授权处理，避免了代码耦合，减少了大量重复代码工作。 三、为什么需要 oAuth21、应用场景我们假设你有一个“云笔记”产品，并提供了“云笔记服务”和“云相册服务”，此时用户需要在不同的设备（PC、Android、iPhone、TV、Watch）上去访问这些“资源”（笔记，图片），一切皆资源（restfull）。 那么用户如何才能访问属于自己的那部分资源呢？此时传统的做法就是提供自己的账号和密码给我们的“云笔记”，登录成功后就可以获取资源了。但这样的做法会有以下几个问题： “云笔记服务”和“云相册服务”会分别部署，难道我们要分别登录吗？ 如果有第三方应用程序想要接入我们的“云笔记”，难道需要用户提供账号和密码给第三方应用程序，让他记录后再访问我们的资源吗？ 用户如何限制第三方应用程序在我们“云笔记”的授权范围和使用期限？难道把所有资料都永久暴露给它吗？ 如果用户修改了密码收回了权限，那么所有第三方应用程序会全部失效。 只要有一个接入的第三方应用程序遭到破解，那么用户的密码就会泄露，后果不堪设想。 为了解决如上问题，oAuth 应用而生。 2、名词解释 第三方应用程序（Third-party application）： 又称之为客户端（client），比如上节中提到的设备（PC、Android、iPhone、TV、Watch），我们会在这些设备中安装我们自己研发的 APP。又比如我们的产品想要使用 QQ、微信等第三方登录。对我们的产品来说，QQ、微信登录是第三方登录系统。我们又需要第三方登录系统的资源（头像、昵称等）。对于 QQ、微信等系统我们又是第三方应用程序。 HTTP 服务提供商（HTTP service）： 我们的云笔记产品以及 QQ、微信等都可以称之为“服务提供商”。 资源所有者（Resource Owner）： 又称之为用户（user）。 用户代理（User Agent）： 比如浏览器，代替用户去访问这些资源。 认证服务器（Authorization server）： 即服务提供商专门用来处理认证的服务器，简单点说就是登录功能（验证用户的账号密码是否正确以及分配相应的权限） 资源服务器（Resource server）： 即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。简单点说就是资源的访问入口，比如上节中提到的“云笔记服务”和“云相册服务”都可以称之为资源服务器。 四、交互过程oAuth 在 “客户端” 与 “服务提供商” 之间，设置了一个授权层（authorization layer）。”客户端” 不能直接登录 “服务提供商”，只能登录授权层，以此将用户与客户端区分开来。”客户端” 登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。”客户端” 登录授权层以后，”服务提供商” 根据令牌的权限范围和有效期，向 “客户端” 开放用户储存的资料。 五、交互模型交互模型涉及三方： 资源拥有者：用户 客户端：APP 服务提供方：包含两个角色 认证服务器 资源服务器 六、认证服务器认证服务器负责对用户进行认证，并授权给客户端权限。认证很容易实现（验证账号密码即可），问题在于如何授权。比如我们使用第三方登录 “有道云笔记”，你可以看到如使用 QQ 登录的授权页面上有 “有道云笔记将获得以下权限” 的字样以及权限信息 认证服务器需要知道请求授权的客户端的身份以及该客户端请求的权限。我们可以为每一个客户端预先分配一个 id，并给每个 id 对应一个名称以及权限信息。这些信息可以写在认证服务器上的配置文件里。然后，客户端每次打开授权页面的时候，把属于自己的 id 传过来，如： 1http://www.funtl.com/login?client_id=yourClientId 随着时间的推移和业务的增长，会发现，修改配置的工作消耗了太多的人力。有没有办法把这个过程自动化起来，把人工从这些繁琐的操作中解放出来？当开始考虑这一步，开放平台的成型也就是水到渠成的事情了。 六、oAuth2 开放平台开放平台是由 oAuth2.0 协议衍生出来的一个产品。它的作用是让客户端自己去这上面进行注册、申请，通过之后系统自动分配 client_id ，并完成配置的自动更新（通常是写进数据库）。 客户端要完成申请，通常需要填写客户端程序的类型（Web、App 等）、企业介绍、执照、想要获取的权限等等信息。这些信息在得到服务提供方的人工审核通过后，开发平台就会自动分配一个 client_id 给客户端了。 到这里，已经实现了登录认证、授权页的信息展示。那么接下来，当用户成功进行授权之后，认证服务器需要把产生的 access_token 发送给客户端，方案如下： 让客户端在开放平台申请的时候，填写一个 URL，例如：http://www.funtl.com 每次当有用户授权成功之后，认证服务器将页面重定向到这个 URL（回调），并带上 access_token，例如：http://www.funtl.com?access_token=123456789 客户端接收到了这个 access_token，而且认证服务器的授权动作已经完成，刚好可以把程序的控制权转交回客户端，由客户端决定接下来向用户展示什么内容 七、令牌的访问与刷新1、Access TokenAccess Token 是客户端访问资源服务器的令牌。拥有这个令牌代表着得到用户的授权。然而，这个授权应该是 临时 的，有一定有效期。这是因为，Access Token 在使用的过程中 可能会泄露。给 Access Token 限定一个 较短的有效期 可以降低因 Access Token 泄露而带来的风险。 然而引入了有效期之后，客户端使用起来就不那么方便了。每当 Access Token 过期，客户端就必须重新向用户索要授权。这样用户可能每隔几天，甚至每天都需要进行授权操作。这是一件非常影响用户体验的事情。希望有一种方法，可以避免这种情况。 于是 oAuth2.0 引入了 Refresh Token 机制 2、Refresh TokenRefresh Token 的作用是用来刷新 Access Token。认证服务器提供一个刷新接口，例如： 1http://www.funtl.com/refresh?refresh_token=&amp;client_id= 传入 refresh_token 和 client_id，认证服务器验证通过后，返回一个新的 Access Token。为了安全，oAuth2.0 引入了两个措施： oAuth2.0 要求，Refresh Token 一定是保存在客户端的服务器上 ，而绝不能存放在狭义的客户端（例如 App、PC 端软件）上。调用 refresh 接口的时候，一定是从服务器到服务器的访问。 oAuth2.0 引入了 client_secret 机制。即每一个 client_id 都对应一个 client_secret。这个 client_secret 会在客户端申请 client_id 时，随 client_id 一起分配给客户端。客户端必须把 client_secret 妥善保管在服务器上，决不能泄露。刷新 Access Token 时，需要验证这个 client_secret。 实际上的刷新接口类似于： 1http://www.funtl.com/refresh?refresh_token=&amp;client_id=&amp;client_secret= 以上就是 Refresh Token 机制。Refresh Token 的有效期非常长，会在用户授权时，随 Access Token 一起重定向到回调 URL，传递给客户端。 八、客户端授权模式1、概述客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。oAuth 2.0 定义了四种授权方式。 implicit：简化模式，不推荐使用 authorization code：授权码模式 resource owner password credentials：密码模式 client credentials：客户端模式 2、简化模式简化模式适用于纯静态页面应用。所谓纯静态页面应用，也就是应用没有在服务器上执行代码的权限（通常是把代码托管在别人的服务器上），只有前端 JS 代码的控制权。 这种场景下，应用是没有持久化存储的能力的。因此，按照 oAuth2.0 的规定，这种应用是拿不到 Refresh Token 的。其整个授权流程如下： 该模式下，access_token 容易泄露且不可刷新 3、授权码模式授权码模式适用于有自己的服务器的应用，它是一个一次性的临时凭证，用来换取 access_token 和 refresh_token。认证服务器提供了一个类似这样的接口： 你用一开始的操作首先是获取了一个code，然后再用code获取token 1https://www.funtl.com/exchange?code=&amp;client_id=&amp;client_secret= 需要传入 code、client_id 以及 client_secret。验证通过后，返回 access_token 和 refresh_token。一旦换取成功，code 立即作废，不能再使用第二次。流程图如下： ​ 这个 code 的作用是保护 token 的安全性。上一节说到，简单模式下，token 是不安全的。这是因为在第 4 步当中直接把 token 返回给应用。而这一步容易被拦截、窃听。引入了 code 之后，即使攻击者能够窃取到 code，但是由于他无法获得应用保存在服务器的 `client_secret`，因此也无法通过 code 换取 token。而第 5 步，为什么不容易被拦截、窃听呢？这是因为，首先，这是一个从服务器到服务器的访问，黑客比较难捕捉到；其次，这个请求通常要求是 https 的实现。即使能窃听到数据包也无法解析出内容。 有了这个 code，token 的安全性大大提高。因此，oAuth2.0 鼓励使用这种方式进行授权，而简单模式则是在不得已情况下才会使用。 4、密码模式密码模式中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向 “服务商提供商” 索要授权。在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分。 一个典型的例子是同一个企业内部的不同产品要使用本企业的 oAuth2.0 体系。在有些情况下，产品希望能够定制化授权页面。由于是同个企业，不需要向用户展示“xxx将获取以下权限”等字样并询问用户的授权意向，而只需进行用户的身份认证即可。这个时候，由具体的产品团队开发定制化的授权界面，接收用户输入账号密码，并直接传递给鉴权服务器进行授权即可。 有一点需要特别注意的是，在第 2 步中，认证服务器需要对客户端的身份进行验证，确保是受信任的客户端。 5、客户端模式如果信任关系再进一步，或者调用者是一个后端的模块，没有用户界面的时候，可以使用客户端模式。鉴权服务器直接对客户端进行身份验证，验证通过后，返回 token。 九、基于Spring Security oAuth21、创建案例工程项目123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-samples&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;modules&gt; &lt;!-- 工程模块请随着项目的不断完善自行添加 --&gt; &lt;/modules&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;maven.compiler.source&gt;$&#123;java.version&#125;&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;$&#123;java.version&#125;&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;/properties&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-samples-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;default&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;spring-javaformat.version&gt;0.0.7&lt;/spring-javaformat.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.spring.javaformat&lt;/groupId&gt; &lt;artifactId&gt;spring-javaformat-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-javaformat.version&#125;&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt;**/*Tests.java&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/Abstract*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;systemPropertyVariables&gt; &lt;java.security.egd&gt;file:/dev/./urandom&lt;/java.security.egd&gt; &lt;java.awt.headless&gt;true&lt;/java.awt.headless&gt; &lt;/systemPropertyVariables&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-enforcer-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;enforce-rules&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;enforce&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;rules&gt; &lt;bannedDependencies&gt; &lt;excludes&gt; &lt;exclude&gt;commons-logging:*:*&lt;/exclude&gt; &lt;/excludes&gt; &lt;searchTransitive&gt;true&lt;/searchTransitive&gt; &lt;/bannedDependencies&gt; &lt;/rules&gt; &lt;fail&gt;true&lt;/fail&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;name&gt;Spring Milestone&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;name&gt;Spring Milestone&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; 2、创建统一的依赖管理模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-samples-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;properties&gt; &lt;spring-cloud.version&gt;Greenwich.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;name&gt;Spring Milestone&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;name&gt;Spring Milestone&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; 3、创建 oAuth2 案例模块1234567891011121314151617181920212223242526272829303132333435&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-samples&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;modules&gt; &lt;!-- 工程模块请随着项目的不断完善自行添加 --&gt; &lt;/modules&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt;&lt;/project&gt; 4、创建认证服务器模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-security-oauth2-server&lt;/artifactId&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencies&gt; &lt;!-- Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.oauth2.OAuth2ServerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 5、Application123456789101112131415161718192021222324package com.funtl.oauth2;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * 认证服务器，用于获取 Token * &lt;p&gt; * Description: * &lt;/p&gt; * * @author Lusifer * @version v1.0.0 * @date 2019-04-01 16:06:45 * @see com.funtl.oauth2 */@SpringBootApplicationpublic class OAuth2ServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OAuth2ServerApplication.class, args); &#125;&#125; 6、基于内存存储令牌1、概述本章节基于 内存存储令牌 的模式用于演示最基本的操作，帮助大家快速理解 oAuth2 认证服务器中 “认证”、”授权”、”访问令牌” 的基本概念 2、操作流程 配置认证服务器 配置客户端信息： 1ClientDetailsServiceConfigurer inMemory：内存配置 withClient：客户端标识 secret：客户端安全码 authorizedGrantTypes：客户端授权类型 scopes：客户端授权范围 redirectUris：注册回调地址 配置 Web 安全 通过 GET 请求访问认证服务器获取授权码 端点：/oauth/authorize 通过 POST 请求利用授权码访问认证服务器获取令牌 端点：/oauth/token 附：默认的端点 URL /oauth/authorize：授权端点 /oauth/token：令牌端点 /oauth/confirm_access：用户确认授权提交端点 /oauth/error：授权服务错误信息端点 /oauth/check_token：用于资源服务访问的令牌解析端点 /oauth/token_key：提供公有密匙的端点，如果你使用 JWT 令牌的话 6、配置认证服务器创建一个类继承 AuthorizationServerConfigurerAdapter 并添加相关注解： @Configuration @EnableAuthorizationServer 12345678910111213141516171819202122232425262728package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;@Configuration@EnableAuthorizationServerpublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; // 配置客户端 clients // 使用内存设置 .inMemory() // client_id .withClient("client") // client_secret .secret("secret") // 授权类型 .authorizedGrantTypes("authorization_code") // 授权范围 .scopes("app") // 注册回调地址 .redirectUris("http://www.funtl.com"); &#125;&#125; 7、服务器安全配置创建一个类继承 WebSecurityConfigurerAdapter 并添加相关注解： @Configuration @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)：全局方法拦截 12345678910111213package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123;&#125; 8、application.yml123456789101112spring: application: name: oauth2-server security: user: # 账号 name: root # 密码 password: 123456server: port: 8080 9、访问获取授权码打开浏览器，输入地址： 1http://localhost:8080/oauth/authorize?client_id=client&amp;response_type=code 第一次访问会跳转到登录页面 验证成功后会询问用户是否授权客户端 选择授权后会跳转到我的博客，浏览器地址上还会包含一个授权码（code=1JuO6V），浏览器地址栏会显示如下地址： 1http://www.funtl.com/?code=1JuO6V 有了这个授权码就可以获取访问令牌了 10、通过授权码向服务器申请令牌通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 注意：此时无法请求到令牌，访问服务器会报错 There is no PasswordEncoder mapped for the id “null”解决方案请移步 这里 （1）问题描述按照 基于内存存储令牌 配置成功后，携授权码使用 POST 请求认证服务器时，服务器返回错误信息 版本 Spring Boot: 2.1.3.RELEASE Spring Security: 5.1.4.RELEASE 日志 1java.lang.IllegalArgumentException: There is no PasswordEncoder mapped for the id &quot;null&quot; （2）解决方案Spring Security 5.0 之前版本的 PasswordEncoder 接口默认实现为 NoOpPasswordEncoder 此时是可以使用明文密码的，在 5.0 之后默认实现类改为 DelegatingPasswordEncoder 此时密码必须以加密形式存储。 （3）application.yml删除 spring.security 相关配置，修改为 123456spring: application: name: oauth2-serverserver: port: 8080 （4）WebSecurityConfiguration1234567891011121314151617181920212223242526272829303132package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication() // 在内存中创建用户并为密码加密 .withUser("user").password(passwordEncoder().encode("123456")).roles("USER") .and() .withUser("admin").password(passwordEncoder().encode("123456")).roles("ADMIN"); &#125;&#125; （5）AuthorizationServerConfiguration123456789101112131415161718192021222324252627282930package com.funtl.oauth2.server.config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;@Configuration@EnableAuthorizationServerpublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; // 注入 WebSecurityConfiguration 中配置的 BCryptPasswordEncoder @Autowired private BCryptPasswordEncoder passwordEncoder; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; clients .inMemory() .withClient("client") // 还需要为 secret 加密 .secret(passwordEncoder.encode("secret")) .authorizedGrantTypes("authorization_code") .scopes("app") .redirectUris("http://www.funtl.com"); &#125;&#125; （6）测试访问通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 1 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; 11、基于 JDBC 存储令牌本章节 基于 JDBC 存储令牌 的模式用于演示最基本的操作，帮助大家快速理解 oAuth2 认证服务器中 “认证”、”授权”、”访问令牌” 的基本概念 操作流程 初始化 oAuth2 相关表 在数据库中配置客户端 配置认证服务器 配置数据源：DataSource 配置令牌存储方式：TokenStore -&gt; JdbcTokenStore 配置客户端读取方式：ClientDetailsService -&gt; JdbcClientDetailsService 配置服务端点信息： 1AuthorizationServerEndpointsConfigurer tokenStore：设置令牌存储方式 配置客户端信息： 1ClientDetailsServiceConfigurer withClientDetails：设置客户端配置读取方式 配置 Web 安全 配置密码加密方式：BCryptPasswordEncoder 配置认证信息：AuthenticationManagerBuilder 通过 GET 请求访问认证服务器获取授权码 端点：/oauth/authorize 通过 POST 请求利用授权码访问认证服务器获取令牌 端点：/oauth/token 附：默认的端点 URL /oauth/authorize：授权端点 /oauth/token：令牌端点 /oauth/confirm_access：用户确认授权提交端点 /oauth/error：授权服务错误信息端点 /oauth/check_token：用于资源服务访问的令牌解析端点 /oauth/token_key：提供公有密匙的端点，如果你使用 JWT 令牌的话 （1）初始化 oAuth2 相关表使用官方提供的建表脚本初始化 oAuth2 相关表，地址如下： 1https://github.com/spring-projects/spring-security-oauth/blob/master/spring-security-oauth2/src/test/resources/schema.sql 由于我们使用的是 MySQL 数据库，默认建表语句中主键为 VARCHAR(256)，这超过了最大的主键长度，请手动修改为 128，并用 BLOB 替换语句中的 LONGVARBINARY 类型，修改后的建表脚本如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869CREATE TABLE `clientdetails` ( `appId` varchar(128) NOT NULL, `resourceIds` varchar(256) DEFAULT NULL, `appSecret` varchar(256) DEFAULT NULL, `scope` varchar(256) DEFAULT NULL, `grantTypes` varchar(256) DEFAULT NULL, `redirectUrl` varchar(256) DEFAULT NULL, `authorities` varchar(256) DEFAULT NULL, `access_token_validity` int(11) DEFAULT NULL, `refresh_token_validity` int(11) DEFAULT NULL, `additionalInformation` varchar(4096) DEFAULT NULL, `autoApproveScopes` varchar(256) DEFAULT NULL, PRIMARY KEY (`appId`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_access_token` ( `token_id` varchar(256) DEFAULT NULL, `token` blob, `authentication_id` varchar(128) NOT NULL, `user_name` varchar(256) DEFAULT NULL, `client_id` varchar(256) DEFAULT NULL, `authentication` blob, `refresh_token` varchar(256) DEFAULT NULL, PRIMARY KEY (`authentication_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_approvals` ( `userId` varchar(256) DEFAULT NULL, `clientId` varchar(256) DEFAULT NULL, `scope` varchar(256) DEFAULT NULL, `status` varchar(10) DEFAULT NULL, `expiresAt` timestamp NULL DEFAULT NULL, `lastModifiedAt` timestamp NULL DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_client_details` ( `client_id` varchar(128) NOT NULL, `resource_ids` varchar(256) DEFAULT NULL, `client_secret` varchar(256) DEFAULT NULL, `scope` varchar(256) DEFAULT NULL, `authorized_grant_types` varchar(256) DEFAULT NULL, `web_server_redirect_uri` varchar(256) DEFAULT NULL, `authorities` varchar(256) DEFAULT NULL, `access_token_validity` int(11) DEFAULT NULL, `refresh_token_validity` int(11) DEFAULT NULL, `additional_information` varchar(4096) DEFAULT NULL, `autoapprove` varchar(256) DEFAULT NULL, PRIMARY KEY (`client_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_client_token` ( `token_id` varchar(256) DEFAULT NULL, `token` blob, `authentication_id` varchar(128) NOT NULL, `user_name` varchar(256) DEFAULT NULL, `client_id` varchar(256) DEFAULT NULL, PRIMARY KEY (`authentication_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_code` ( `code` varchar(256) DEFAULT NULL, `authentication` blob) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `oauth_refresh_token` ( `token_id` varchar(256) DEFAULT NULL, `token` blob, `authentication` blob) ENGINE=InnoDB DEFAULT CHARSET=utf8; （2）在数据库中配置客户端在表 oauth_client_details 中增加一条客户端配置记录，需要设置的字段如下： client_id：客户端标识 client_secret：客户端安全码，此处不能是明文，需要加密 scope：客户端授权范围 authorized_grant_types：客户端授权类型 web_server_redirect_uri：服务器回调地址 使用 BCryptPasswordEncoder 为客户端安全码加密，代码如下： 1System.out.println(new BCryptPasswordEncoder().encode("secret")); 数据库配置客户端效果图如下： 由于使用了 JDBC 存储，我们需要增加相关依赖，数据库连接池部分弃用 Druid 改为 HikariCP （号称全球最快连接池） 123456789101112131415161718192021&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;$&#123;hikaricp.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 排除 tomcat-jdbc 以使用 HikariCP --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt;&lt;/dependency&gt; （3）配置认证服务器创建一个类继承 AuthorizationServerConfigurerAdapter 并添加相关注解： @Configuration @EnableAuthorizationServer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.funtl.oauth2.server.config;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.jdbc.DataSourceBuilder;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer;import org.springframework.security.oauth2.provider.ClientDetailsService;import org.springframework.security.oauth2.provider.client.JdbcClientDetailsService;import org.springframework.security.oauth2.provider.token.TokenStore;import org.springframework.security.oauth2.provider.token.store.JdbcTokenStore;import javax.sql.DataSource;@Configuration@EnableAuthorizationServerpublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; @Bean @Primary @ConfigurationProperties(prefix = "spring.datasource") public DataSource dataSource() &#123; // 配置数据源（注意，我使用的是 HikariCP 连接池），以上注解是指定数据源，否则会有冲突 return DataSourceBuilder.create().build(); &#125; @Bean public TokenStore tokenStore() &#123; // 基于 JDBC 实现，令牌保存到数据 return new JdbcTokenStore(dataSource()); &#125; @Bean public ClientDetailsService jdbcClientDetails() &#123; // 基于 JDBC 实现，需要事先在数据库配置客户端信息 return new JdbcClientDetailsService(dataSource()); &#125; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; // 设置令牌 endpoints.tokenStore(tokenStore()); &#125; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; // 读取客户端配置 clients.withClientDetails(jdbcClientDetails()); &#125;&#125; （4）服务器安全配置创建一个类继承 WebSecurityConfigurerAdapter 并添加相关注解： @Configuration @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)：全局方法拦截 1234567891011121314151617181920212223242526272829303132package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication() // 在内存中创建用户并为密码加密 .withUser("user").password(passwordEncoder().encode("123456")).roles("USER") .and() .withUser("admin").password(passwordEncoder().encode("123456")).roles("ADMIN"); &#125;&#125; （5）application.yml123456789101112131415161718192021spring: application: name: oauth2-server datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://192.168.141.128:3307/oauth2?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 hikari: minimum-idle: 5 idle-timeout: 600000 maximum-pool-size: 10 auto-commit: true pool-name: MyHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1server: port: 8080 （6）访问获取授权码打开浏览器，输入地址： 1http://localhost:8080/oauth/authorize?client_id=client&amp;response_type=code 第一次访问会跳转到登录页面 验证成功后会询问用户是否授权客户端 选择授权后会跳转到我的博客，浏览器地址上还会包含一个授权码（code=1JuO6V），浏览器地址栏会显示如下地址： 1http://www.funtl.com/?code=1JuO6V 有了这个授权码就可以获取访问令牌了 （7）通过授权码向服务器申请令牌通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 1 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; 操作成功后数据库 oauth_access_token 表中会增加一笔记录，效果图如下： 十、RBAC 基于角色的权限控制RBAC（Role-Based Access Control，基于角色的访问控制），就是用户通过角色与权限进行关联。简单地说，一个用户拥有若干角色，每一个角色拥有若干权限。这样，就构造成“用户-角色-权限”的授权模型。在这种模型中，用户与角色之间，角色与权限之间，一般是多对多的关系。（如下图） 1、目的在我们的 oAuth2 系统中，我们需要对系统的所有资源进行权限控制，系统中的资源包括： 静态资源（对象资源）：功能操作、数据列 动态资源（数据资源）：数据 系统的目的就是对应用系统的所有对象资源和数据资源进行权限控制，比如：功能菜单、界面按钮、数据显示的列、各种行级数据进行权限的操控 2、对象关系3、权限系统的所有权限信息。权限具有上下级关系，是一个树状的结构。如： 系统管理 用户管理 查看用户 新增用户 修改用户 删除用户 4、用户系统的具体操作者，可以归属于一个或多个角色，它与角色的关系是多对多的关系 5、角色为了对许多拥有相似权限的用户进行分类管理，定义了角色的概念，例如系统管理员、管理员、用户、访客等角色。角色具有上下级关系，可以形成树状视图，父级角色的权限是自身及它的所有子角色的权限的综合。父级角色的用户、父级角色的组同理可推。 6、关系图 7、模块图8、表结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950CREATE TABLE `tb_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父权限', `name` varchar(64) NOT NULL COMMENT '权限名称', `enname` varchar(64) NOT NULL COMMENT '权限英文名称', `url` varchar(255) NOT NULL COMMENT '授权路径', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='权限表';CREATE TABLE `tb_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父角色', `name` varchar(64) NOT NULL COMMENT '角色名称', `enname` varchar(64) NOT NULL COMMENT '角色英文名称', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='角色表';CREATE TABLE `tb_role_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `role_id` bigint(20) NOT NULL COMMENT '角色 ID', `permission_id` bigint(20) NOT NULL COMMENT '权限 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='角色权限表';CREATE TABLE `tb_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `username` varchar(50) NOT NULL COMMENT '用户名', `password` varchar(64) NOT NULL COMMENT '密码，加密存储', `phone` varchar(20) DEFAULT NULL COMMENT '注册手机号', `email` varchar(50) DEFAULT NULL COMMENT '注册邮箱', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`) USING BTREE, UNIQUE KEY `phone` (`phone`) USING BTREE, UNIQUE KEY `email` (`email`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='用户表';CREATE TABLE `tb_user_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `user_id` bigint(20) NOT NULL COMMENT '用户 ID', `role_id` bigint(20) NOT NULL COMMENT '角色 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8 COMMENT='用户角色表'; 十一、基于 RBAC 的自定义认证在实际开发中，我们的用户信息都是存在数据库里的，本章节基于 RBAC 模型 将用户的认证信息与数据库对接，实现真正的用户认证与授权 操作流程 继续 基于 JDBC 存储令牌 章节的代码开发 初始化 RBAC 相关表 在数据库中配置“用户”、“角色”、“权限”相关信息 数据库操作使用 tk.mybatis 框架，故需要增加相关依赖 配置 Web 安全 配置使用自定义认证与授权 通过 GET 请求访问认证服务器获取授权码 端点：/oauth/authorize 通过 POST 请求利用授权码访问认证服务器获取令牌 端点：/oauth/token 附：默认的端点 URL /oauth/authorize：授权端点 /oauth/token：令牌端点 /oauth/confirm_access：用户确认授权提交端点 /oauth/error：授权服务错误信息端点 /oauth/check_token：用于资源服务访问的令牌解析端点 /oauth/token_key：提供公有密匙的端点，如果你使用 JWT 令牌的话 1、初始化 RBAC 相关表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970CREATE TABLE `tb_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父权限', `name` varchar(64) NOT NULL COMMENT '权限名称', `enname` varchar(64) NOT NULL COMMENT '权限英文名称', `url` varchar(255) NOT NULL COMMENT '授权路径', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=44 DEFAULT CHARSET=utf8 COMMENT='权限表';insert into `tb_permission`(`id`,`parent_id`,`name`,`enname`,`url`,`description`,`created`,`updated`) values (37,0,'系统管理','System','/',NULL,'2019-04-04 23:22:54','2019-04-04 23:22:56'),(38,37,'用户管理','SystemUser','/users/',NULL,'2019-04-04 23:25:31','2019-04-04 23:25:33'),(39,38,'查看用户','SystemUserView','',NULL,'2019-04-04 15:30:30','2019-04-04 15:30:43'),(40,38,'新增用户','SystemUserInsert','',NULL,'2019-04-04 15:30:31','2019-04-04 15:30:44'),(41,38,'编辑用户','SystemUserUpdate','',NULL,'2019-04-04 15:30:32','2019-04-04 15:30:45'),(42,38,'删除用户','SystemUserDelete','',NULL,'2019-04-04 15:30:48','2019-04-04 15:30:45');CREATE TABLE `tb_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父角色', `name` varchar(64) NOT NULL COMMENT '角色名称', `enname` varchar(64) NOT NULL COMMENT '角色英文名称', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='角色表';insert into `tb_role`(`id`,`parent_id`,`name`,`enname`,`description`,`created`,`updated`) values (37,0,'超级管理员','admin',NULL,'2019-04-04 23:22:03','2019-04-04 23:22:05');CREATE TABLE `tb_role_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `role_id` bigint(20) NOT NULL COMMENT '角色 ID', `permission_id` bigint(20) NOT NULL COMMENT '权限 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=43 DEFAULT CHARSET=utf8 COMMENT='角色权限表';insert into `tb_role_permission`(`id`,`role_id`,`permission_id`) values (37,37,37),(38,37,38),(39,37,39),(40,37,40),(41,37,41),(42,37,42);CREATE TABLE `tb_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `username` varchar(50) NOT NULL COMMENT '用户名', `password` varchar(64) NOT NULL COMMENT '密码，加密存储', `phone` varchar(20) DEFAULT NULL COMMENT '注册手机号', `email` varchar(50) DEFAULT NULL COMMENT '注册邮箱', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`) USING BTREE, UNIQUE KEY `phone` (`phone`) USING BTREE, UNIQUE KEY `email` (`email`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='用户表';insert into `tb_user`(`id`,`username`,`password`,`phone`,`email`,`created`,`updated`) values (37,'admin','$2a$10$9ZhDOBp.sRKat4l14ygu/.LscxrMUcDAfeVOEPiYwbcRkoB09gCmi','15888888888','lee.lusifer@gmail.com','2019-04-04 23:21:27','2019-04-04 23:21:29');CREATE TABLE `tb_user_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `user_id` bigint(20) NOT NULL COMMENT '用户 ID', `role_id` bigint(20) NOT NULL COMMENT '角色 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='用户角色表';insert into `tb_user_role`(`id`,`user_id`,`role_id`) values (37,37,37); 由于使用了 BCryptPasswordEncoder 的加密方式，故用户密码需要加密，代码如下： 1System.out.println(new BCryptPasswordEncoder().encode("123456")); 数据库操作采用 tk.mybatis 框架，需增加相关依赖 1234&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 2、关键步骤由于本次增加了 MyBatis 相关操作，代码增加较多，可以参考我 GitHub 上的源码，下面仅列出关键步骤及代码 （1）获取用户信息目的是为了实现自定义认证授权时可以通过数据库查询用户信息，Spring Security oAuth2 要求使用 username 的方式查询，提供相关用户信息后，认证工作由框架自行完成 1234567891011121314151617181920212223package com.funtl.oauth2.server.service.impl;import com.funtl.oauth2.server.domain.TbUser;import com.funtl.oauth2.server.mapper.TbUserMapper;import com.funtl.oauth2.server.service.TbUserService;import org.springframework.stereotype.Service;import tk.mybatis.mapper.entity.Example;import javax.annotation.Resource;@Servicepublic class TbUserServiceImpl implements TbUserService &#123; @Resource private TbUserMapper tbUserMapper; @Override public TbUser getByUsername(String username) &#123; Example example = new Example(TbUser.class); example.createCriteria().andEqualTo("username", username); return tbUserMapper.selectOneByExample(example); &#125;&#125; （2）获取用户权限信息认证成功后需要给用户授权，具体的权限已经存储在数据库里了，SQL 语句如下： 12345678910111213SELECT p.*FROM tb_user AS u LEFT JOIN tb_user_role AS ur ON u.id = ur.user_id LEFT JOIN tb_role AS r ON r.id = ur.role_id LEFT JOIN tb_role_permission AS rp ON r.id = rp.role_id LEFT JOIN tb_permission AS p ON p.id = rp.permission_idWHERE u.id = &lt;yourUserId&gt; （3）自定义认证授权实现类创建一个类，实现 UserDetailsService 接口，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.funtl.oauth2.server.config.service;import com.funtl.oauth2.server.domain.TbPermission;import com.funtl.oauth2.server.domain.TbUser;import com.funtl.oauth2.server.service.TbPermissionService;import com.funtl.oauth2.server.service.TbUserService;import org.assertj.core.util.Lists;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.security.core.GrantedAuthority;import org.springframework.security.core.authority.SimpleGrantedAuthority;import org.springframework.security.core.userdetails.User;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.core.userdetails.UsernameNotFoundException;import org.springframework.stereotype.Service;import java.util.List;/** * 自定义用户认证与授权 * &lt;p&gt; * Description: * &lt;/p&gt; * * @author Lusifer * @version v1.0.0 * @date 2019-04-04 23:57:04 * @see com.funtl.oauth2.server.config */@Servicepublic class UserDetailsServiceImpl implements UserDetailsService &#123; @Autowired private TbUserService tbUserService; @Autowired private TbPermissionService tbPermissionService; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; // 查询用户信息 TbUser tbUser = tbUserService.getByUsername(username); List&lt;GrantedAuthority&gt; grantedAuthorities = Lists.newArrayList(); if (tbUser != null) &#123; // 获取用户授权 List&lt;TbPermission&gt; tbPermissions = tbPermissionService.selectByUserId(tbUser.getId()); // 声明用户授权 tbPermissions.forEach(tbPermission -&gt; &#123; if (tbPermission != null &amp;&amp; tbPermission.getEnname() != null) &#123; GrantedAuthority grantedAuthority = new SimpleGrantedAuthority(tbPermission.getEnname()); grantedAuthorities.add(grantedAuthority); &#125; &#125;); &#125; // 由框架完成认证工作 return new User(tbUser.getUsername(), tbUser.getPassword(), grantedAuthorities); &#125;&#125; （4）服务器安全配置创建一个类继承 WebSecurityConfigurerAdapter 并添加相关注解： @Configuration @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)：全局方法拦截 1234567891011121314151617181920212223242526272829303132333435package com.funtl.oauth2.server.config;import com.funtl.oauth2.server.config.service.UserDetailsServiceImpl;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Bean @Override public UserDetailsService userDetailsService() &#123; return new UserDetailsServiceImpl(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; // 使用自定义认证与授权 auth.userDetailsService(userDetailsService()); &#125;&#125; （5）Application增加了 Mapper 的包扫描配置 1234567891011121314151617181920212223242526package com.funtl.oauth2;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import tk.mybatis.spring.annotation.MapperScan;/** * 认证服务器，用于获取 Token * &lt;p&gt; * Description: * &lt;/p&gt; * * @author Lusifer * @version v1.0.0 * @date 2019-04-01 16:06:45 * @see com.funtl.oauth2 */@SpringBootApplication@MapperScan(basePackages = "com.funtl.oauth2.server.mapper")public class OAuth2ServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OAuth2ServerApplication.class, args); &#125;&#125; （6）application.yml增加了 MyBatis 配置 12345678910111213141516171819202122232425spring: application: name: oauth2-server datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://192.168.141.128:3307/oauth2?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 hikari: minimum-idle: 5 idle-timeout: 600000 maximum-pool-size: 10 auto-commit: true pool-name: MyHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1server: port: 8080mybatis: type-aliases-package: com.funtl.oauth2.server.domain mapper-locations: classpath:mapper/*.xml （7）访问获取授权码打开浏览器，输入地址： 1http://localhost:8080/oauth/authorize?client_id=client&amp;response_type=code 第一次访问会跳转到登录页面 验证成功后会询问用户是否授权客户端 选择授权后会跳转到我的博客，浏览器地址上还会包含一个授权码（code=1JuO6V），浏览器地址栏会显示如下地址： 1http://www.funtl.com/?code=1JuO6V 有了这个授权码就可以获取访问令牌了 （8）通过授权码向服务器申请令牌通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 1 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; 操作成功后数据库 oauth_access_token 表中会增加一笔记录，效果图如下： here is no PasswordEncoder mapped 3、问题描述按照 基于内存存储令牌 配置成功后，携授权码使用 POST 请求认证服务器时，服务器返回错误信息 版本 Spring Boot: 2.1.3.RELEASE Spring Security: 5.1.4.RELEASE 日志 1java.lang.IllegalArgumentException: There is no PasswordEncoder mapped for the id &quot;null&quot; （1）解决方案Spring Security 5.0 之前版本的 PasswordEncoder 接口默认实现为 NoOpPasswordEncoder 此时是可以使用明文密码的，在 5.0 之后默认实现类改为 DelegatingPasswordEncoder 此时密码必须以加密形式存储。 （2）application.yml删除 spring.security 相关配置，修改为 123456spring: application: name: oauth2-serverserver: port: 8080 （3）WebSecurityConfiguration1234567891011121314151617181920212223242526272829303132package com.funtl.oauth2.server.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication() // 在内存中创建用户并为密码加密 .withUser("user").password(passwordEncoder().encode("123456")).roles("USER") .and() .withUser("admin").password(passwordEncoder().encode("123456")).roles("ADMIN"); &#125;&#125; （4）AuthorizationServerConfiguration123456789101112131415161718192021222324252627282930package com.funtl.oauth2.server.config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;@Configuration@EnableAuthorizationServerpublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; // 注入 WebSecurityConfiguration 中配置的 BCryptPasswordEncoder @Autowired private BCryptPasswordEncoder passwordEncoder; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; clients .inMemory() .withClient("client") // 还需要为 secret 加密 .secret(passwordEncoder.encode("secret")) .authorizedGrantTypes("authorization_code") .scopes("app") .redirectUris("http://www.funtl.com"); &#125;&#125; （5）测试访问通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; 十二、对认证服务器的修改在开发资源服务器之前，我们需要对 创建认证服务器 章节的配置进行小量修改，需要修改的内容如下： 删除 spring-boot-starter-security 依赖，因为 spring-cloud-starter-oauth2 包含了该依赖 解决访问 /oauth/check_token 端点的 403 问题 优化 RBAC 模型数据，以便更好的演示资源服务器的概念 修改 spring-security-oauth2-server 项目的 pom.xml，删除 spring-boot-starter-security 依赖，因为 spring-cloud-starter-oauth2 包含了该依赖，完整 POM 如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-security-oauth2-server&lt;/artifactId&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencies&gt; &lt;!-- Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 数据库 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 排除 tomcat-jdbc 以使用 HikariCP --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.oauth2.OAuth2ServerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 1、服务器安全配置资源服务器需要访问 /oauth/check_token 端点来检查 access_token 的有效性，此时该端点是受保护的资源，当我们访问该端点时会遇到 403 问题，将该端点暴露出来即可，暴露端点的关键代码为： 12345@Overridepublic void configure(WebSecurity web) throws Exception &#123; // 将 check_token 暴露出去，否则资源服务器访问时报 403 错误 web.ignoring().antMatchers("/oauth/check_token");&#125; 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142package com.funtl.oauth2.server.config;import com.funtl.oauth2.server.config.service.UserDetailsServiceImpl;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.builders.WebSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public BCryptPasswordEncoder passwordEncoder() &#123; // 设置默认的加密方式 return new BCryptPasswordEncoder(); &#125; @Bean @Override public UserDetailsService userDetailsService() &#123; return new UserDetailsServiceImpl(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; // 使用自定义认证与授权 auth.userDetailsService(userDetailsService()); &#125; @Override public void configure(WebSecurity web) throws Exception &#123; // 将 check_token 暴露出去，否则资源服务器访问时报 403 错误 web.ignoring().antMatchers("/oauth/check_token"); &#125;&#125; 2、初始化 RBAC 相关表增加了内容管理权限的数据，以便于我演示资源服务器的用法，SQL 语句如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980CREATE TABLE `tb_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父权限', `name` varchar(64) NOT NULL COMMENT '权限名称', `enname` varchar(64) NOT NULL COMMENT '权限英文名称', `url` varchar(255) NOT NULL COMMENT '授权路径', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=49 DEFAULT CHARSET=utf8 COMMENT='权限表';insert into `tb_permission`(`id`,`parent_id`,`name`,`enname`,`url`,`description`,`created`,`updated`) values (37,0,'系统管理','System','/',NULL,'2019-04-04 23:22:54','2019-04-04 23:22:56'),(38,37,'用户管理','SystemUser','/users/',NULL,'2019-04-04 23:25:31','2019-04-04 23:25:33'),(39,38,'查看用户','SystemUserView','/users/view/**',NULL,'2019-04-04 15:30:30','2019-04-04 15:30:43'),(40,38,'新增用户','SystemUserInsert','/users/insert/**',NULL,'2019-04-04 15:30:31','2019-04-04 15:30:44'),(41,38,'编辑用户','SystemUserUpdate','/users/update/**',NULL,'2019-04-04 15:30:32','2019-04-04 15:30:45'),(42,38,'删除用户','SystemUserDelete','/users/delete/**',NULL,'2019-04-04 15:30:48','2019-04-04 15:30:45'),(44,37,'内容管理','SystemContent','/contents/',NULL,'2019-04-06 18:23:58','2019-04-06 18:24:00'),(45,44,'查看内容','SystemContentView','/contents/view/**',NULL,'2019-04-06 23:49:39','2019-04-06 23:49:41'),(46,44,'新增内容','SystemContentInsert','/contents/insert/**',NULL,'2019-04-06 23:51:00','2019-04-06 23:51:02'),(47,44,'编辑内容','SystemContentUpdate','/contents/update/**',NULL,'2019-04-06 23:51:04','2019-04-06 23:51:06'),(48,44,'删除内容','SystemContentDelete','/contents/delete/**',NULL,'2019-04-06 23:51:08','2019-04-06 23:51:10');CREATE TABLE `tb_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `parent_id` bigint(20) DEFAULT NULL COMMENT '父角色', `name` varchar(64) NOT NULL COMMENT '角色名称', `enname` varchar(64) NOT NULL COMMENT '角色英文名称', `description` varchar(200) DEFAULT NULL COMMENT '备注', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='角色表';insert into `tb_role`(`id`,`parent_id`,`name`,`enname`,`description`,`created`,`updated`) values (37,0,'超级管理员','admin',NULL,'2019-04-04 23:22:03','2019-04-04 23:22:05');CREATE TABLE `tb_role_permission` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `role_id` bigint(20) NOT NULL COMMENT '角色 ID', `permission_id` bigint(20) NOT NULL COMMENT '权限 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=48 DEFAULT CHARSET=utf8 COMMENT='角色权限表';insert into `tb_role_permission`(`id`,`role_id`,`permission_id`) values (37,37,37),(38,37,38),(39,37,39),(40,37,40),(41,37,41),(42,37,42),(43,37,44),(44,37,45),(45,37,46),(46,37,47),(47,37,48);CREATE TABLE `tb_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `username` varchar(50) NOT NULL COMMENT '用户名', `password` varchar(64) NOT NULL COMMENT '密码，加密存储', `phone` varchar(20) DEFAULT NULL COMMENT '注册手机号', `email` varchar(50) DEFAULT NULL COMMENT '注册邮箱', `created` datetime NOT NULL, `updated` datetime NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`) USING BTREE, UNIQUE KEY `phone` (`phone`) USING BTREE, UNIQUE KEY `email` (`email`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='用户表';insert into `tb_user`(`id`,`username`,`password`,`phone`,`email`,`created`,`updated`) values (37,'admin','$2a$10$9ZhDOBp.sRKat4l14ygu/.LscxrMUcDAfeVOEPiYwbcRkoB09gCmi','15888888888','lee.lusifer@gmail.com','2019-04-04 23:21:27','2019-04-04 23:21:29');CREATE TABLE `tb_user_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `user_id` bigint(20) NOT NULL COMMENT '用户 ID', `role_id` bigint(20) NOT NULL COMMENT '角色 ID', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=38 DEFAULT CHARSET=utf8 COMMENT='用户角色表';insert into `tb_user_role`(`id`,`user_id`,`role_id`) values (37,37,37); 十三、创建资源服务器模块在 为什么需要 oAuth2 和 RBAC 基于角色的权限控制 章节，我们介绍过资源的概念，简单点说就是需要被访问的业务数据或是静态资源文件都可以被称作资源。 为了让大家更好的理解资源服务器的概念，我们单独创建一个名为 spring-security-oauth2-resource 资源服务器的项目，该项目的主要目的就是对数据表的 CRUD 操作，而这些操作就是对资源的操作了。 操作流程 初始化资源服务器数据库 POM 所需依赖同认证服务器 配置资源服务器 配置资源(Controller) 1、初始化资源服务器数据库12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849CREATE TABLE `tb_content` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `category_id` bigint(20) NOT NULL COMMENT '内容类目ID', `title` varchar(200) DEFAULT NULL COMMENT '内容标题', `sub_title` varchar(100) DEFAULT NULL COMMENT '子标题', `title_desc` varchar(500) DEFAULT NULL COMMENT '标题描述', `url` varchar(500) DEFAULT NULL COMMENT '链接', `pic` varchar(300) DEFAULT NULL COMMENT '图片绝对路径', `pic2` varchar(300) DEFAULT NULL COMMENT '图片2', `content` text COMMENT '内容', `created` datetime DEFAULT NULL, `updated` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `category_id` (`category_id`), KEY `updated` (`updated`)) ENGINE=InnoDB AUTO_INCREMENT=42 DEFAULT CHARSET=utf8;insert into `tb_content`(`id`,`category_id`,`title`,`sub_title`,`title_desc`,`url`,`pic`,`pic2`,`content`,`created`,`updated`) values (28,89,'标题','子标题','标题说明','http://www.jd.com',NULL,NULL,NULL,'2019-04-07 00:56:09','2019-04-07 00:56:11'),(29,89,'ad2','ad2','ad2','http://www.baidu.com',NULL,NULL,NULL,'2019-04-07 00:56:13','2019-04-07 00:56:15'),(30,89,'ad3','ad3','ad3','http://www.sina.com.cn',NULL,NULL,NULL,'2019-04-07 00:56:17','2019-04-07 00:56:19'),(31,89,'ad4','ad4','ad4','http://www.funtl.com',NULL,NULL,NULL,'2019-04-07 00:56:22','2019-04-07 00:56:25');CREATE TABLE `tb_content_category` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '类目ID', `parent_id` bigint(20) DEFAULT NULL COMMENT '父类目ID=0时，代表的是一级的类目', `name` varchar(50) DEFAULT NULL COMMENT '分类名称', `status` int(1) DEFAULT '1' COMMENT '状态。可选值:1(正常),2(删除)', `sort_order` int(4) DEFAULT NULL COMMENT '排列序号，表示同级类目的展现次序，如数值相等则按名称次序排列。取值范围:大于零的整数', `is_parent` tinyint(1) DEFAULT '1' COMMENT '该类目是否为父类目，1为true，0为false', `created` datetime DEFAULT NULL COMMENT '创建时间', `updated` datetime DEFAULT NULL COMMENT '创建时间', PRIMARY KEY (`id`), KEY `parent_id` (`parent_id`,`status`) USING BTREE, KEY `sort_order` (`sort_order`)) ENGINE=InnoDB AUTO_INCREMENT=98 DEFAULT CHARSET=utf8 COMMENT='内容分类';insert into `tb_content_category`(`id`,`parent_id`,`name`,`status`,`sort_order`,`is_parent`,`created`,`updated`) values (30,0,'LeeShop',1,1,1,'2015-04-03 16:51:38','2015-04-03 16:51:40'),(86,30,'首页',1,1,1,'2015-06-07 15:36:07','2015-06-07 15:36:07'),(87,30,'列表页面',1,1,1,'2015-06-07 15:36:16','2015-06-07 15:36:16'),(88,30,'详细页面',1,1,1,'2015-06-07 15:36:27','2015-06-07 15:36:27'),(89,86,'大广告',1,1,0,'2015-06-07 15:36:38','2015-06-07 15:36:38'),(90,86,'小广告',1,1,0,'2015-06-07 15:36:45','2015-06-07 15:36:45'),(91,86,'商城快报',1,1,0,'2015-06-07 15:36:55','2015-06-07 15:36:55'),(92,87,'边栏广告',1,1,0,'2015-06-07 15:37:07','2015-06-07 15:37:07'),(93,87,'页头广告',1,1,0,'2015-06-07 15:37:17','2015-06-07 15:37:17'),(94,87,'页脚广告',1,1,0,'2015-06-07 15:37:31','2015-06-07 15:37:31'),(95,88,'边栏广告',1,1,0,'2015-06-07 15:37:56','2015-06-07 15:37:56'),(96,86,'中广告',1,1,1,'2015-07-25 18:58:52','2015-07-25 18:58:52'),(97,96,'中广告1',1,1,0,'2015-07-25 18:59:43','2015-07-25 18:59:43'); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.funtl&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-security-oauth2-resource&lt;/artifactId&gt; &lt;url&gt;http://www.funtl.com&lt;/url&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2.0&lt;/name&gt; &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;liwemin&lt;/id&gt; &lt;name&gt;Lusifer Lee&lt;/name&gt; &lt;email&gt;lee.lusifer@gmail.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;dependencies&gt; &lt;!-- Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 数据库 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 排除 tomcat-jdbc 以使用 HikariCP --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.funtl.oauth2.OAuth2ResourceApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2、关键步骤由于代码较多，可以参考我 GitHub 上的源码，下面仅列出关键步骤及代码 （1）配置资源服务器创建一个类继承 ResourceServerConfigurerAdapter 并添加相关注解： @Configuration @EnableResourceServer：资源服务器 @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)：全局方法拦截 12345678910111213141516171819202122232425262728293031package com.funtl.oauth2.resource.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.http.SessionCreationPolicy;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableResourceServer;import org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfigurerAdapter;@Configuration@EnableResourceServer@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class ResourceServerConfiguration extends ResourceServerConfigurerAdapter &#123; @Override public void configure(HttpSecurity http) throws Exception &#123; http .exceptionHandling() .and() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() // 以下为配置所需保护的资源路径及权限，需要与认证服务器配置的授权部分对应 .antMatchers("/").hasAuthority("SystemContent") .antMatchers("/view/**").hasAuthority("SystemContentView") .antMatchers("/insert/**").hasAuthority("SystemContentInsert") .antMatchers("/update/**").hasAuthority("SystemContentUpdate") .antMatchers("/delete/**").hasAuthority("SystemContentDelete"); &#125;&#125; （2）Application1234567891011121314package com.funtl.oauth2;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import tk.mybatis.spring.annotation.MapperScan;@SpringBootApplication@MapperScan(basePackages = "com.funtl.oauth2.resource.mapper")public class OAuth2ResourceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OAuth2ResourceApplication.class, args); &#125;&#125; （3）application.yml1234567891011121314151617181920212223242526272829303132333435363738394041424344spring: application: name: oauth2-resource datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://192.168.141.128:3307/oauth2_resource?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 hikari: minimum-idle: 5 idle-timeout: 600000 maximum-pool-size: 10 auto-commit: true pool-name: MyHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1security: oauth2: client: client-id: client client-secret: secret access-token-uri: http://localhost:8080/oauth/token user-authorization-uri: http://localhost:8080/oauth/authorize resource: token-info-uri: http://localhost:8080/oauth/check_tokenserver: port: 8081 servlet: context-path: /contentsmybatis: type-aliases-package: com.funtl.oauth2.resource.domain mapper-locations: classpath:mapper/*.xmllogging: level: root: INFO org.springframework.web: INFO org.springframework.security: INFO org.springframework.security.oauth2: INFO 3、访问资源（1）访问获取授权码打开浏览器，输入地址： 1http://localhost:8080/oauth/authorize?client_id=client&amp;response_type=code 第一次访问会跳转到登录页面 验证成功后会询问用户是否授权客户端 选择授权后会跳转到我的博客，浏览器地址上还会包含一个授权码（code=1JuO6V），浏览器地址栏会显示如下地址： 1http://www.funtl.com/?code=1JuO6V 有了这个授权码就可以获取访问令牌了 （2）通过授权码向服务器申请令牌通过 CURL 或是 Postman 请求 1curl -X POST -H "Content-Type: application/x-www-form-urlencoded" -d 'grant_type=authorization_code&amp;code=1JuO6V' "http://client:secret@localhost:8080/oauth/token" 1 得到响应结果如下： 123456&#123; "access_token": "016d8d4a-dd6e-4493-b590-5f072923c413", "token_type": "bearer", "expires_in": 43199, "scope": "app"&#125; （3）携带令牌访问资源服务器此处以获取全部资源为例，其它请求方式一样，可以参考我源码中的单元测试代码。可以使用以下方式请求： 使用 Headers 方式：需要在请求头增加 Authorization: Bearer yourAccessToken 直接请求带参数方式：http://localhost:8081/contents?access_token=yourAccessToken 使用 Headers 方式，通过 CURL 或是 Postman 请求 1curl --location --request GET "http://localhost:8081/contents" --header "Content-Type: application/json" --header "Authorization: Bearer yourAccessToken" OAuth（开放授权）是一个开放标准，允许用户让第三方应用访问该用户在某一网站上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和密码提供给第三方应用。OAuth协议为用户资源的授权提供了一个安全的、开放而又简易的标准。与以往的授权方式不同之处是OAuth的授权不会使第三方触及到用户的帐号信息（如用户名与密码），即第三方无需使用用户的用户名与密码就可以申请获得该用户资源的授权，因此OAuth是安全的。同时，任何第三方都可以使用OAuth认证服务，任何服务提供商都可以实现自身的OAuth认证服务，因而OAuth是开放的。Shiro是一个强大的，易用的Java安全框架。它被用作于认证，授权，加密，session管理。依赖于Shiro简单易懂的API，就可以快速的构建包括手机，大型web和商业应用。 十四、shiro 简单整合oauth2.0服务端使用了shiro，如果用户在授权过程中，密码连续错误5次将冻结账号，登录时有验证码,但是并没有使用,可以忽略。客户端就是纯粹的http请求。 1、服务端（1）初始化数据库12345678910111213141516171819202122DROP TABLE IF EXISTS `user_info`;CREATE TABLE `user_info` ( `uid` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(50) DEFAULT '' COMMENT '用户名', `password` varchar(256) DEFAULT NULL COMMENT '登录密码', `name` varchar(256) DEFAULT NULL COMMENT '用户真实姓名', `id_card_num` varchar(256) DEFAULT NULL COMMENT '用户身份证号', `state` char(1) DEFAULT '0' COMMENT '用户状态：0:正常状态,1：用户被锁定', PRIMARY KEY (`uid`), UNIQUE KEY `username` (`username`) USING BTREE, UNIQUE KEY `id_card_num` (`id_card_num`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8;DROP TABLE IF EXISTS `oauth2_client`;CREATE TABLE `oauth2_client` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `client_name` varchar(100) DEFAULT NULL COMMENT '客戶端名稱', `client_id` varchar(100) DEFAULT NULL COMMENT '客戶端ID', `client_secret` varchar(100) DEFAULT NULL COMMENT '客户端安全key', PRIMARY KEY (`id`), KEY `idx_oauth2_client_client_id` (`client_id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; 12345#插入用户信息表INSERT INTO user_info(uid,username,`password`,`name`,id_card_num) VALUES (null,'admin','123456','超哥','133333333333333333');#插入client表insert into oauth2_client values(1,'oauth-client','c1ebe466-1cdc-4bd3-ab69-77c3561b9dee','d8346ea2-6017-43ed-ad68-19c0f971738b');12345 （2）pom添加依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.oltu.oauth2&lt;/groupId&gt; &lt;artifactId&gt;org.apache.oltu.oauth2.authzserver&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.oltu.oauth2&lt;/groupId&gt; &lt;artifactId&gt;org.apache.oltu.oauth2.resourceserver&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt; （3）相关实体类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.springboot.test.shiro.oauthserver.entity;import java.io.Serializable;import java.util.HashSet;import java.util.Set;/** * @author: wangsaichao * @date: 2018/5/11 * @description: 用户信息 */public class User implements Serializable&#123; /** * 用户id(主键 自增) */ private Integer uid; /** * 用户名 */ private String username; /** * 登录密码 */ private String password; /** * 用户真实姓名 */ private String name; /** * 身份证号 */ private String id_card_num; /** * 用户状态：0:正常状态,1：用户被锁定 */ private String state;&#125;package com.springboot.test.shiro.oauthserver.entity;/** * @author: wangsaichao * @date: 2018/5/11 * @description: 客户端信息 */public class Client &#123; private String id; private String clientName; private String clientId; private String clientSecret;&#125; （5）相关service层1234567891011121314151617181920212223242526272829303132public interface AuthorizeService &#123; /** 根据客户端id 查询客户端是否存在 */ public boolean checkClientId(String clientId); /** 添加 auth code */ public void addAuthCode(String authCode, String username); /** 检查客户端安全Key是否正确 */ public boolean checkClientSecret(String clientSecret); /** 检查authCode是否可用 */ public boolean checkAuthCode(String authCode); /** 根据 authCode 获取用户名 */ public String getUsernameByAuthCode(String authCode); /** 添加accessToken */ public void addAccessToken(String accessToken, String username); /** access token 过期时间 */ public long getExpireIn(); /** 检查 accessToken 是否可用 */ public boolean checkAccessToken(String accessToken); /** 根据 accessToken 获取用户名 */ public String getUsernameByAccessToken(String accessToken);&#125;public interface ClientService &#123; /** 根据clientId查询Client信息 */ public Client findByClientId(String clientId); /** 根据clientSecret查询client信息 */ public Client findByClientSecret(String clientSecret);&#125;public interface UserService &#123; /** 根据用户名 查询用户 */ public User findByUserName(String username); /** 修改用户信息 */ public int updateUser(User user);&#125; 相关dao和数据库操作请参考代码代码中并没有有关资源的维护,只是授权服务。资源服务相关操作没有写。只拿插入数据库的那一条基础数据测试。 以下代码参考开涛博客：http://jinnianshilongnian.iteye.com/blog/2038646 （6）授权控制器AuthorizeController123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162package com.springboot.test.shiro.oauthserver.controller;import com.springboot.test.shiro.oauthserver.service.AuthorizeService;import com.springboot.test.shiro.oauthserver.service.ClientService;import org.apache.oltu.oauth2.as.issuer.MD5Generator;import org.apache.oltu.oauth2.as.issuer.OAuthIssuerImpl;import org.apache.oltu.oauth2.as.request.OAuthAuthzRequest;import org.apache.oltu.oauth2.as.response.OAuthASResponse;import org.apache.oltu.oauth2.common.OAuth;import org.apache.oltu.oauth2.common.error.OAuthError;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.apache.oltu.oauth2.common.message.OAuthResponse;import org.apache.oltu.oauth2.common.message.types.ResponseType;import org.apache.oltu.oauth2.common.utils.OAuthUtils;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.IncorrectCredentialsException;import org.apache.shiro.authc.LockedAccountException;import org.apache.shiro.authc.UnknownAccountException;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.subject.Subject;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.util.StringUtils;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.net.URI;import java.net.URISyntaxException;/** * @author: wangsaichao * @date: 2018/5/27 * @description: 授权控制器 * * 代码的作用: * 1、首先通过如 http://localhost:9090/oauth-server/authorize?response_type=code&amp;redirect_uri=http%3A%2F%2Flocalhost%3A9080%2Foauth-client%2FcallbackCode&amp;client_id=c1ebe466-1cdc-4bd3-ab69-77c3561b9dee * 2、该控制器首先检查clientId是否正确；如果错误将返回相应的错误信息 * 3、然后判断用户是否登录了，如果没有登录首先到登录页面登录 * 4、登录成功后生成相应的auth code即授权码，然后重定向到客户端地址，如http://localhost:9080/oauth-client/oauth2-login?code=52b1832f5dff68122f4f00ae995da0ed；在重定向到的地址中会带上code参数（授权码），接着客户端可以根据授权码去换取access token。 */@Controller@RequestMapping("/oauth-server")public class AuthorizeController &#123; @Autowired private AuthorizeService authorizeService; @Autowired private ClientService clientService; @RequestMapping("/authorize") public Object authorize(Model model, HttpServletRequest request) throws OAuthSystemException, URISyntaxException &#123; try &#123; //构建OAuth 授权请求 OAuthAuthzRequest oauthRequest = new OAuthAuthzRequest(request); //根据传入的clientId 判断 客户端是否存在 if (!authorizeService.checkClientId(oauthRequest.getClientId())) &#123; //生成错误信息,告知客户端不存在 OAuthResponse response = OAuthASResponse .errorResponse(HttpServletResponse.SC_BAD_REQUEST) .setError(OAuthError.TokenResponse.INVALID_CLIENT) .setErrorDescription("客户端验证失败，如错误的client_id/client_secret") .buildJSONMessage(); return new ResponseEntity( response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; // 判断用户是否登录 Subject subject = SecurityUtils.getSubject(); //如果用户没有登录,跳转到登录页面 if(!subject.isAuthenticated()) &#123; if(!login(subject, request)) &#123; //登录失败时跳转到登陆页面 model.addAttribute("client", clientService.findByClientId(oauthRequest.getClientId())); return "oauth2login"; &#125; &#125; String username = (String) subject.getPrincipal(); //生成授权码 String authorizationCode = null; String responseType = oauthRequest.getParam(OAuth.OAUTH_RESPONSE_TYPE); if(responseType.equals(ResponseType.CODE.toString())) &#123; OAuthIssuerImpl oAuthIssuer = new OAuthIssuerImpl(new MD5Generator()); authorizationCode = oAuthIssuer.authorizationCode(); //把授权码放到缓存中 authorizeService.addAuthCode(authorizationCode, username); &#125; // 进行OAuth响应构建 OAuthASResponse.OAuthAuthorizationResponseBuilder builder = OAuthASResponse.authorizationResponse(request, HttpServletResponse.SC_FOUND); // 设置授权码 builder.setCode(authorizationCode); // 根据客户端重定向地址 String redirectURI = oauthRequest.getParam(OAuth.OAUTH_REDIRECT_URI); // 构建响应 final OAuthResponse response = builder.location(redirectURI).buildQueryMessage(); // 根据OAuthResponse 返回 ResponseEntity响应 HttpHeaders headers = new HttpHeaders(); headers.setLocation(new URI(response.getLocationUri())); return new ResponseEntity(headers, HttpStatus.valueOf(response.getResponseStatus())); &#125; catch (OAuthProblemException e) &#123; // 出错处理 String redirectUri = e.getRedirectUri(); if(OAuthUtils.isEmpty(redirectUri)) &#123; // 告诉客户端没有传入redirectUri直接报错 return new ResponseEntity("告诉客户端没有传入redirectUri直接报错！", HttpStatus.NOT_FOUND); &#125; // 返回错误消息 final OAuthResponse response = OAuthASResponse.errorResponse(HttpServletResponse.SC_FOUND).error(e).location(redirectUri).buildQueryMessage(); HttpHeaders headers = new HttpHeaders(); headers.setLocation(new URI(response.getLocationUri())); return new ResponseEntity(headers, HttpStatus.valueOf(response.getResponseStatus())); &#125; &#125; private boolean login(Subject subject, HttpServletRequest request) &#123; if("get".equalsIgnoreCase(request.getMethod())) &#123; return false; &#125; String username = request.getParameter("username"); String password = request.getParameter("password"); if(StringUtils.isEmpty(username) || StringUtils.isEmpty(password)) &#123; return false; &#125; UsernamePasswordToken token = new UsernamePasswordToken(username, password); try &#123; subject.login(token); return true; &#125;catch(Exception e)&#123; if(e instanceof UnknownAccountException)&#123; request.setAttribute("msg","用户名或密码错误！"); &#125; if(e instanceof IncorrectCredentialsException)&#123; request.setAttribute("msg","用户名或密码错误！"); &#125; if(e instanceof LockedAccountException)&#123; request.setAttribute("msg","账号已被锁定,请联系管理员！"); &#125; return false; &#125; &#125;&#125; 1、首先通过如http://localhost:9090/oauth-server/authorize?response_type=code&amp;redirect_uri=http://localhost:9080/oauth-client/callbackCode&amp;client_id=c1ebe466-1cdc-4bd3-ab69-77c3561b9dee进入方法2、该控制器首先检查clientId是否正确；如果错误将返回相应的错误信息3、然后判断用户是否登录了，如果没有登录首先到登录页面登录4、登录成功后生成相应的auth code即授权码，然后重定向到客户端地址，如http://localhost:9080/oauth-client/oauth2-login？code=52b1832f5dff68122f4f00ae995da0ed；在重定向到的地址中会带上code参数（授权码），接着客户端可以根据授权码去换取access token。 （7）访问令牌控制器AccessTokenController123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596package com.springboot.test.shiro.oauthserver.controller;import com.springboot.test.shiro.oauthserver.service.AuthorizeService;import org.apache.oltu.oauth2.as.issuer.MD5Generator;import org.apache.oltu.oauth2.as.issuer.OAuthIssuer;import org.apache.oltu.oauth2.as.issuer.OAuthIssuerImpl;import org.apache.oltu.oauth2.as.request.OAuthTokenRequest;import org.apache.oltu.oauth2.as.response.OAuthASResponse;import org.apache.oltu.oauth2.common.OAuth;import org.apache.oltu.oauth2.common.error.OAuthError;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.apache.oltu.oauth2.common.message.OAuthResponse;import org.apache.oltu.oauth2.common.message.types.GrantType;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpEntity;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @author: wangsaichao * @date: 2018/5/27 * @description: 访问令牌控制器 * * 代码描述： * 1、首先通过如http://localhost:9090/accessToken，POST提交如下数据：client_id= c1ebe466-1cdc-4bd3-ab69-77c3561b9dee&amp; client_secret= d8346ea2-6017-43ed-ad68-19c0f971738b&amp;grant_type=authorization_code&amp;code=828beda907066d058584f37bcfd597b6&amp;redirect_uri=http://localhost:9080/oauth-client/oauth2-login访问。 * 2、该控制器会验证client_id、client_secret、auth code的正确性，如果错误会返回相应的错误； * 3、如果验证通过会生成并返回相应的访问令牌access token。 */@RestController@RequestMapping("/oauth-server")public class AccessTokenController &#123; @Autowired private AuthorizeService authorizeService; @RequestMapping("/accessToken") public HttpEntity token(HttpServletRequest request) throws OAuthSystemException &#123; try &#123; // 构建Oauth请求 OAuthTokenRequest oAuthTokenRequest = new OAuthTokenRequest(request); //检查提交的客户端id是否正确 if(!authorizeService.checkClientId(oAuthTokenRequest.getClientId())) &#123; OAuthResponse response = OAuthASResponse.errorResponse(HttpServletResponse.SC_BAD_REQUEST) .setError(OAuthError.TokenResponse.INVALID_CLIENT) .setErrorDescription("客户端验证失败，client_id错误！") .buildJSONMessage(); return new ResponseEntity(response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; // 检查客户端安全Key是否正确 if(!authorizeService.checkClientSecret(oAuthTokenRequest.getClientSecret()))&#123; OAuthResponse response = OAuthASResponse.errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setError(OAuthError.TokenResponse.UNAUTHORIZED_CLIENT) .setErrorDescription("客户端验证失败，client_secret错误！") .buildJSONMessage(); return new ResponseEntity(response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; String authCode = oAuthTokenRequest.getParam(OAuth.OAUTH_CODE); // 检查验证类型，此处只检查AUTHORIZATION类型，其他的还有PASSWORD或者REFRESH_TOKEN if(oAuthTokenRequest.getParam(OAuth.OAUTH_GRANT_TYPE).equals(GrantType.AUTHORIZATION_CODE.toString()))&#123; if(!authorizeService.checkAuthCode(authCode))&#123; OAuthResponse response = OAuthASResponse.errorResponse(HttpServletResponse.SC_BAD_REQUEST) .setError(OAuthError.TokenResponse.INVALID_GRANT) .setErrorDescription("auth_code错误！") .buildJSONMessage(); return new ResponseEntity(response.getBody(),HttpStatus.valueOf(response.getResponseStatus())); &#125; &#125; //生成Access Token OAuthIssuer issuer = new OAuthIssuerImpl(new MD5Generator()); final String accessToken = issuer.accessToken(); authorizeService.addAccessToken(accessToken, authorizeService.getUsernameByAuthCode(authCode)); // 生成OAuth响应 OAuthResponse response = OAuthASResponse.tokenResponse(HttpServletResponse.SC_OK) .setAccessToken(accessToken).setExpiresIn(String.valueOf(authorizeService.getExpireIn())) .buildJSONMessage(); return new ResponseEntity(response.getBody(),HttpStatus.valueOf(response.getResponseStatus())); &#125; catch(OAuthProblemException e) &#123; OAuthResponse res = OAuthASResponse.errorResponse(HttpServletResponse.SC_BAD_REQUEST).error(e).buildBodyMessage(); return new ResponseEntity(res.getBody(),HttpStatus.valueOf(res.getResponseStatus())); &#125; &#125;&#125; 1、首先通过如http://localhost:9090/accessToken，POST提交如下数据：client_id= c1ebe466-1cdc-4bd3-ab69-77c3561b9dee&amp;client_secret=d8346ea2-6017-43ed-ad68-19c0f971738b&amp;grant_type=authorization_code&amp;code=828beda907066d058584f37bcfd597b6&amp;redirect_uri=http://localhost:9080/oauth-client/oauth2-login访问。2、该控制器会验证client_id、client_secret、auth code的正确性，如果错误会返回相应的错误；3、如果验证通过会生成并返回相应的访问令牌access token。 （8）资源控制器UserInfoController12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package com.springboot.test.shiro.oauthserver.controller;import com.springboot.test.shiro.oauthserver.service.AuthorizeService;import org.apache.oltu.oauth2.common.OAuth;import org.apache.oltu.oauth2.common.error.OAuthError;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.apache.oltu.oauth2.common.message.OAuthResponse;import org.apache.oltu.oauth2.common.message.types.ParameterStyle;import org.apache.oltu.oauth2.common.utils.OAuthUtils;import org.apache.oltu.oauth2.rs.request.OAuthAccessResourceRequest;import org.apache.oltu.oauth2.rs.response.OAuthRSResponse;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @author: wangsaichao * @date: 2018/5/27 * @description: * 1、首先通过如http://localhost:9090/oauth-server/userInfo?access_token=828beda907066d058584f37bcfd597b6进行访问； * 2、该控制器会验证access token的有效性；如果无效了将返回相应的错误，客户端再重新进行授权； * 3、如果有效，则返回当前登录用户的用户名。 */@Controller@RequestMapping("/oauth-server")public class UserInfoController &#123; @Autowired private AuthorizeService authorizeService; @RequestMapping("/userInfo") public HttpEntity userInfo(HttpServletRequest request) throws OAuthSystemException &#123; try &#123; //构建OAuth资源请求 OAuthAccessResourceRequest oauthRequest = new OAuthAccessResourceRequest(request, ParameterStyle.QUERY); //获取Access Token String accessToken = oauthRequest.getAccessToken(); //验证Access Token if (!authorizeService.checkAccessToken(accessToken)) &#123; // 如果不存在/过期了，返回未验证错误，需重新验证 OAuthResponse oauthResponse = OAuthRSResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setRealm("oauth-server") .setError(OAuthError.ResourceResponse.INVALID_TOKEN) .buildHeaderMessage(); HttpHeaders headers = new HttpHeaders(); headers.add(OAuth.HeaderType.WWW_AUTHENTICATE, oauthResponse.getHeader(OAuth.HeaderType.WWW_AUTHENTICATE)); return new ResponseEntity(headers, HttpStatus.UNAUTHORIZED); &#125; //返回用户名 String username = authorizeService.getUsernameByAccessToken(accessToken); return new ResponseEntity(username, HttpStatus.OK); &#125; catch (OAuthProblemException e) &#123; //检查是否设置了错误码 String errorCode = e.getError(); if (OAuthUtils.isEmpty(errorCode)) &#123; OAuthResponse oauthResponse = OAuthRSResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setRealm("fxb") .buildHeaderMessage(); HttpHeaders headers = new HttpHeaders(); headers.add(OAuth.HeaderType.WWW_AUTHENTICATE, oauthResponse.getHeader(OAuth.HeaderType.WWW_AUTHENTICATE)); return new ResponseEntity(headers, HttpStatus.UNAUTHORIZED); &#125; OAuthResponse oauthResponse = OAuthRSResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setRealm("oauth-server") .setError(e.getError()) .setErrorDescription(e.getDescription()) .setErrorUri(e.getUri()) .buildHeaderMessage(); HttpHeaders headers = new HttpHeaders(); headers.add(OAuth.HeaderType.WWW_AUTHENTICATE, oauthResponse.getHeader(OAuth.HeaderType.WWW_AUTHENTICATE)); return new ResponseEntity(HttpStatus.BAD_REQUEST); &#125; &#125;&#125; 1、首先通过如http://localhost:9090/oauth-server/userInfo?access_token=828beda907066d058584f37bcfd597b6进行访问；2、该控制器会验证access token的有效性；如果无效了将返回相应的错误，客户端再重新进行授权；3、如果有效，则返回当前登录用户的用户名。 对于授权服务和资源服务的实现可以参考新浪微博开发平台的实现：http://open.weibo.com/wiki/授权机制说明http://open.weibo.com/wiki/微博API 2、客户端我是将客户端一系列流程直接跑完的，就是内部redirect没有使用shiro控制权限，只是为了理解这个流程 （1）pom添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.oltu.oauth2&lt;/groupId&gt; &lt;artifactId&gt;org.apache.oltu.oauth2.client&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt; （2）AuthCodeController获取code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.springboot.test.shiro.oauthclient.controller;import org.apache.oltu.oauth2.client.request.OAuthClientRequest;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;/** * @author: wangsaichao * @date: 2018/5/29 * @description: * 1、拼接url然后访问，获取code * 2、服务端检查成功,然后会回调到 另一个接口 /oauth-client/callbackCode */@Controller@RequestMapping("/oauth-client")public class AuthCodeController &#123; @Value("$&#123;clientId&#125;") private String clientId; @Value("$&#123;authorizeUrl&#125;") private String authorizeUrl; @Value("$&#123;redirectUrl&#125;") private String redirectUrl; @Value("$&#123;response_type&#125;") private String response_type; @RequestMapping("/getCode") public String getCode() throws OAuthProblemException &#123; String requestUrl = null; try &#123; //配置请求参数，构建oauthd的请求。设置请求服务地址（authorizeUrl）、clientId、response_type、redirectUrl OAuthClientRequest accessTokenRequest = OAuthClientRequest.authorizationLocation(authorizeUrl) .setResponseType(response_type) .setClientId(clientId) .setRedirectURI(redirectUrl) .buildQueryMessage(); requestUrl = accessTokenRequest.getLocationUri(); &#125; catch (OAuthSystemException e) &#123; e.printStackTrace(); &#125; System.out.println("==&gt; 客户端重定向到服务端获取auth_code： "+requestUrl); return "redirect:"+requestUrl ; &#125;&#125; 1、拼接url然后重定向到服务端，获取code2、服务端检查成功,然后会回调到 另一个接口 /oauth-client/callbackCode （3）AccessTokenController服务端回调1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.springboot.test.shiro.oauthclient.controller;import org.apache.oltu.oauth2.client.OAuthClient;import org.apache.oltu.oauth2.client.URLConnectionClient;import org.apache.oltu.oauth2.client.request.OAuthClientRequest;import org.apache.oltu.oauth2.client.response.OAuthAccessTokenResponse;import org.apache.oltu.oauth2.common.OAuth;import org.apache.oltu.oauth2.common.exception.OAuthProblemException;import org.apache.oltu.oauth2.common.exception.OAuthSystemException;import org.apache.oltu.oauth2.common.message.types.GrantType;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;/** * @author: wangsaichao * @date: 2018/5/29 * @description: 服务端回调方法 * 1.服务端回调,传回code值 * 2.根据code值，调用服务端服务,根据code获取access_token * 3.拿到access_token重定向到客户端的服务 /oauth-client/getUserInfo 在该服务中 再调用服务端获取用户信息 */@Controller@RequestMapping("/oauth-client")public class AccessTokenController &#123; @Value("$&#123;clientId&#125;") private String clientId; @Value("$&#123;clientSecret&#125;") private String clientSecret; @Value("$&#123;accessTokenUrl&#125;") private String accessTokenUrl; @Value("$&#123;redirectUrl&#125;") private String redirectUrl; @Value("$&#123;response_type&#125;") private String response_type; //接受客户端返回的code，提交申请access token的请求 @RequestMapping("/callbackCode") public Object toLogin(HttpServletRequest request)throws OAuthProblemException &#123; String code = request.getParameter("code"); System.out.println("==&gt; 服务端回调，获取的code："+code); OAuthClient oAuthClient =new OAuthClient(new URLConnectionClient()); try &#123; OAuthClientRequest accessTokenRequest = OAuthClientRequest .tokenLocation(accessTokenUrl) .setGrantType(GrantType.AUTHORIZATION_CODE) .setClientId(clientId) .setClientSecret(clientSecret) .setCode(code) .setRedirectURI(redirectUrl) .buildQueryMessage(); //去服务端请求access token，并返回响应 OAuthAccessTokenResponse oAuthResponse =oAuthClient.accessToken(accessTokenRequest, OAuth.HttpMethod.POST); //获取服务端返回过来的access token String accessToken = oAuthResponse.getAccessToken(); //查看access token是否过期 Long expiresIn =oAuthResponse.getExpiresIn(); System.out.println("==&gt; 客户端根据 code值 "+code +" 到服务端获取的access_token为："+accessToken+" 过期时间为："+expiresIn); System.out.println("==&gt; 拿到access_token然后重定向到 客户端 /oauth-client/getUserInfo服务,传过去accessToken"); return"redirect:/oauth-client/getUserInfo?accessToken="+accessToken; &#125; catch (OAuthSystemException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 1、服务端回调,传回code值2、根据code值，调用服务端服务,根据code获取access_token3、拿到access_token重定向到客户端的服务 /oauth-client/getUserInfo 在该服务中 再调用服务端获取用户信息 （4）GetUserInfoController客户端根据access_token获取用户信息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.springboot.test.shiro.oauthclient.controller;import org.apache.oltu.oauth2.client.OAuthClient;import org.apache.oltu.oauth2.client.URLConnectionClient;import org.apache.oltu.oauth2.client.request.OAuthBearerClientRequest;import org.apache.oltu.oauth2.client.request.OAuthClientRequest;import org.apache.oltu.oauth2.client.response.OAuthResourceResponse;import org.apache.oltu.oauth2.common.OAuth;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;/** * @author: wangsaichao * @date: 2018/5/29 * @description: 通过access_token获取用户信息 */@Controller@RequestMapping("/oauth-client")public class GetUserInfoController &#123; @Value("$&#123;userInfoUrl&#125;") private String userInfoUrl; //接受服务端传回来的access token，由此token去请求服务端的资源（用户信息等） @RequestMapping("/getUserInfo") @ResponseBody public String accessToken(String accessToken) &#123; OAuthClient oAuthClient =new OAuthClient(new URLConnectionClient()); try &#123; OAuthClientRequest userInfoRequest =new OAuthBearerClientRequest(userInfoUrl) .setAccessToken(accessToken).buildQueryMessage(); OAuthResourceResponse resourceResponse =oAuthClient.resource(userInfoRequest, OAuth.HttpMethod.GET, OAuthResourceResponse.class); String body = resourceResponse.getBody(); System.out.println("==&gt; 客户端通过accessToken："+accessToken +" 从服务端获取用户信息为："+body); return body; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 3、测试1、首先访问客户端http://localhost:9080/oauth-client/getCode 会重定向到服务端让你输入账号密码授权2、输入用户名进行登录并授权；3、如果登录成功，服务端会重定向到客户端，即之前客户端提供的地址http://localhost:9080/oauth-client/callbackCode?code=98872aeb79889bc27be46da76a204aa3，并带着auth code过去；4、方法内部拿到code之后 会调用服务端获取access_token 然后重定向到客户端的获取用户信息方法5、获取用户信息方法内调用服务端 并传过去 access_token 获取用户名,然后展示到页面 控制台打印日志 到此流程结束,此处的客户端 服务端 比较简单,还有很多没有做 比如根据scope 获取不同的级别的用户信息,请求的验签等等。]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes使用教程]]></title>
    <url>%2Fblog%2F2019%2F07%2F13%2F%E4%BA%91%E8%AE%A1%E7%AE%97%2Fk8s%2F</url>
    <content type="text"><![CDATA[Kubernetes 是 Google 2014 年创建管理的，是 Google 10 多年大规模容器管理技术 Borg 的开源版本。Kubernetes 是容器集群管理系统，是一个开源的平台，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。使用 Kubernetes 我们可以： 快速部署应用 快速扩展应用 无缝对接新的应用功能 节省资源，优化硬件资源的使用 Kubernetes 的目标是促进完善组件和工具的生态系统，以减轻应用程序在公有云或私有云中运行的负担。 特点 可移植： 支持公有云，私有云，混合云，多重云（多个公共云） 可扩展： 模块化，插件化，可挂载，可组合 自动化： 自动部署，自动重启，自动复制，自动伸缩/扩展 从传统到容器化部署 传统的部署方式传统的应用部署方式是通过插件或脚本来安装应用。这样做的缺点是应用的运行、配置、管理、所有生存周期将与当前操作系统绑定，这样做并不利于应用的升级更新/回滚等操作，当然也可以通过创建虚机的方式来实现某些功能，但是虚拟机非常重，并不利于可移植性。 容器化部署的优势 快速创建/部署应用： 与虚拟机相比，容器镜像的创建更加容易。 持续开发、集成和部署： 提供可靠且频繁的容器镜像构建/部署，并使用快速和简单的回滚(由于镜像不可变性)。 开发和运行相分离： 在 build 或者 release 阶段创建容器镜像，使得应用和基础设施解耦。 开发，测试和生产环境一致性： 在本地或外网（生产环境）运行的一致性。 云平台或其他操作系统： 可以在 Ubuntu、RHEL、CoreOS、on-prem、Google Container Engine 或其它任何环境中运行。 分布式，弹性，微服务化： 应用程序分为更小的、独立的部件，可以动态部署和管理。 资源隔离 资源利用更高效 为什么需要 Kubernetes可以在物理或虚拟机的 Kubernetes 集群上运行容器化应用，Kubernetes 能提供一个以 “容器为中心的基础架构”，满足在生产环境中运行应用的一些常见需求，如： 多个进程协同工作 存储系统挂载 应用健康检查 应用实例的复制 自动伸缩/扩展 注册与发现 负载均衡 滚动更新 资源监控 日志访问 调试应用程序 提供认证和授权 Kubernetes 安装前的准备概述本次安装采用 Ubuntu Server X64 18.04 LTS 版本安装 kubernetes 集群环境，集群节点为 1 主 2 从模式，此次对虚拟机会有些基本要求，如下： OS：Ubuntu Server X64 18.04 LTS（16.04 版本步骤相同，再之前则不同） CPU：最低要求，1 CPU 2 核 内存：最低要求，2GB 磁盘：最低要求，20GB 创建三台虚拟机，分别命名如下： Ubuntu Server 18.04 X64 Kubernetes Master Ubuntu Server 18.04 X64 Kubernetes Slave1 Ubuntu Server 18.04 X64 Kubernetes Slave2 对虚拟机系统的配置： 关闭交换空间：sudo swapoff -a 避免开机启动交换空间：注释 /etc/fstab 中的 swap 关闭防火墙：ufw disable 使用 APT 安装 Docker安装123456789101112# 更新软件源sudo apt-get update# 安装所需依赖sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common# 安装 GPG 证书curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# 新增软件源信息sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"# 再次更新软件源sudo apt-get -y update# 安装 Docker CE 版sudo apt-get -y install docker-ce 验证12345678910111213141516171819docker versionClient: Version: 18.09.6 API version: 1.39 Go version: go1.10.8 Git commit: 481bc77 Built: Sat May 4 02:35:57 2019 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.6 API version: 1.39 (minimum version 1.12) Go version: go1.10.8 Git commit: 481bc77 Built: Sat May 4 01:59:36 2019 OS/Arch: linux/amd64 Experimental: false 配置加速器对于使用 systemd 的系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件） 12345&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125; 注意，一定要保证该文件符合 JSON 规范，否则 Docker 将不能启动。 验证加速器是否配置成功： 1234567sudo systemctl restart dockerdocker info...# 出现如下语句即表示配置成功Registry Mirrors: https://registry.docker-cn.com/... 修改主机名在同一局域网中主机名不应该相同，所以我们需要做修改，下列操作步骤为修改 18.04 版本的 Hostname，如果是 16.04 或以下版本则直接修改 /etc/hostname 里的名称即可 查看当前 Hostname 123456789101112# 查看当前主机名hostnamectl# 显示如下内容 Static hostname: ubuntu Icon name: computer-vm Chassis: vm Machine ID: 33011e0a95094672b99a198eff07f652 Boot ID: dc856039f0d24164a9f8a50c506be96d Virtualization: vmware Operating System: Ubuntu 18.04.2 LTS Kernel: Linux 4.15.0-48-generic Architecture: x86-64 修改 Hostname 12# 使用 hostnamectl 命令修改，其中 kubernetes-master 为新的主机名hostnamectl set-hostname kubernetes-master 修改 cloud.cfg 如果 cloud-init package 安装了，需要修改 cloud.cfg 文件。该软件包通常缺省安装用于处理 cloud 12345# 如果有该文件vi /etc/cloud/cloud.cfg# 该配置默认为 false，修改为 true 即可preserve_hostname: true 验证 12345678910root@kubernetes-master:~# hostnamectl Static hostname: kubernetes-master Icon name: computer-vm Chassis: vm Machine ID: 33011e0a95094672b99a198eff07f652 Boot ID: 8c0fd75d08c644abaad3df565e6e4cbd Virtualization: vmware Operating System: Ubuntu 18.04.2 LTS Kernel: Linux 4.15.0-48-generic Architecture: x86-64 安装 kubeadm概述kubeadm 是 kubernetes 的集群安装工具，能够快速安装 kubernetes 集群。 配置软件源12345678# 安装系统工具apt-get update &amp;&amp; apt-get install -y apt-transport-https# 安装 GPG 证书curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -# 写入软件源；注意：我们用系统代号为 bionic，但目前阿里云不支持，所以沿用 16.04 的 xenialcat &lt;&lt; EOF &gt;/etc/apt/sources.list.d/kubernetes.list&gt; deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main&gt; EOF 安装 kubeadm，kubelet，kubectl12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 安装apt-get update apt-get install -y kubelet kubeadm kubectl# 安装过程如下，注意 kubeadm 的版本号Reading package lists... DoneBuilding dependency tree Reading state information... DoneThe following additional packages will be installed: conntrack cri-tools kubernetes-cni socatThe following NEW packages will be installed: conntrack cri-tools kubeadm kubectl kubelet kubernetes-cni socat0 upgraded, 7 newly installed, 0 to remove and 96 not upgraded.Need to get 50.6 MB of archives.After this operation, 290 MB of additional disk space will be used.Get:1 http://mirrors.aliyun.com/ubuntu bionic/main amd64 conntrack amd64 1:1.4.4+snapshot20161117-6ubuntu2 [30.6 kB]Get:2 http://mirrors.aliyun.com/ubuntu bionic/main amd64 socat amd64 1.7.3.2-2ubuntu2 [342 kB]Get:3 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 cri-tools amd64 1.12.0-00 [5,343 kB]Get:4 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubernetes-cni amd64 0.7.5-00 [6,473 kB]Get:5 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubelet amd64 1.14.1-00 [21.5 MB]Get:6 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubectl amd64 1.14.1-00 [8,806 kB]Get:7 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubeadm amd64 1.14.1-00 [8,150 kB]Fetched 50.6 MB in 5s (9,912 kB/s) Selecting previously unselected package conntrack.(Reading database ... 67205 files and directories currently installed.)Preparing to unpack .../0-conntrack_1%3a1.4.4+snapshot20161117-6ubuntu2_amd64.deb ...Unpacking conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ...Selecting previously unselected package cri-tools.Preparing to unpack .../1-cri-tools_1.12.0-00_amd64.deb ...Unpacking cri-tools (1.12.0-00) ...Selecting previously unselected package kubernetes-cni.Preparing to unpack .../2-kubernetes-cni_0.7.5-00_amd64.deb ...Unpacking kubernetes-cni (0.7.5-00) ...Selecting previously unselected package socat.Preparing to unpack .../3-socat_1.7.3.2-2ubuntu2_amd64.deb ...Unpacking socat (1.7.3.2-2ubuntu2) ...Selecting previously unselected package kubelet.Preparing to unpack .../4-kubelet_1.14.1-00_amd64.deb ...Unpacking kubelet (1.14.1-00) ...Selecting previously unselected package kubectl.Preparing to unpack .../5-kubectl_1.14.1-00_amd64.deb ...Unpacking kubectl (1.14.1-00) ...Selecting previously unselected package kubeadm.Preparing to unpack .../6-kubeadm_1.14.1-00_amd64.deb ...Unpacking kubeadm (1.14.1-00) ...Setting up conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ...Setting up kubernetes-cni (0.7.5-00) ...Setting up cri-tools (1.12.0-00) ...Setting up socat (1.7.3.2-2ubuntu2) ...Setting up kubelet (1.14.1-00) ...Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /lib/systemd/system/kubelet.service.Setting up kubectl (1.14.1-00) ...Processing triggers for man-db (2.8.3-2ubuntu0.1) ...# 注意这里的版本号，我们使用的是 kubernetes v1.14.1Setting up kubeadm (1.14.1-00) ...# 设置 kubelet 自启动，并启动 kubeletsystemctl enable kubelet &amp;&amp; systemctl start kubelet kubeadm：用于初始化 Kubernetes 集群 kubectl：Kubernetes 的命令行工具，主要作用是部署和管理应用，查看各种资源，创建，删除和更新组件 kubelet：主要负责启动 Pod 和容器 配置 kubeadm安装 kubernetes 主要是安装它的各个镜像，而 kubeadm 已经为我们集成好了运行 kubernetes 所需的基本镜像。但由于国内的网络原因，在搭建环境时，无法拉取到这些镜像。此时我们只需要修改为阿里云提供的镜像服务即可解决该问题。 创建并修改配置12# 导出配置文件kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 修改配置为如下内容apiVersion: kubeadm.k8s.io/v1beta1bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: # 修改为主节点 IP advertiseAddress: 192.168.141.130 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: kubernetes-master taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta1certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrolPlaneEndpoint: ""controllerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcd# 国内不能访问 Google，修改为阿里云imageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfiguration# 修改版本号kubernetesVersion: v1.14.1networking: dnsDomain: cluster.local # 配置成 Calico 的默认网段 podSubnet: "192.168.0.0/16" serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;---# 开启 IPVS 模式apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs 查看和拉取镜像1234# 查看所需镜像列表kubeadm config images list --config kubeadm.yml# 拉取镜像kubeadm config images pull --config kubeadm.yml 使用 kubeadm 搭建 kubernetes 集群安装 kubernetes 主节点执行以下命令初始化主节点，该命令指定了初始化时需要使用的配置文件，其中添加 --experimental-upload-certs 参数可以在后续执行加入节点时自动分发证书文件。追加的 tee kubeadm-init.log 用以输出日志。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172kubeadm init --config=kubeadm.yml --experimental-upload-certs | tee kubeadm-init.log# 安装成功则会有如下输出[init] Using Kubernetes version: v1.14.1[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Activating the kubelet service[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "ca" certificate and key[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [kubernetes-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.141.130][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "front-proxy-ca" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "etcd/ca" certificate and key[certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [kubernetes-master localhost] and IPs [192.168.141.130 127.0.0.1 ::1][certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [kubernetes-master localhost] and IPs [192.168.141.130 127.0.0.1 ::1][certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "apiserver-etcd-client" certificate and key[certs] Generating "sa" key and public key[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[kubeconfig] Writing "admin.conf" kubeconfig file[kubeconfig] Writing "kubelet.conf" kubeconfig file[kubeconfig] Writing "controller-manager.conf" kubeconfig file[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s[apiclient] All control plane components are healthy after 20.003326 seconds[upload-config] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.14" in namespace kube-system with the configuration for the kubelets in the cluster[upload-certs] Storing the certificates in ConfigMap "kubeadm-certs" in the "kube-system" Namespace[upload-certs] Using certificate key:2cd5b86c4905c54d68cc7dfecc2bf87195e9d5d90b4fff9832d9b22fc5e73f96[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: abcdef.0123456789abcdef[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] creating the "cluster-info" ConfigMap in the "kube-public" namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:# 后面子节点加入需要如下命令kubeadm join 192.168.141.130:6443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:cab7c86212535adde6b8d1c7415e81847715cfc8629bb1d270b601744d662515 注意：如果安装 kubernetes 版本和下载的镜像版本不统一则会出现 timed out waiting for the condition 错误。中途失败或是想修改配置可以使用 kubeadm reset 命令重置配置，再做初始化操作即可。 配置 kubectl12345mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/config# 非 ROOT 用户执行chown $(id -u):$(id -g) $HOME/.kube/config 验证是否成功12345kubectl get node# 能够打印出节点信息即表示成功NAME STATUS ROLES AGE VERSIONkubernetes-master NotReady master 8m40s v1.14.1 至此主节点配置完成 kubeadm init 的执行过程 init：指定版本进行初始化操作 preflight：初始化前的检查和下载所需要的 Docker 镜像文件 kubelet-start：生成 kubelet 的配置文件 var/lib/kubelet/config.yaml，没有这个文件 kubelet 无法启动，所以初始化之前的 kubelet 实际上启动不会成功 certificates：生成 Kubernetes 使用的证书，存放在 /etc/kubernetes/pki 目录中 kubeconfig：生成 KubeConfig 文件，存放在 /etc/kubernetes 目录中，组件之间通信需要使用对应文件 control-plane：使用 /etc/kubernetes/manifest 目录下的 YAML 文件，安装 Master 组件 etcd：使用 /etc/kubernetes/manifest/etcd.yaml 安装 Etcd 服务 wait-control-plane：等待 control-plan 部署的 Master 组件启动 apiclient：检查 Master 组件服务状态。 uploadconfig：更新配置 kubelet：使用 configMap 配置 kubelet patchnode：更新 CNI 信息到 Node 上，通过注释的方式记录 mark-control-plane：为当前节点打标签，打了角色 Master，和不可调度标签，这样默认就不会使用 Master 节点来运行 Pod bootstrap-token：生成 token 记录下来，后边使用 kubeadm join 往集群中添加节点时会用到 addons：安装附加组件 CoreDNS 和 kube-proxy 使用 kubeadm 配置 slave 节点概述将 slave 节点加入到集群中很简单，只需要在 slave 服务器上安装 kubeadm，kubectl，kubelet 三个工具，然后使用 kubeadm join 命令加入即可。准备工作如下： 修改主机名 配置软件源 安装三个工具 由于之前章节已经说明了操作步骤，此处不再赘述。 将 slave 加入到集群123456789101112131415161718kubeadm join 192.168.141.130:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:cab7c86212535adde6b8d1c7415e81847715cfc8629bb1d270b601744d662515# 安装成功将看到如下信息[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.14" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Activating the kubelet service[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 说明： token 可以通过安装 master 时的日志查看 token 信息 可以通过 kubeadm token list 命令打印出 token 信息 如果 token 过期，可以使用 kubeadm token create 命令创建新的 token discovery-token-ca-cert-hash 可以通过安装 master 时的日志查看 sha256 信息 可以通过 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39;命令查看 sha256 信息 以上方式感谢群友 停 驻 提供。 验证是否成功回到 master 服务器 123456kubectl get nodes# 可以看到 slave 成功加入 masterNAME STATUS ROLES AGE VERSIONkubernetes-master NotReady master 9h v1.14.1kubernetes-slave1 NotReady &lt;none&gt; 22s v1.14.1 如果 slave 节点加入 master 时配置有问题可以在 slave 节点上使用 kubeadm reset 重置配置再使用 kubeadm join 命令重新加入即可。希望在 master 节点删除 node ，可以使用 kubeadm delete nodes &lt;NAME&gt; 删除。 查看 pod 状态1234567891011kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-8686dcc4fd-gwrmb 0/1 Pending 0 9h &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;coredns-8686dcc4fd-j6gfk 0/1 Pending 0 9h &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;etcd-kubernetes-master 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt;kube-apiserver-kubernetes-master 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt;kube-controller-manager-kubernetes-master 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt;kube-proxy-496dr 1/1 Running 0 17m 192.168.141.131 kubernetes-slave1 &lt;none&gt; &lt;none&gt;kube-proxy-rsnb6 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt;kube-scheduler-kubernetes-master 1/1 Running 1 9h 192.168.141.130 kubernetes-master &lt;none&gt; &lt;none&gt; 由此可以看出 coredns 尚未运行，此时我们还需要安装网络插件。 配置网络容器网络是容器选择连接到其他容器、主机和外部网络的机制。容器的 runtime 提供了各种网络模式，每种模式都会产生不同的体验。例如，Docker 默认情况下可以为容器配置以下网络： none： 将容器添加到一个容器专门的网络堆栈中，没有对外连接。 host： 将容器添加到主机的网络堆栈中，没有隔离。 default bridge： 默认网络模式。每个容器可以通过 IP 地址相互连接。 自定义网桥： 用户定义的网桥，具有更多的灵活性、隔离性和其他便利功能。 什么是 CNICNI(Container Network Interface) 是一个标准的，通用的接口。在容器平台，Docker，Kubernetes，Mesos 容器网络解决方案 flannel，calico，weave。只要提供一个标准的接口，就能为同样满足该协议的所有容器平台提供网络功能，而 CNI 正是这样的一个标准接口协议。 Kubernetes 中的 CNI 插件CNI 的初衷是创建一个框架，用于在配置或销毁容器时动态配置适当的网络配置和资源。插件负责为接口配置和管理 IP 地址，并且通常提供与 IP 管理、每个容器的 IP 分配、以及多主机连接相关的功能。容器运行时会调用网络插件，从而在容器启动时分配 IP 地址并配置网络，并在删除容器时再次调用它以清理这些资源。 运行时或协调器决定了容器应该加入哪个网络以及它需要调用哪个插件。然后，插件会将接口添加到容器网络命名空间中，作为一个 veth 对的一侧。接着，它会在主机上进行更改，包括将 veth 的其他部分连接到网桥。再之后，它会通过调用单独的 IPAM（IP地址管理）插件来分配 IP 地址并设置路由。 在 Kubernetes 中，kubelet 可以在适当的时间调用它找到的插件，为通过 kubelet 启动的 pod进行自动的网络配置。 Kubernetes 中可选的 CNI 插件如下： Flannel Calico Canal Weave 什么是 CalicoCalico 为容器和虚拟机提供了安全的网络连接解决方案，并经过了大规模生产验证（在公有云和跨数千个集群节点中），可与 Kubernetes，OpenShift，Docker，Mesos，DC / OS 和 OpenStack 集成。 Calico 还提供网络安全规则的动态实施。使用 Calico 的简单策略语言，您可以实现对容器，虚拟机工作负载和裸机主机端点之间通信的细粒度控制。 安装网络插件 Calico 注意：截止到文章发表日期 2019 年 05 月 11 日，Calico 官方版本为 3.7 参考官方文档安装：https://docs.projectcalico.org/v3.7/getting-started/kubernetes/ 123456789101112131415161718192021222324252627# 在 Master 节点操作即可kubectl apply -f https://docs.projectcalico.org/v3.7/manifests/calico.yaml# 安装时显示如下输出configmap/calico-config createdcustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org createdclusterrole.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrole.rbac.authorization.k8s.io/calico-node createdclusterrolebinding.rbac.authorization.k8s.io/calico-node createddaemonset.extensions/calico-node createdserviceaccount/calico-node createddeployment.extensions/calico-kube-controllers createdserviceaccount/calico-kube-controllers created 确认安装是否成功 123456789101112131415watch kubectl get pods --all-namespaces# 需要等待所有状态为 Running，注意时间可能较久，3 - 5 分钟的样子Every 2.0s: kubectl get pods --all-namespaces kubernetes-master: Fri May 10 18:16:51 2019NAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-8646dd497f-g2lln 1/1 Running 0 50mkube-system calico-node-8jrtp 1/1 Running 0 50mkube-system coredns-8686dcc4fd-mhwfn 1/1 Running 0 51mkube-system coredns-8686dcc4fd-xsxwk 1/1 Running 0 51mkube-system etcd-kubernetes-master 1/1 Running 0 50mkube-system kube-apiserver-kubernetes-master 1/1 Running 0 51mkube-system kube-controller-manager-kubernetes-master 1/1 Running 0 51mkube-system kube-proxy-p8mdw 1/1 Running 0 51mkube-system kube-scheduler-kubernetes-master 1/1 Running 0 51m 至此基本环境已部署完毕。 解决 ImagePullBackOff在使用 watch kubectl get pods --all-namespaces 命令观察 Pods 状态时如果出现 ImagePullBackOff 无法 Running 的情况，请尝试使用如下步骤处理： Master 中删除 Nodes：kubeadm delete nodes &lt;NAME&gt; Slave 中重置配置：kubeadm reset Slave 重启计算机：reboot Slave 重新加入集群：kubeadm join 附：配置固定 IP 和 DNS当关机后再启动虚拟机有时 IP 地址会自动更换，导致之前的配置不可用；配置完 Kubernetes 网络后虚拟机还会出现无法联网的情况，后经研究发现是 DNS 会被自动重写所致，Ubuntu Server 18.04 LTS 版本的 IP 和 DNS 配置也与之前的版本配置大相径庭，故在此说明下如何修改 IP 和 DNS 修改固定 IP编辑 vi /etc/netplan/50-cloud-init.yaml 配置文件，注意这里的配置文件名未必和你机器上的相同，请根据实际情况修改。修改内容如下： 12345678network: ethernets: ens33: addresses: [192.168.141.134/24] gateway4: 192.168.141.2 nameservers: addresses: [192.168.141.2] version: 2 使配置生效 netplan apply 修改 DNS方法一 停止 systemd-resolved 服务：systemctl stop systemd-resolved 修改 DNS：vi /etc/resolv.conf，将 nameserver 修改为如 114.114.114.114 可以正常使用的 DNS 地址 方法二1vi /etc/systemd/resolved.conf 把 DNS 取消注释，添加 DNS，保存退出，重启即可 第一个 Kubernetes 容器检查组件运行状态12345678910kubectl get cs# 输出如下NAME STATUS MESSAGE ERROR# 调度服务，主要作用是将 POD 调度到 Nodescheduler Healthy ok # 自动化修复服务，主要作用是 Node 宕机后自动修复 Node 回到正常的工作状态controller-manager Healthy ok # 服务注册与发现etcd-0 Healthy &#123;"health":"true"&#125; 检查 Master 状态123456789kubectl cluster-info# 输出如下# 主节点状态Kubernetes master is running at https://192.168.141.130:6443# DNS 状态KubeDNS is running at https://192.168.141.130:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxyTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. 检查 Nodes 状态1234567kubectl get nodes# 输出如下，STATUS 为 Ready 即为正常状态NAME STATUS ROLES AGE VERSIONkubernetes-master Ready master 44h v1.14.1kubernetes-slave1 Ready &lt;none&gt; 3h38m v1.14.1kubernetes-slave2 Ready &lt;none&gt; 3h37m v1.14.1 运行第一个容器实例1234567# 使用 kubectl 命令创建两个监听 80 端口的 Nginx Pod（Kubernetes 运行容器的最小单元）# 80是内网的端口，启动两个副本kubectl run nginx --image=nginx --replicas=2 --port=80# 输出如下kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.deployment.apps/nginx created 查看全部 Pods 的状态123456kubectl get pods# 输出如下，需要等待一小段实践，STATUS 为 Running 即为运行成功NAME READY STATUS RESTARTS AGEnginx-755464dd6c-qnmwp 1/1 Running 0 90mnginx-755464dd6c-shqrp 1/1 Running 0 90m 查看已部署的服务12345kubectl get deployment# 输出如下NAME READY UP-TO-DATE AVAILABLE AGEnginx 2/2 2 2 91m 映射服务，让用户可以访问12345#暴露80端口以负载均衡方式kubectl expose deployment nginx --port=80 --type=LoadBalancer# 输出如下service/nginx exposed 查看已发布的服务1234567kubectl get services# 输出如下NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 44h# 由此可见，Nginx 服务已成功发布并将 80 端口映射为 31738nginx LoadBalancer 10.108.121.244 &lt;pending&gt; 80:31738/TCP 88m 查看服务详情1234567891011121314151617kubectl describe service nginx# 输出如下Name: nginxNamespace: defaultLabels: run=nginxAnnotations: &lt;none&gt;Selector: run=nginxType: LoadBalancerIP: 10.108.121.244Port: &lt;unset&gt; 80/TCPTargetPort: 80/TCPNodePort: &lt;unset&gt; 31738/TCPEndpoints: 192.168.17.5:80,192.168.8.134:80Session Affinity: NoneExternal Traffic Policy: ClusterEvents: &lt;none&gt; 验证是否成功通过浏览器访问 Master 服务器 1http://192.168.141.130:31738/ 此时 Kubernetes 会以负载均衡的方式访问部署的 Nginx 服务，能够正常看到 Nginx 的欢迎页即表示成功。容器实际部署在其它 Node 节点上，通过访问 Node 节点的 IP:Port 也是可以的。 停止服务1234kubectl delete deployment nginx# 输出如下deployment.extensions "nginx" deleted 1234kubectl delete service nginx# 输出如下service "nginx" deleted 概念总结 总结什么是 KubernetesKubernetes 是一个开源的 Docker 容器编排系统，它可以调度计算集群的节点，动态管理上面的作业，保证它们按用户期望的状态运行。通过使用「labels」和「pods」的概念，Kubernetes 将应用按逻辑单元进行分组，方便管理和服务发现。 容器编排工具，为了实现高可用，容器隔离 pods： 是一组紧密关联的容器集合，它们共享 IPC(进程间通信)、Network(网络) 和 UTS namespace(UTS 命名空间是 Linux 命名空间的一个子系统，主要作用是完成对容器 Hostname 和 Domain 的隔离，同时保存内核名称、版本、以及底层体系结构类型等信息)，是 Kubernetes 调度的基本单位。 labels： 键值对(key/value)标签，可以被关联到如 Pod 这样的对象上，主要作用是给用户一个直观的感受，比如这个 Pod 是用来放置数据库的 GUI： 用户图形界面，可以是 Web 用户界面，比如使用 kubernetes-dashboard 组件，用户可以通过 Dashboard 在 Kubernetes 集群中部署容器化的应用，可以查看集群中应用的运行情况，同时也能够基于 Dashboard 创建或修改部署、任务、服务等 Kubernetes 的资源。通过部署向导，用户能够对部署进行扩缩容，进行滚动更新、重启 Pod 和部署新应用。当然，通过 Dashboard 也能够查看 Kubernetes 资源的状态 kubectl： 用于管理 Kubernetes 集群的命令行工具 kube-apiserver： 提供了资源操作的唯一入口，并提供认证、授权（RBCA）、访问控制、API 注册和发现等机制 Kubernetes Master： Kubernetes 集群主节点，主要由 kube-apiserver、kube-scheduler（调度）、kube-controller-manager（管理pods生命周期）、etcd（服务注册与发现） 四个模块组成 Kubernetes Node： Kubernetes 集群子节点，主要由 kubelet（也是容器生命周期管理，帮助你在外界因素容器挂掉后自动重启）、kube-proxy（k8s组成一个巨大的内网，内网的端口是不向外暴露的，进入需要代理）、runtime（容器引擎，docker） 三个模块组成 Image Registry： 镜像仓库，比如：Ducker HUB 或 Docker 私服 Kubernetes Master kube-apiserver： 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制 kube-scheduler： 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上 kube-controller-manager： 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 etcd： CoreOS 基于 Raft 开发的分布式 key-value 存储，可用于服务发现、共享配置以及一致性保障（如数据库选主、分布式锁等） Kubernetes Node runtime： 负责镜像管理以及 Pod 和容器的真正运行（CRI，Container Runtime Interface），默认的容器运行时为 Docker，还支持 RKT 容器 kubelet： 负责维持容器的生命周期，同时也负责 Volume数据卷（CVI，Container Volume Interface）和网络（CNI，Container Network Interface）的管理 kube-proxy： 负责为 Service 提供 cluster 内部的服务发现和负载均衡 job Kubernetes 架构 Kubernetes 高可用集群概述在入门课程中我们部署的 Kubernetes 是 集群模式，但在实际生产中我们需要部署 高可用集群 ，本章内容旨在指导大家如何部署 Kubernetes 高可用集群 统一环境配置节点配置 主机名 IP 角色 系统 CPU/内存 磁盘 kubernetes-master-01 192.168.141.150 Master Ubuntu Server 18.04 2核2G 20G kubernetes-master-02 192.168.141.151 Master Ubuntu Server 18.04 2核2G 20G kubernetes-master-03 192.168.141.152 Master Ubuntu Server 18.04 2核2G 20G kubernetes-node-01 192.168.141.160 Node Ubuntu Server 18.04 2核4G 20G kubernetes-node-02 192.168.141.161 Node Ubuntu Server 18.04 2核4G 20G kubernetes-node-03 192.168.141.162 Node Ubuntu Server 18.04 2核4G 20G Kubernetes VIP 192.168.141.200 - - - - 对操作系统的配置 特别注意：以下步骤请在制作 VMware 镜像时一并完成，避免逐台安装的痛苦 关闭交换空间1swapoff -a 避免开机启动交换空间12# 注释 swap 开头的行vi /etc/fstab 关闭防火墙1ufw disable 配置 DNS12# 取消 DNS 行注释，并增加 DNS 配置如：114.114.114.114，修改后重启下计算机vi /etc/systemd/resolved.conf 安装 Docker123456789101112# 更新软件源sudo apt-get update# 安装所需依赖sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common# 安装 GPG 证书curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# 新增软件源信息sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"# 再次更新软件源sudo apt-get -y update# 安装 Docker CE 版sudo apt-get -y install docker-ce 配置 Docker 加速器 特别注意：国内镜像加速器可能会很卡，请替换成你自己阿里云镜像加速器，地址如：https://yourself.mirror.aliyuncs.com，在阿里云控制台的 容器镜像服务 -&gt; 镜像加速器 菜单中可以找到 在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件） 12345&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125; 安装 kubeadm，kubelet，kubectl12345678910111213# 安装系统工具apt-get update &amp;&amp; apt-get install -y apt-transport-https# 安装 GPG 证书curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -# 写入软件源；注意：我们用系统代号为 bionic，但目前阿里云不支持，所以沿用 16.04 的 xenialcat &lt;&lt; EOF &gt;/etc/apt/sources.list.d/kubernetes.list&gt; deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main&gt; EOF# 安装apt-get update &amp;&amp; apt-get install -y kubelet kubeadm kubectl 同步时间设置时区 1dpkg-reconfigure tzdata 选择 Asia（亚洲） 选择 Shanghai（上海） 时间同步 12345678# 安装 ntpdateapt-get install ntpdate# 设置系统时间与网络时间同步（cn.pool.ntp.org 位于中国的公共 NTP 服务器）ntpdate cn.pool.ntp.org# 将系统时间写入硬件时间hwclock --systohc 确认时间 1234date# 输出如下（自行对照与系统时间是否一致）Sun Jun 2 22:02:35 CST 2019 配置 IPVS123456789101112131415161718192021222324252627# 安装系统工具apt-get install -y ipset ipvsadm# 配置并加载 IPVS 模块mkdir -p /etc/sysconfig/modules/vi /etc/sysconfig/modules/ipvs.modules# 输入如下内容#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4# 执行脚本，注意：如果重启则需要重新运行该脚本chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4# 执行脚本输出如下ip_vs_sh 16384 0ip_vs_wrr 16384 0ip_vs_rr 16384 0ip_vs 147456 6 ip_vs_rr,ip_vs_sh,ip_vs_wrrnf_conntrack_ipv4 16384 3nf_defrag_ipv4 16384 1 nf_conntrack_ipv4nf_conntrack 131072 8 xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_ipv4,nf_nat,ipt_MASQUERADE,nf_nat_ipv4,nf_conntrack_netlink,ip_vslibcrc32c 16384 4 nf_conntrack,nf_nat,raid456,ip_vs 配置内核参数123456789101112131415161718192021222324252627282930313233343536373839404142434445# 配置参数vi /etc/sysctl.d/k8s.conf# 输入如下内容net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_nonlocal_bind = 1net.ipv4.ip_forward = 1vm.swappiness=0# 应用参数sysctl --system# 应用参数输出如下（找到 Applying /etc/sysctl.d/k8s.conf 开头的日志）* Applying /etc/sysctl.d/10-console-messages.conf ...kernel.printk = 4 4 1 7* Applying /etc/sysctl.d/10-ipv6-privacy.conf ...* Applying /etc/sysctl.d/10-kernel-hardening.conf ...kernel.kptr_restrict = 1* Applying /etc/sysctl.d/10-link-restrictions.conf ...fs.protected_hardlinks = 1fs.protected_symlinks = 1* Applying /etc/sysctl.d/10-lxd-inotify.conf ...fs.inotify.max_user_instances = 1024* Applying /etc/sysctl.d/10-magic-sysrq.conf ...kernel.sysrq = 176* Applying /etc/sysctl.d/10-network-security.conf ...net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.all.rp_filter = 1net.ipv4.tcp_syncookies = 1* Applying /etc/sysctl.d/10-ptrace.conf ...kernel.yama.ptrace_scope = 1* Applying /etc/sysctl.d/10-zeropage.conf ...vm.mmap_min_addr = 65536* Applying /usr/lib/sysctl.d/50-default.conf ...net.ipv4.conf.all.promote_secondaries = 1net.core.default_qdisc = fq_codel* Applying /etc/sysctl.d/99-sysctl.conf ...* Applying /etc/sysctl.d/k8s.conf ...net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_nonlocal_bind = 1net.ipv4.ip_forward = 1vm.swappiness = 0* Applying /etc/sysctl.conf ... 修改 cloud.cfg1234vi /etc/cloud/cloud.cfg# 该配置默认为 false，修改为 true 即可preserve_hostname: true 单独节点配置 特别注意：为 Master 和 Node 节点单独配置对应的 IP 和 主机名 配置 IP编辑 vi /etc/netplan/50-cloud-init.yaml 配置文件，修改内容如下 123456789network: ethernets: ens33: # 我的 Master 是 150 - 152，Node 是 160 - 162 addresses: [192.168.141.150/24] gateway4: 192.168.141.2 nameservers: addresses: [192.168.141.2] version: 2 使用 netplan apply 命令让配置生效 配置主机名1234567# 修改主机名hostnamectl set-hostname kubernetes-master-01# 配置 hostscat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.141.150 kubernetes-master-01EOF 安装 HAProxy + Keepalived概述Kubernetes Master 节点运行组件如下： kube-apiserver： 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制 kube-scheduler： 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上 kube-controller-manager： 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 etcd： CoreOS 基于 Raft 开发的分布式 key-value 存储，可用于服务发现、共享配置以及一致性保障（如数据库选主、分布式锁等） kube-scheduler 和 kube-controller-manager 可以以集群模式运行，通过 leader 选举产生一个工作进程，其它进程处于阻塞模式。 kube-apiserver 可以运行多个实例，但对其它组件需要提供统一的访问地址，本章节部署 Kubernetes 高可用集群实际就是利用 HAProxy + Keepalived 配置该组件 配置的思路就是利用 HAProxy + Keepalived 实现 kube-apiserver 虚拟 IP 访问从而实现高可用和负载均衡，拆解如下： Keepalived 提供 kube-apiserver 对外服务的虚拟 IP（VIP） HAProxy 监听 Keepalived VIP 运行 Keepalived 和 HAProxy 的节点称为 LB（负载均衡） 节点 Keepalived 是一主多备运行模式，故至少需要两个 LB 节点 Keepalived 在运行过程中周期检查本机的 HAProxy 进程状态，如果检测到 HAProxy 进程异常，则触发重新选主的过程，VIP 将飘移到新选出来的主节点，从而实现 VIP 的高可用 所有组件（如 kubeclt、apiserver、controller-manager、scheduler 等）都通过 VIP +HAProxy 监听的 6444 端口访问 kube-apiserver 服务（注意：kube-apiserver 默认端口为 6443，为了避免冲突我们将 HAProxy 端口设置为 6444，其它组件都是通过该端口统一请求 apiserver） 创建 HAProxy 启动脚本 该步骤在 kubernetes-master-01 执行 12345678910111213141516171819202122mkdir -p /usr/local/kubernetes/lbvi /usr/local/kubernetes/lb/start-haproxy.sh# 输入内容如下#!/bin/bash# 修改为你自己的 Master 地址MasterIP1=192.168.141.150MasterIP2=192.168.141.151MasterIP3=192.168.141.152# 这是 kube-apiserver 默认端口，不用修改MasterPort=6443# 容器将 HAProxy 的 6444 端口暴露出去docker run -d --restart=always --name HAProxy-K8S -p 6444:6444 \ -e MasterIP1=$MasterIP1 \ -e MasterIP2=$MasterIP2 \ -e MasterIP3=$MasterIP3 \ -e MasterPort=$MasterPort \ wise2c/haproxy-k8s# 设置权限chmod +x start-haproxy.sh 创建 Keepalived 启动脚本 该步骤在 kubernetes-master-01 执行 123456789101112131415161718192021222324252627282930313233mkdir -p /usr/local/kubernetes/lbvi /usr/local/kubernetes/lb/start-keepalived.sh# 输入内容如下#!/bin/bash# 修改为你自己的虚拟 IP 地址VIRTUAL_IP=192.168.141.200# 虚拟网卡设备名INTERFACE=ens33# 虚拟网卡的子网掩码NETMASK_BIT=24# HAProxy 暴露端口，内部指向 kube-apiserver 的 6443 端口CHECK_PORT=6444# 路由标识符RID=10# 虚拟路由标识符VRID=160# IPV4 多播地址，默认 224.0.0.18MCAST_GROUP=224.0.0.18docker run -itd --restart=always --name=Keepalived-K8S \ --net=host --cap-add=NET_ADMIN \ -e VIRTUAL_IP=$VIRTUAL_IP \ -e INTERFACE=$INTERFACE \ -e CHECK_PORT=$CHECK_PORT \ -e RID=$RID \ -e VRID=$VRID \ -e NETMASK_BIT=$NETMASK_BIT \ -e MCAST_GROUP=$MCAST_GROUP \ wise2c/keepalived-k8s# 设置权限chmod +x start-keepalived.sh 复制脚本到其它 Master 地址分别在 kubernetes-master-02 和 kubernetes-master-03 执行创建工作目录命令 1mkdir -p /usr/local/kubernetes/lb 将 kubernetes-master-01 中的脚本拷贝至其它 Master 12scp start-haproxy.sh start-keepalived.sh 192.168.141.151:/usr/local/kubernetes/lbscp start-haproxy.sh start-keepalived.sh 192.168.141.152:/usr/local/kubernetes/lb 分别在 3 个 Master 中启动容器（执行脚本） 1sh /usr/local/kubernetes/lb/start-haproxy.sh &amp;&amp; sh /usr/local/kubernetes/lb/start-keepalived.sh 验证是否成功查看容器123456docker ps# 输出如下CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf50df479ecae wise2c/keepalived-k8s "/usr/bin/keepalived…" About an hour ago Up About an hour Keepalived-K8S75066a7ed2fb wise2c/haproxy-k8s "/docker-entrypoint.…" About an hour ago Up About an hour 0.0.0.0:6444-&gt;6444/tcp HAProxy-K8S 查看网卡绑定的虚拟 IP123456ip a | grep ens33# 输出如下2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 inet 192.168.141.151/24 brd 192.168.141.255 scope global ens33 inet 192.168.141.200/24 scope global secondary ens33 特别注意：Keepalived 会对 HAProxy 监听的 6444 端口进行检测，如果检测失败即认定本机 HAProxy 进程异常，会将 VIP 漂移到其他节点，所以无论本机 Keepalived 容器异常或 HAProxy 容器异常都会导致 VIP 漂移到其他节点 部署 Kubernetes 集群初始化 Master 创建工作目录并导出配置文件 12345# 创建工作目录mkdir -p /usr/local/kubernetes/cluster# 导出配置文件到工作目录kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml 修改配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152apiVersion: kubeadm.k8s.io/v1beta1bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: # 修改为主节点 IP advertiseAddress: 192.168.141.150 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: kubernetes-master taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta1certificatesDir: /etc/kubernetes/pkiclusterName: kubernetes# 配置 Keepalived 地址和 HAProxy 端口controlPlaneEndpoint: "192.168.141.200:6444"controllerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcd# 国内不能访问 Google，修改为阿里云imageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfiguration# 修改版本号kubernetesVersion: v1.14.2networking: dnsDomain: cluster.local # 配置成 Calico 的默认网段 podSubnet: "192.168.0.0/16" serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;---# 开启 IPVS 模式apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs kubeadm 初始化 12345678910# kubeadm 初始化kubeadm init --config=kubeadm.yml --experimental-upload-certs | tee kubeadm-init.log# 配置 kubectlmkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config# 验证是否成功kubectl get node 安装网络插件 12345# 安装 Calicokubectl apply -f https://docs.projectcalico.org/v3.7/manifests/calico.yaml# 验证安装是否成功watch kubectl get pods --all-namespaces 加入 Master 节点从 kubeadm-init.log 中获取命令，分别将 kubernetes-master-02 和 kubernetes-master-03 加入 Master 1234# 以下为示例命令kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:56d53268517c132ae81c868ce99c44be797148fb2923e59b49d73c99782ff21f \ --experimental-control-plane --certificate-key c4d1525b6cce4b69c11c18919328c826f92e660e040a46f5159431d5ff0545bd 加入 Node 节点从 kubeadm-init.log 中获取命令，分别将 kubernetes-node-01 至 kubernetes-node-03 加入 Node 123# 以下为示例命令kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:56d53268517c132ae81c868ce99c44be797148fb2923e59b49d73c99782ff21f 验证集群状态 查看 Node 1kubectl get nodes -o wide 查看 Pod 1kubectl -n kube-system get pod -o wide 查看 Service 1kubectl -n kube-system get svc 验证 IPVS 查看 kube-proxy 日志，server_others.go:176] Using ipvs Proxier. 1kubectl -n kube-system logs -f &lt;kube-proxy 容器名&gt; 查看代理规则 1ipvsadm -ln 查看生效的配置 1kubectl -n kube-system get cm kubeadm-config -oyaml 查看 etcd 集群 1234567891011kubectl -n kube-system exec etcd-kubernetes-master-01 -- etcdctl \ --endpoints=https://192.168.141.150:2379 \ --ca-file=/etc/kubernetes/pki/etcd/ca.crt \ --cert-file=/etc/kubernetes/pki/etcd/server.crt \ --key-file=/etc/kubernetes/pki/etcd/server.key cluster-health# 输出如下member 1dfaf07371bb0cb6 is healthy: got healthy result from https://192.168.141.152:2379member 2da85730b52fbeb2 is healthy: got healthy result from https://192.168.141.150:2379member 6a3153eb4faaaffa is healthy: got healthy result from https://192.168.141.151:2379cluster is healthy 验证高可用 特别注意：Keepalived 要求至少 2 个备用节点，故想测试高可用至少需要 1 主 2 从模式验证，否则可能出现意想不到的问题 对任意一台 Master 机器执行关机操作 1shutdown -h now 在任意一台 Master 节点上查看 Node 状态 1234567kubectl get node# 输出如下，除已关机那台状态为 NotReady 其余正常便表示成功NAME STATUS ROLES AGE VERSIONkubernetes-master-01 NotReady master 18m v1.14.2kubernetes-master-02 Ready master 17m v1.14.2kubernetes-master-03 Ready master 16m v1.14.2 查看 VIP 漂移 123456ip a |grep ens33# 输出如下2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 inet 192.168.141.151/24 brd 192.168.141.255 scope global ens33 inet 192.168.141.200/24 scope global secondary ens33 解决 Node 无法加入的问题问题描述当我们使用 kubeadm join 命令将 Node 节点加入集群时，你会发现所有 kubectl 命令均不可用（呈现阻塞状态，并不会返回响应结果），我们可以在 Node 节点中通过 kubeadm reset 命令将 Node 节点下线，此时回到 Master 节点再使用 watch kubectl get pods --all-namespaces 可以看到下图中报错了，coredns-xxx-xxx 状态为 CrashLoopBackOff 解决方案从上面的错误信息不难看出应该是出现了网络问题，而我们在安装过程中只使用了一个网络插件 Calico ，那么该错误是不是由 Calico 引起的呢？带着这个疑问我们去到 Calico 官网再看一下它的说明，官网地址：https://docs.projectcalico.org/v3.7/getting-started/kubernetes/ 在它的 Quickstart 里有两段话（属于特别提醒），截图如下： 上面这段话的主要意思是：当 kubeadm 安装完成后不要关机，继续完成后续的安装步骤；这也说明了安装 Kubernetes 的过程不要出现中断一口气搞定（不过这不是重点）(*￣rǒ￣) 上面这段话的主要意思是：如果你的网络在 192.168.0.0/16 网段中，则必须选择一个不同的 Pod 网络；恰巧咱们的网络范围（我虚拟机的 IP 范围是 192.168.141.0/24）和该网段重叠 (ノへ￣、)；好吧，当时做单节点集群时因为没啥问题而忽略了 ♪(^∇^*) so，能够遇到这个问题主要是因为虚拟机 IP 范围刚好和 Calico 默认网段重叠导致的，所以想要解决这个问题，咱们就需要修改 Calico 的网段了（当然也可以改虚拟机的），换句话说就是大家重装一下 o (一︿一 +) o 按照以下标准步骤重装即可 重置 Kubernetes12345678910111213141516171819202122kubeadm reset# 输出如下[reset] WARNING: Changes made to this host by 'kubeadm init' or 'kubeadm join' will be reverted.[reset] Are you sure you want to proceed? [y/N]: y[preflight] Running pre-flight checksW0604 01:55:28.517280 22688 reset.go:234] [reset] No kubeadm config, using etcd pod spec to get data directory[reset] No etcd config found. Assuming external etcd[reset] Please manually reset etcd to prevent further issues[reset] Stopping the kubelet service[reset] unmounting mounted directories in "/var/lib/kubelet"[reset] Deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/run/kubernetes][reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki][reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]The reset process does not reset or clean up iptables rules or IPVS tables.If you wish to reset iptables, you must do so manually.For example:iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -XIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)to reset your system's IPVS tables. 删除 kubectl 配置1rm -fr ~/.kube/ 启用 IPVS12345modprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4 导出并修改配置文件1kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml 配置文件修改如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647apiVersion: kubeadm.k8s.io/v1beta1bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 192.168.141.150 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: kubernetes-master-01 taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta1certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrolPlaneEndpoint: "192.168.141.200:6444"controllerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfigurationkubernetesVersion: v1.14.2networking: dnsDomain: cluster.local # 主要修改在这里，替换 Calico 网段为我们虚拟机不重叠的网段（这里用的是 Flannel 默认网段） podSubnet: "10.244.0.0/16" serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs kubeadm 初始化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586kubeadm init --config=kubeadm.yml --experimental-upload-certs | tee kubeadm-init.log# 输出如下[init] Using Kubernetes version: v1.14.2[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Activating the kubelet service[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "front-proxy-ca" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "etcd/ca" certificate and key[certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [kubernetes-master-01 localhost] and IPs [192.168.141.150 127.0.0.1 ::1][certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "apiserver-etcd-client" certificate and key[certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [kubernetes-master-01 localhost] and IPs [192.168.141.150 127.0.0.1 ::1][certs] Generating "ca" certificate and key[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [kubernetes-master-01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.141.150 192.168.141.200][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "sa" key and public key[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "admin.conf" kubeconfig file[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "kubelet.conf" kubeconfig file[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "controller-manager.conf" kubeconfig file[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s[apiclient] All control plane components are healthy after 24.507568 seconds[upload-config] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.14" in namespace kube-system with the configuration for the kubelets in the cluster[upload-certs] Storing the certificates in ConfigMap "kubeadm-certs" in the "kube-system" Namespace[upload-certs] Using certificate key:a662b8364666f82c93cc5cd4fb4fabb623bbe9afdb182da353ac40f1752dfa4a[mark-control-plane] Marking the node kubernetes-master-01 as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node kubernetes-master-01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: abcdef.0123456789abcdef[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] creating the "cluster-info" ConfigMap in the "kube-public" namespace[addons] Applied essential addon: CoreDNS[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of the control-plane node running the following command on each as root: kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad \ --experimental-control-plane --certificate-key a662b8364666f82c93cc5cd4fb4fabb623bbe9afdb182da353ac40f1752dfa4aPlease note that the certificate-key gives access to cluster sensitive data, keep it secret!As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use "kubeadm init phase upload-certs --experimental-upload-certs" to reload certs afterward.Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad 配置 kubectl1234567# 配置 kubectlmkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config# 验证是否成功kubectl get node 下载 Calico 配置文件并修改1wget https://docs.projectcalico.org/v3.7/manifests/calico.yaml 1vi calico.yaml 修改第 611 行，将 192.168.0.0/16 修改为 10.244.0.0/16，可以通过如下命令快速查找 显示行号：:set number 查找字符：/要查找的字符，输入小写 n 下一个匹配项，输入大写 N 上一个匹配项 安装 Calico1234567891011121314151617181920212223242526kubectl apply -f calico.yaml# 输出如下configmap/calico-config createdcustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org createdclusterrole.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrole.rbac.authorization.k8s.io/calico-node createdclusterrolebinding.rbac.authorization.k8s.io/calico-node createddaemonset.extensions/calico-node createdserviceaccount/calico-node createddeployment.extensions/calico-kube-controllers createdserviceaccount/calico-kube-controllers created 加入 Master 节点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 示例如下，别忘记两个备用节点都要加入哦kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad \ --experimental-control-plane --certificate-key a662b8364666f82c93cc5cd4fb4fabb623bbe9afdb182da353ac40f1752dfa4a# 输出如下[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[preflight] Running pre-flight checks before initializing the new control plane instance[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[download-certs] Downloading the certificates in Secret "kubeadm-certs" in the "kube-system" Namespace[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [kubernetes-master-02 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.141.151 192.168.141.200][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [kubernetes-master-02 localhost] and IPs [192.168.141.151 127.0.0.1 ::1][certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [kubernetes-master-02 localhost] and IPs [192.168.141.151 127.0.0.1 ::1][certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "apiserver-etcd-client" certificate and key[certs] Valid certificates and keys now exist in "/etc/kubernetes/pki"[certs] Using the existing "sa" key[kubeconfig] Generating kubeconfig files[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address[kubeconfig] Writing "admin.conf" kubeconfig file[kubeconfig] Writing "controller-manager.conf" kubeconfig file[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"[check-etcd] Checking that the etcd cluster is healthy[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.14" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Activating the kubelet service[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...[etcd] Announced new etcd member joining to the existing etcd cluster[etcd] Wrote Static Pod manifest for a local etcd member to "/etc/kubernetes/manifests/etcd.yaml"[etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s[upload-config] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[mark-control-plane] Marking the node kubernetes-master-02 as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node kubernetes-master-02 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]This node has joined the cluster and a new control plane instance was created:* Certificate signing request was sent to apiserver and approval was received.* The Kubelet was informed of the new secure connection details.* Control plane (master) label and taint were applied to the new node.* The Kubernetes control plane instances scaled up.* A new etcd member was added to the local/stacked etcd cluster.To start administering your cluster from this node, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configRun 'kubectl get nodes' to see this node join the cluster. 加入 Node 节点123456789101112131415161718192021# 示例如下kubeadm join 192.168.141.200:6444 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad# 输出如下&gt; --discovery-token-ca-cert-hash sha256:2ea8c138021fb1e184a24ed2a81c16c92f9f25c635c73918b1402df98f9c8aad [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.14" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Activating the kubelet service[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 验证是否可用12345678kubectl get node# 输出如下，我们可以看到 Node 节点已经成功上线 ━━(￣ー￣*|||━━NAME STATUS ROLES AGE VERSIONkubernetes-master-01 Ready master 19m v1.14.2kubernetes-master-02 Ready master 4m46s v1.14.2kubernetes-master-03 Ready master 3m23s v1.14.2kubernetes-node-01 Ready &lt;none&gt; 74s v1.14.2 1234567891011121314151617181920212223242526272829watch kubectl get pods --all-namespaces# 输出如下，coredns 也正常运行了Every 2.0s: kubectl get pods --all-namespaces kubernetes-master-01: Tue Jun 4 02:31:43 2019NAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-8646dd497f-hz5xp 1/1 Running 0 9m9skube-system calico-node-2z892 1/1 Running 0 9m9skube-system calico-node-fljxv 1/1 Running 0 6m39skube-system calico-node-vprlw 1/1 Running 0 5m16skube-system calico-node-xvqcx 1/1 Running 0 3m7skube-system coredns-8686dcc4fd-5ndjm 1/1 Running 0 21mkube-system coredns-8686dcc4fd-zxtql 1/1 Running 0 21mkube-system etcd-kubernetes-master-01 1/1 Running 0 20mkube-system etcd-kubernetes-master-02 1/1 Running 0 6m37skube-system etcd-kubernetes-master-03 1/1 Running 0 5m14skube-system kube-apiserver-kubernetes-master-01 1/1 Running 0 20mkube-system kube-apiserver-kubernetes-master-02 1/1 Running 0 6m37skube-system kube-apiserver-kubernetes-master-03 1/1 Running 0 5m14skube-system kube-controller-manager-kubernetes-master-01 1/1 Running 1 20mkube-system kube-controller-manager-kubernetes-master-02 1/1 Running 0 6m37skube-system kube-controller-manager-kubernetes-master-03 1/1 Running 0 5m14skube-system kube-proxy-68jqr 1/1 Running 0 3m7skube-system kube-proxy-69bnn 1/1 Running 0 6m39skube-system kube-proxy-vvhp5 1/1 Running 0 5m16skube-system kube-proxy-ws6wx 1/1 Running 0 21mkube-system kube-scheduler-kubernetes-master-01 1/1 Running 1 20mkube-system kube-scheduler-kubernetes-master-02 1/1 Running 0 6m37skube-system kube-scheduler-kubernetes-master-03 1/1 Running 0 5m14s 至此，Kubernetes 高可用集群算是彻底部署成功，撒花撒花 (゜-゜)つロ 干杯 通过资源配置运行容器我们知道通过 run 命令启动容器非常麻烦，Docker 提供了 Compose 为我们解决了这个问题。那 Kubernetes 是如何解决这个问题的呢？其实很简单，使用 kubectl create命令就可以做到和 Compose 一样的效果了，该命令可以通过配置文件快速创建一个集群资源对象。 创建 YAML 配置文件以部署 Nginx 为例 部署 Deployment创建一个名为 nginx-deployment.yml 的配置文件 123456789101112131415161718192021222324252627# API 版本号apiVersion: extensions/v1beta1# 类型，如：Pod/ReplicationController/Deployment/Service/Ingresskind: Deployment# 元数据metadata: # Kind 的名称 name: nginx-appspec: # 部署的实例数量 replicas: 2 template: metadata: labels: # 容器标签的名字，发布 Service 时，selector 需要和这里对应 name: nginx spec: # 配置容器，数组类型，说明可以配置多个容器 containers: # 容器名称 - name: nginx # 容器镜像 image: nginx # 暴露端口 ports: # Pod 端口 - containerPort: 80 12345# 部署kubectl create -f nginx-deployment.yml# 删除kubectl delete -f nginx-deployment.yml 发布 Service创建一个名为 nginx-service.yml 的配置文件 123456789101112131415161718192021# API 版本号apiVersion: v1# 类型，如：Pod/ReplicationController/Deployment/Service/Ingresskind: Service# 元数据metadata: # Kind 的名称 name: nginx-httpspec: # 暴露端口 ports: ## Service 暴露的端口 - port: 80 ## Pod 上的端口，这里是将 Service 暴露的端口转发到 Pod 端口上 targetPort: 80 # 类型 type: LoadBalancer # 标签选择器 selector: # 需要和上面部署的 Deployment 标签名对应 name: nginx 12345# 部署kubectl create -f nginx-service.yml# 删除kubectl delete -f nginx-service.yml 验证是否生效查看 Pod 列表123456kubectl get pods# 输出如下NAME READY STATUS RESTARTS AGEnginx-app-64bb598779-2pplx 1/1 Running 0 25mnginx-app-64bb598779-824lc 1/1 Running 0 25m 查看 Deployment 列表12345kubectl get deployment# 输出如下NAME READY UP-TO-DATE AVAILABLE AGEnginx-app 2/2 2 2 25m 查看 Service 列表123456kubectl get service# 输出如下NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 20hnginx-http LoadBalancer 10.98.49.142 &lt;pending&gt; 80:31631/TCP 14m 查看 Service 详情1234567891011121314151617kubectl describe service nginx-app# 输出如下Name: nginx-httpNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Selector: name=nginxType: LoadBalancerIP: 10.98.49.142Port: &lt;unset&gt; 80/TCPTargetPort: 80/TCPNodePort: &lt;unset&gt; 31631/TCPEndpoints: 10.244.141.205:80,10.244.2.4:80Session Affinity: NoneExternal Traffic Policy: ClusterEvents: &lt;none&gt; 通过浏览器访问通过浏览器访问 http://192.168.141.150:31631/ ，出现 Nginx 欢迎页即表示成功 集成环境部署也可以不区分配置文件，一次性部署 Deployment 和 Service，创建一个名为 nginx.yml的配置文件，配置内容如下： 123456789101112131415161718192021222324252627282930apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx-appspec: replicas: 2 template: metadata: labels: name: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: nginx-httpspec: ports: - port: 80 targetPort: 80 # 可以指定 NodePort 端口，默认范围是：30000-32767 # nodePort: 30080 type: LoadBalancer selector: name: nginx 12345# 部署kubectl create -f nginx.yml# 删除kubectl delete -f nginx.yml 附：修改默认的端口范围Kubernetes 服务的 NodePort 默认端口范围是 30000-32767，在某些场合下，这个限制不太适用，我们可以自定义它的端口范围，操作步骤如下： 编辑 vi /etc/kubernetes/manifests/kube-apiserver.yaml 配置文件，增加配置 --service-node-port-range=2-65535 123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: creationTimestamp: null labels: component: kube-apiserver tier: control-plane name: kube-apiserver namespace: kube-systemspec: containers: - command: - kube-apiserver # 在这里增加配置即可 - --service-node-port-range=2-65535 - --advertise-address=192.168.141.150 - --allow-privileged=true - --authorization-mode=Node,RBAC - --client-ca-file=/etc/kubernetes/pki/ca.crt - --enable-admission-plugins=NodeRestriction - --enable-bootstrap-token-auth=true - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt// 以下配置省略... 使用 docker ps 命令找到 kube-apiserver 容器，再使用 docker restart &lt;ApiServer 容器 ID&gt; 即可生效。 Ingress 统一访问入口术语 节点： Kubernetes 集群中的服务器 集群： Kubernetes 管理的一组服务器集合 边界路由器： 为局域网和 Internet 路由数据包的路由器，执行防火墙保护局域网络 集群网络： 遵循 Kubernetes 网络模型实现集群内的通信的具体实现，比如 Flannel 和 Calico 服务： Kubernetes 的服务 (Service) 是使用标签选择器标识的一组 Pod Service (Deployment)。 除非另有说明，否则服务的虚拟 IP 仅可在集群内部访问 内部访问方式 ClusterIPClusterIP 服务是 Kubernetes 的默认服务。它给你一个集群内的服务，集群内的其它应用都可以访问该服务。集群外部无法访问它。在某些场景下我们可以使用 Kubernetes 的 Proxy 模式来访问服务，比如调试服务时。 三种外部访问方式NodePortNodePort 服务是引导外部流量到你的服务的最原始方式。NodePort，正如这个名字所示，在所有节点（虚拟机）上开放一个特定端口，任何发送到该端口的流量都被转发到对应服务。 NodePort 服务特征如下： 每个端口只能是一种服务 端口范围只能是 30000-32767（可调） 不在 YAML 配置文件中指定则会分配一个默认端口 建议： 不要在生产环境中使用这种方式暴露服务，大多数时候我们应该让 Kubernetes 来选择端口 LoadBalancerLoadBalancer 服务是暴露服务到 Internet 的标准方式。所有通往你指定的端口的流量都会被转发到对应的服务。它没有过滤条件，没有路由等。这意味着你几乎可以发送任何种类的流量到该服务，像 HTTP，TCP，UDP，WebSocket，gRPC 或其它任意种类。 IngressIngress 事实上不是一种服务类型。相反，它处于多个服务的前端，扮演着 “智能路由” 或者集群入口的角色。你可以用 Ingress 来做许多不同的事情，各种不同类型的 Ingress 控制器也有不同的能力。它允许你基于路径或者子域名来路由流量到后端服务。 Ingress 可能是暴露服务的最强大方式，但同时也是最复杂的。Ingress 控制器有各种类型，包括 Google Cloud Load Balancer， Nginx，Contour，Istio，等等。它还有各种插件，比如 cert-manager (它可以为你的服务自动提供 SSL 证书)/ 如果你想要使用同一个 IP 暴露多个服务，这些服务都是使用相同的七层协议（典型如 HTTP），你还可以获取各种开箱即用的特性（比如 SSL、认证、路由等等） 什么是 Ingress通常情况下，Service 和 Pod 的 IP 仅可在集群内部访问。集群外部的请求需要通过负载均衡转发到 Service 在 Node 上暴露的 NodePort 上，然后再由 kube-proxy 通过边缘路由器 (edge router) 将其转发给相关的 Pod 或者丢弃。而 Ingress 就是为进入集群的请求提供路由规则的集合 Ingress 可以给 Service 提供集群外部访问的 URL、负载均衡、SSL 终止、HTTP 路由等。为了配置这些 Ingress 规则，集群管理员需要部署一个 Ingress Controller，它监听 Ingress 和 Service 的变化，并根据规则配置负载均衡并提供访问入口。 使用 Nginx Ingress Controller本次实践的主要目的就是将入口统一，不再通过 LoadBalancer 等方式将端口暴露出来，而是使用 Ingress 提供的反向代理负载均衡功能作为我们的唯一入口。通过以下步骤操作仔细体会。 注意： 下面包含资源配置的步骤都是自行创建 YAML 配置文件通过 kubectl create -f &lt;YAML&gt; 和 kubectl delete -f &lt;YAML&gt; 部署和删除 部署 Tomcat部署 Tomcat 但仅允许在内网访问，我们要通过 Ingress 提供的反向代理功能路由到 Tomcat 之上 1234567891011121314151617181920212223242526272829apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: tomcat-appspec: replicas: 2 template: metadata: labels: name: tomcat spec: containers: - name: tomcat image: tomcat ports: - containerPort: 8080---apiVersion: v1kind: Servicemetadata: name: tomcat-httpspec: ports: - port: 8080 targetPort: 8080 # ClusterIP, NodePort, LoadBalancer type: LoadBalancer selector: name: tomcat 安装 Nginx Ingress ControllerIngress Controller 有许多种，我们选择最熟悉的 Nginx 来处理请求，其它可以参考 官方文档 下载 Nginx Ingress Controller 配置文件 1wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml 1 修改配置文件，找到配置如下位置 (搜索 serviceAccountName) 在下面增加一句 hostNetwork: true 12345678910111213141516171819202122232425262728293031323334353637apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-ingress-controller namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: # 可以部署多个实例 replicas: 1 selector: matchLabels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx template: metadata: labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx annotations: prometheus.io/port: "10254" prometheus.io/scrape: "true" spec: serviceAccountName: nginx-ingress-serviceaccount # 增加 hostNetwork: true，意思是开启主机网络模式，暴露 Nginx 服务端口 80 hostNetwork: true containers: - name: nginx-ingress-controller image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.24.1 args: - /nginx-ingress-controller - --configmap=$(POD_NAMESPACE)/nginx-configuration - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services - --udp-services-configmap=$(POD_NAMESPACE)/udp-services - --publish-service=$(POD_NAMESPACE)/ingress-nginx// 以下代码省略... 部署 IngressIngress 翻译过来是入口的意思，说白了就是个 API 网关（想想之前学的 Zuul 和 Spring Cloud Gateway） 1234567891011121314151617181920212223242526272829303132apiVersion: networking.k8s.io/v1beta1kind: Ingressmetadata: name: nginx-web annotations: # 指定 Ingress Controller 的类型 kubernetes.io/ingress.class: "nginx" # 指定我们的 rules 的 path 可以使用正则表达式 nginx.ingress.kubernetes.io/use-regex: "true" # 连接超时时间，默认为 5s nginx.ingress.kubernetes.io/proxy-connect-timeout: "600" # 后端服务器回转数据超时时间，默认为 60s nginx.ingress.kubernetes.io/proxy-send-timeout: "600" # 后端服务器响应超时时间，默认为 60s nginx.ingress.kubernetes.io/proxy-read-timeout: "600" # 客户端上传文件，最大大小，默认为 20m nginx.ingress.kubernetes.io/proxy-body-size: "10m" # URL 重写 nginx.ingress.kubernetes.io/rewrite-target: /spec: # 路由规则 rules: # 主机名，只能是域名，修改为你自己的 - host: k8s.test.com http: paths: - path: backend: # 后台部署的 Service Name，与上面部署的 Tomcat 对应 serviceName: tomcat-http # 后台部署的 Service Port，与上面部署的 Tomcat 对应 servicePort: 8080 验证是否成功查看 Tomcat12345kubectl get deployment# 输出如下NAME READY UP-TO-DATE AVAILABLE AGEtomcat-app 2/2 2 2 88m 123456kubectl get service# 输出如下NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 2d5htomcat-http ClusterIP 10.97.222.179 &lt;none&gt; 8080/TCP 89m 查看 Nginx Ingress Controller12345kubectl get pods -n ingress-nginx -o wide# 输出如下，注意下面的 IP 地址，就是我们实际访问地址NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-ingress-controller-76f9fddcf8-vzkm5 1/1 Running 0 61m 192.168.141.160 kubernetes-node-01 &lt;none&gt; &lt;none&gt; 查看 Ingress12345kubectl get ingress# 输出如下NAME HOSTS ADDRESS PORTS AGEnginx-web k8s.test.com 80 61m 测试访问成功代理到 Tomcat 即表示成功 12# 不设置 Hosts 的方式请求地址，下面的 IP 和 Host 均在上面有配置curl -v http://192.168.141.160 -H 'host: k8s.test.com' 准备数据持久化在 Docker 中就有数据卷的概念，当容器删除时，数据也一起会被删除，想要持久化使用数据，需要把主机上的目录挂载到 Docker 中去，在 K8S 中，数据卷是通过 Pod 实现持久化的，如果 Pod 删除，数据卷也会一起删除，k8s 的数据卷是 docker 数据卷的扩展，K8S 适配各种存储系统，包括本地存储 EmptyDir，HostPath， 网络存储（NFS，GlusterFS，PV/PVC）等。 我们以部署 MySQL8 为例，采用 NFS + PV/PVC 网络存储方案实现我们的 Kubernetes 数据持久化。 什么是 NFSNFS 是 Network File System 的简写，即网络文件系统，NFS 是 FreeBSD 支持的文件系统中的一种。NFS 基于 RPC (Remote Procedure Call) 远程过程调用实现，其允许一个系统在网络上与它人共享目录和文件。通过使用 NFS，用户和程序就可以像访问本地文件一样访问远端系统上的文件。NFS 是一个非常稳定的，可移植的网络文件系统。具备可扩展和高性能等特性，达到了企业级应用质量标准。由于网络速度的增加和延迟的降低，NFS 系统一直是通过网络提供文件系统服务的有竞争力的选择 。 NFS 原理NFS 使用 RPC (Remote Procedure Call) 的机制进行实现，RPC 使得客户端可以调用服务端的函数。同时，由于有 VFS 的存在，客户端可以像使用其它普通文件系统一样使用 NFS 文件系统。经由操作系统的内核，将 NFS 文件系统的调用请求通过 TCP/IP 发送至服务端的 NFS 服务。NFS 服务器执行相关的操作，并将操作结果返回给客户端。 NFS 服务主要进程 rpc.nfsd：最主要的 NFS 进程，管理客户端是否可登录 rpc.mountd：挂载和卸载 NFS 文件系统，包括权限管理 rpc.lockd：非必要，管理文件锁，避免同时写出错 rpc.statd：非必要，检查文件一致性，可修复文件 NFS 的关键工具 主要配置文件：/etc/exports NFS 文件系统维护命令：/usr/bin/exportfs 共享资源的日志文件：/var/lib/nfs/*tab 客户端查询共享资源命令：/usr/sbin/showmount 端口配置：/etc/sysconfig/nfs NFS 服务端配置在 NFS 服务器端的主要配置文件为 /etc/exports 时，通过此配置文件可以设置共享文件目录。每条配置记录由 NFS 共享目录、NFS 客户端地址和参数这 3 部分组成，格式如下： 1[NFS 共享目录] [NFS 客户端地址 1 (参数 1, 参数 2, 参数 3……)] [客户端地址 2 (参数 1, 参数 2, 参数 3……)] NFS 共享目录：服务器上共享出去的文件目录 NFS 客户端地址：允许其访问的 NFS 服务器的客户端地址，可以是客户端 IP 地址，也可以是一个网段 (192.168.141.0/24) 访问参数：括号中逗号分隔项，主要是一些权限选项 访问权限参数 序号 选项 描述 1 ro 客户端对于共享文件目录为只读权限。默认 2 rw 客户端对于共享文件目录具有读写权限 用户映射参数 序号 选项 描述 1 root_squash 使客户端使用 root 账户访冋时，服务器映射为服务器本地的匿名账号 2 no_root_squash 客户端连接服务端时如果使用的是 root，那么也拥有对服务端分享的目录的 root 权限 3 all_squash 将所有客户端用户请求映射到匿名用户或用户组（nfsnobody) 4 no_all_squash 与上相反。默认 5 anonuid=xxx 将远程访问的所有用户都映射为匿名用户，并指定该用户为本地用户(UID=xxx) 6 anongid=xxx 将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户(GUI=xxx) 其它配置参数 序号 选项 描述 1 sync 同步写操作，数据写入存储设备后返回成功信息。默认 2 async 异步写提作，数据在未完全写入存储设备前就返回成功信息，实际还在内存， 3 wdelay 延迟写入选项，将多个写提请求合并后写入硬盘，减少 I/O 次数， NFS 非正常关闭数据可能丢失。默认 4 no_wdelay 与上相反，不与 async 同时生效，如果 NFS 服务器主要收到小且不相关的请求，该选项实际会降低性能 5 subtree 若输出目录是一个子目录，则 NFS 服务器将检查其父目录的权限。默认 6 no_subtree 即使输出目录是一个子目录， NFS 服务器也不检查其父目录的权限，这样可以提高效率 7 secure 限制客户端只能从小于 1024 的 TCP/IP 端口连接 NFS 服务器。默认 8 insecure 允许客户端从大于 1024 的 TCP/IP 端口连接服务器 安装 NFS 服务端由于 NFS 是一套分布式文件系统，我们再创建一台独立的虚拟机作为我们 NFS 服务端，配置如下 主机名 IP 系统 CPU/内存 磁盘 kubernetes-volumes 192.168.141.140 Ubuntu Server 18.04 2核2G 20G 创建一个目录作为共享文件目录 1mkdir -p /usr/local/kubernetes/volumes 给目录增加读写权限 1chmod a+rw /usr/local/kubernetes/volumes 安装 NFS 服务端 12apt-get updateapt-get install -y nfs-kernel-server 配置 NFS 服务目录，打开文件 1vi /etc/exports ，在尾部新增一行，内容如下 /usr/local/kubernetes/volumes：作为服务目录向客户端开放 *：表示任何 IP 都可以访问 rw：读写权限 sync：同步权限 no_subtree_check：表示如果输出目录是一个子目录，NFS 服务器不检查其父目录的权限 1/usr/local/kubernetes/volumes *(rw,sync,no_subtree_check) 重启服务，使配置生效 1/etc/init.d/nfs-kernel-server restart 安装 NFS 客户端安装客户端的目的是验证是否可以上传文件到服务端，安装命令如下 1apt-get install -y nfs-common 创建 NFS 客户端挂载目录 1mkdir -p /usr/local/kubernetes/volumes-mount 将 NFS 服务器的 /usr/local/kubernetes/volumes 目录挂载到 NFS 客户端的 /usr/local/kubernetes/volumes-mount 目录 1mount 192.168.141.140:/usr/local/kubernetes/volumes /usr/local/kubernetes/volumes-mount 使用 df 命令查看挂载信息 12345678910111213141516df# 输出如下Filesystem 1K-blocks Used Available Use% Mounted onudev 977556 0 977556 0% /devtmpfs 201732 1252 200480 1% /run/dev/mapper/ubuntu--vg-ubuntu--lv 19475088 5490916 12971848 30% /tmpfs 1008648 0 1008648 0% /dev/shmtmpfs 5120 0 5120 0% /run/locktmpfs 1008648 0 1008648 0% /sys/fs/cgroup/dev/loop0 90624 90624 0 100% /snap/core/6964/dev/loop1 93184 93184 0 100% /snap/core/6350/dev/sda2 999320 214252 716256 24% /boottmpfs 201728 0 201728 0% /run/user/0# 有此输出表示挂载成功193.192.168.141.140:/usr/local/kubernetes/volumes 19475200 5490944 12972032 30% /usr/local/kubernetes/volumes-mount 验证 NFS 服务 测试文件上传 1ip addr &gt; /usr/local/kubernetes/volumes-mount/test.txt 查看 /usr/local/kubernetes/volumes 目录下是否有 test.txt 文件，有则表示成功 取消 NFS 客户端挂载 注意： 不要直接在挂载目录下执行，否则会报错 1umount /usr/local/kubernetes/volumes-mount 实现数据持久化概述存储管理与计算管理是两个不同的问题。Persistent Volume 子系统，对存储的供应和使用做了抽象，以 API 形式提供给管理员和用户使用。要完成这一任务，我们引入了两个新的 API 资源：Persistent Volume（持久卷） 和 Persistent Volume Claim（持久卷消费者）。 Persistent Volume（PV）是集群之中的一块网络存储。跟 Node 一样，也是集群的资源。PV 跟 Volume (卷) 类似，不过会有独立于 Pod 的生命周期。这一 API 对象包含了存储的实现细节，例如 NFS、iSCSI 或者其他的云提供商的存储系统。Persistent Volume Claim (PVC) 是用户的一个请求。跟 Pod 类似，Pod 消费 Node 的资源，PVC 消费 PV 的资源。Pod 能够申请特定的资源（CPU 和内存）；Claim 能够请求特定的尺寸和访问模式（例如可以加载一个读写，以及多个只读实例） PV 与 PVCPV 是集群的资源。PVC 是对这一资源的请求，也是对资源的所有权的检验。PV 和 PVC 之间的互动遵循如下的生命周期。 供应： 集群管理员会创建一系列的 PV。这些 PV 包含了为集群用户提供的真实存储资源，它们可利用 Kubernetes API 来消费。 绑定： 用户创建一个包含了容量和访问模式的持久卷申请。Master 会监听 PVC 的产生，并尝试根据请求内容查找匹配的 PV，并把 PV 和 PVC 进行绑定。用户能够获取满足需要的资源，并且在使用过程中可能超出请求数量。如果找不到合适的卷，这一申请就会持续处于非绑定状态，一直到出现合适的 PV。例如一个集群准备了很多的 50G 大小的持久卷，（虽然总量足够）也是无法响应 100G 的申请的，除非把 100G 的 PV 加入集群。 使用： Pod 把申请作为卷来使用。集群会通过 PVC 查找绑定的 PV，并 Mount 给 Pod。对于支持多种访问方式的卷，用户在使用 PVC 作为卷的时候，可以指定需要的访问方式。一旦用户拥有了一个已经绑定的 PVC，被绑定的 PV 就归该用户所有了。用户的 Pods 能够通过在 Pod 的卷中包含的 PVC 来访问他们占有的 PV。 释放： 当用户完成对卷的使用时，就可以利用 API 删除 PVC 对象了，而且他还可以重新申请。删除 PVC 后，对应的卷被视为 “被释放”，但是这时还不能给其他的 PVC 使用。之前的 PVC 数据还保存在卷中，要根据策略来进行后续处理。 回收： PV 的回收策略向集群阐述了在 PVC 释放卷的时候，应如何进行后续工作。目前可以采用三种策略：保留，回收或者删除。保留策略允许重新申请这一资源。在持久卷能够支持的情况下，删除策略会同时删除持久卷以及 AWS EBS/GCE PD 或者 Cinder 卷中的存储内容。如果插件能够支持，回收策略会执行基础的擦除操作（rm -rf /thevolume/*），这一卷就能被重新申请了。 定义 PV持久卷插件持久卷是以插件方式实现的，目前支持的插件如下： GCEPersistentDisk AWSElasticBlockStore NFS（我们采用的是该方案） iSCSI RBD (Ceph Block Device) Glusterfs HostPath (单节点测试使用) 本地持久卷 YAML 配置创建一个名为 nfs-pv-mysql.yml 的配置文件 1234567891011121314151617181920apiVersion: v1kind: PersistentVolumemetadata: name: nfs-pv-mysqlspec: # 设置容量 capacity: storage: 5Gi # 访问模式 accessModes: # 该卷能够以读写模式被多个节点同时加载 - ReadWriteMany # 回收策略，这里是基础擦除 `rm-rf/thevolume/*` persistentVolumeReclaimPolicy: Recycle nfs: # NFS 服务端配置的路径 path: "/usr/local/kubernetes/volumes" # NFS 服务端地址 server: 192.168.141.140 readOnly: false 12345678# 部署kubectl create -f nfs-pv-mysql.yml# 删除kubectl delete -f nfs-pv-mysql.yml# 查看kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfs-pv-mysql 5Gi RWX Recycle Available 29m 配置说明Capacity（容量）一般来说，PV 会指定存储容量。这里需要使用 PV 的 capcity 属性。目前存储大小是唯一一个能够被申请的指标，今后会加入更多属性，例如 IOPS，吞吐能力等。 AccessModes（访问模式）只要资源提供者支持，持久卷能够被用任何方式加载到主机上。每种存储都会有不同的能力，每个 PV 的访问模式也会被设置成为该卷所支持的特定模式。例如 NFS 能够支持多个读写客户端，但是某个 NFS PV 可能会在服务器上以只读方式使用。每个 PV 都有自己的一系列的访问模式，这些访问模式取决于 PV 的能力。访问模式的可选范围如下： ReadWriteOnce：该卷能够以读写模式被加载到一个节点上 ReadOnlyMany：该卷能够以只读模式加载到多个节点上 ReadWriteMany：该卷能够以读写模式被多个节点同时加载 在 CLI 下，访问模式缩写为： RWO：ReadWriteOnce ROX：ReadOnlyMany RWX：ReadWriteMany 另外，一个卷不论支持多少种访问模式，同时只能以一种访问模式加载。例如一个 GCE Persistent Disk 既能支持 ReadWriteOnce，也能支持 ReadOnlyMany。 RecyclingPolicy（回收策略）当前的回收策略可选值包括： Retain：人工重新申请 Recycle：基础擦除（rm-rf/thevolume/*） Delete：相关的存储资产例如 AWS EBS，GCE PD 或者 OpenStack Cinder 卷一并删除 目前，只有 NFS 和 HostPath 支持 Recycle 策略，AWS EBS、GCE PD 以及 Cinder 卷支持 Delete 策略。 阶段（Phase）一个卷会处于如下阶段之一： Available：可用资源，尚未被绑定到 PVC 上 Bound：该卷已经被绑定 Released：PVC 已经被删除，但该资源尚未被集群回收 Failed：该卷的自动回收过程失败 定义 PVC创建一个名为 nfs-pvc-mysql-myshop.yml 的配置文件 123456789101112apiVersion: v1kind: PersistentVolumeClaimmetadata: name: nfs-pvc-mysql-myshopspec: accessModes: # 需要使用和 PV 一致的访问模式 - ReadWriteMany # 按需分配资源 resources: requests: storage: 1Gi 123456# 部署kubectl create -f nfs-pvc-mysql-myshop.yml# 删除kubectl delete -f nfs-pvc-mysql-myshop.yml# 查看kubectl get pvc 部署 MySQL8 注意： 要确保每台 Node 都安装了 NFS 客户端，apt-get install -y nfs-common 12345678910111213141516171819202122232425262728293031323334353637383940414243apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: mysql-myshopspec: replicas: 1 template: metadata: labels: name: mysql-myshop spec: containers: - name: mysql-myshop image: mysql # 只有镜像不存在时，才会进行镜像拉取 imagePullPolicy: IfNotPresent ports: - containerPort: 3306 # 同 Docker 配置中的 environment env: - name: MYSQL_ROOT_PASSWORD value: "123456" # 容器中的挂载目录 volumeMounts: - name: nfs-vol-myshop mountPath: /var/lib/mysql volumes: # 挂载到数据卷 - name: nfs-vol-myshop persistentVolumeClaim: claimName: nfs-pvc-mysql-myshop---apiVersion: v1kind: Servicemetadata: name: mysql-myshopspec: ports: - port: 3306 targetPort: 3306 type: LoadBalancer selector: name: mysql-myshop 解决权限问题当你使用 kubectl create -f &lt;YAML&gt; 部署后，你会发现 Pod 状态为 Error，容器无法正常启动的情况，我们可以使用 kubectl logs &lt;Pod Name&gt; 看到一条日志 1chown: changing ownership of &apos;/var/lib/mysql/&apos;: Operation not permitted 解决方案是在 NFS 服务端配置中增加一个参数 no_root_squash，即将配置修改为：/usr/local/kubernetes/volumes *(rw,sync,no_subtree_check,no_root_squash) 测试运行部署成功后可以使用 kubectl get service 查看我们 MySQL 的运行端口，再使用连接工具连接会报如下错误 意思为无法使用密码的方式登录，在 Docker 部署时我们可以在 YAML 中配置相关参数解决这个问题；下一节我们讲解在 Kubernetes 中采用 ConfigMap 的方式配置 MySQL 附：ImagePullPolicy支持三种 ImagePullPolicy Always： 不管镜像是否存在都会进行一次拉取 Never： 不管镜像是否存在都不会进行拉取 IfNotPresent： 只有镜像不存在时，才会进行镜像拉取 注意 默认为 IfNotPresent，但 :latest 标签的镜像默认为 Always 拉取镜像时 Docker 会进行校验，如果镜像中的 MD5 码没有变，则不会拉取镜像数据 生产环境中应该尽量避免使用 :latest 标签，而开发环境中可以借助 :latest 标签自动拉取最新的镜像 Kubernetes ConfigMap概述ConfigMap 是用来存储配置文件的 Kubernetes 资源对象，所有的配置内容都存储在 etcd 中。它可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制对象。ConfigMap API 资源提供了将配置数据注入容器的方式，同时保证该机制对容器来说是透明的。配置应该从 Image 内容中解耦，以此来保持容器化应用程序的可移植性。 使用 ConfigMap 配置 MySQL123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172apiVersion: v1kind: ConfigMapmetadata: name: mysql-myshop-configdata: # 这里是键值对数据 mysqld.cnf: | [client] port=3306 [mysql] no-auto-rehash [mysqld] skip-host-cache skip-name-resolve default-authentication-plugin=mysql_native_password character-set-server=utf8mb4 collation-server=utf8mb4_general_ci explicit_defaults_for_timestamp=true lower_case_table_names=1---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: mysql-myshopspec: replicas: 1 template: metadata: labels: name: mysql-myshop spec: containers: - name: mysql-myshop image: mysql imagePullPolicy: IfNotPresent ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: "123456" volumeMounts: # 以数据卷的形式挂载 MySQL 配置文件目录 - name: cm-vol-myshop mountPath: /etc/mysql/conf.d - name: nfs-vol-myshop mountPath: /var/lib/mysql volumes: # 将 ConfigMap 中的内容以文件形式挂载进数据卷 - name: cm-vol-myshop configMap: name: mysql-myshop-config items: # ConfigMap 中的 Key - key: mysqld.cnf # ConfigMap Key 匹配的 Value 写入名为 mysqld.cnf 的文件中 path: mysqld.cnf - name: nfs-vol-myshop persistentVolumeClaim: claimName: nfs-pvc-mysql-myshop---apiVersion: v1kind: Servicemetadata: name: mysql-myshopspec: ports: - port: 3306 targetPort: 3306 nodePort: 32036 type: LoadBalancer selector: name: mysql-myshop 123# 查看 ConfigMapkubectl get cmkubectl describe cm &lt;ConfigMap Name&gt; Kubernetes Dashboard本节视频Kubernetes Dashboard 是 Kubernetes 集群的 Web UI，用于管理集群。 安装GitHub 地址：Kubernetes Dashboard 下载配置文件 1wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml 修改配置如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# 省略部分代码...# ------------------- Dashboard Deployment ------------------- #kind: DeploymentapiVersion: apps/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: kubernetes-dashboard template: metadata: labels: k8s-app: kubernetes-dashboard spec: containers: - name: kubernetes-dashboard # 修改镜像地址为阿里云 image: registry.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1 ports: - containerPort: 8443 protocol: TCP args: - --auto-generate-certificates volumeMounts: - name: kubernetes-dashboard-certs mountPath: /certs - mountPath: /tmp name: tmp-volume livenessProbe: httpGet: scheme: HTTPS path: / port: 8443 initialDelaySeconds: 30 timeoutSeconds: 30 volumes: - name: kubernetes-dashboard-certs secret: secretName: kubernetes-dashboard-certs - name: tmp-volume emptyDir: &#123;&#125; serviceAccountName: kubernetes-dashboard tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule---# ------------------- Dashboard Service ------------------- #kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: # 修改类型为 NodePort 访问 type: NodePort ports: - port: 443 targetPort: 8443 # 设置端口号为 30001 nodePort: 30001 selector: k8s-app: kubernetes-dashboard 部署到集群 1234567# 部署kubectl create -f kubernetes-dashboard.yaml# 查看kubectl -n kube-system get podskubectl -n kube-system get service kubernetes-dashboardkubectl -n kube-system describe service kubernetes-dashboard 访问需要使用 NodeIP:30001 访问 Dashboard，因为证书原因除火狐浏览器外其它浏览器无法直接打开页面 Chrome 浏览器显示如下 Firefox 浏览器显示如下 点击 接受风险并继续 即可显示欢迎界面 登录我们采用 Token 方式登录 创建登录账号，创建一个名为 dashboard-adminuser.yaml 的配置文件 123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kube-system 1kubectl create -f dashboard-adminuser.yaml 打印 Token 信息 12345678910111213141516kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '&#123;print $1&#125;')# 输出如下Name: admin-user-token-86cz9Namespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: 3902d3d4-8b13-11e9-8089-000c29d49c77Type: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTg2Y3o5Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIzOTAyZDNkNC04YjEzLTExZTktODA4OS0wMDBjMjlkNDljNzciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pA44wyarsahOwqH7X7RVlcdB1k3_j-L3gwOYlTQ4_Lu5ZmfXDFlhqN-Q1tdryJes_V1Nj_utocnXBAxsGzOGaVR4Te4oli3htSepI9MrggQAyeC3C0_QANXGCE6V5L6B5tGZ6tDsY92VDnlvz2N6OrHaH2IJJd2DlxzYvAPvfAFuPeHWuPeVxUisMfXeW42S7US6skZwbZ06JrPYAFxHjqv3zoxRxI8-bmekltvOamsrL0pAXvIUzaowgbjiQb2NgeLAw9O6qfYcz5DAi2C-7G_yAcve6pgnWcIGhVpKoim9DfJUhe1SVx4H4X5Na6GVaaD6FdUIb7UOgsO1FVpTPw 将 Token 输入浏览器，成功登陆后效果如下 Kubernetes DashboardKubernetes Dashboard 是 Kubernetes 集群的 Web UI，用于管理集群。 安装GitHub 地址：Kubernetes Dashboard 下载配置文件 1wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml 修改配置如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# 省略部分代码...# ------------------- Dashboard Deployment ------------------- #kind: DeploymentapiVersion: apps/v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: kubernetes-dashboard template: metadata: labels: k8s-app: kubernetes-dashboard spec: containers: - name: kubernetes-dashboard # 修改镜像地址为阿里云 image: registry.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1 ports: - containerPort: 8443 protocol: TCP args: - --auto-generate-certificates volumeMounts: - name: kubernetes-dashboard-certs mountPath: /certs - mountPath: /tmp name: tmp-volume livenessProbe: httpGet: scheme: HTTPS path: / port: 8443 initialDelaySeconds: 30 timeoutSeconds: 30 volumes: - name: kubernetes-dashboard-certs secret: secretName: kubernetes-dashboard-certs - name: tmp-volume emptyDir: &#123;&#125; serviceAccountName: kubernetes-dashboard tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule---# ------------------- Dashboard Service ------------------- #kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: # 修改类型为 NodePort 访问 type: NodePort ports: - port: 443 targetPort: 8443 # 设置端口号为 30001 nodePort: 30001 selector: k8s-app: kubernetes-dashboard 到集群 1234567# 部署kubectl create -f kubernetes-dashboard.yaml# 查看kubectl -n kube-system get podskubectl -n kube-system get service kubernetes-dashboardkubectl -n kube-system describe service kubernetes-dashboard 访问需要使用 NodeIP:30001 访问 Dashboard，因为证书原因除火狐浏览器外其它浏览器无法直接打开页面 Chrome 浏览器显示如下 Firefox 浏览器显示如下 点击 接受风险并继续 即可显示欢迎界面 登录我们采用 Token 方式登录 创建登录账号，创建一个名为 dashboard-adminuser.yaml 的配置文件 123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kube-system 1kubectl create -f dashboard-adminuser.yaml 打印 Token 信息 12345678910111213141516kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '&#123;print $1&#125;')# 输出如下Name: admin-user-token-86cz9Namespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: 3902d3d4-8b13-11e9-8089-000c29d49c77Type: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTg2Y3o5Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIzOTAyZDNkNC04YjEzLTExZTktODA4OS0wMDBjMjlkNDljNzciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pA44wyarsahOwqH7X7RVlcdB1k3_j-L3gwOYlTQ4_Lu5ZmfXDFlhqN-Q1tdryJes_V1Nj_utocnXBAxsGzOGaVR4Te4oli3htSepI9MrggQAyeC3C0_QANXGCE6V5L6B5tGZ6tDsY92VDnlvz2N6OrHaH2IJJd2DlxzYvAPvfAFuPeHWuPeVxUisMfXeW42S7US6skZwbZ06JrPYAFxHjqv3zoxRxI8-bmekltvOamsrL0pAXvIUzaowgbjiQb2NgeLAw9O6qfYcz5DAi2C-7G_yAcve6pgnWcIGhVpKoim9DfJUhe1SVx4H4X5Na6GVaaD6FdUIb7UOgsO1FVpTPw 将 Token 输入浏览器，成功登陆后效果如下 Kubectl 常用命令 小提示： 所有命令前都可以加上 watch 命令来观察状态的实时变化，如：watch kubectl get pods --all-namespaces 查看组件状态1kubectl get cs 查看环境信息1kubectl cluster-info 查看 Node1kubectl get nodes -o wide 查看集群配置1kubectl -n kube-system get cm kubeadm-config -oyaml 运行容器1kubectl run nginx --image=nginx --replicas=2 --port=80 暴露服务1kubectl expose deployment nginx --port=80 --type=LoadBalancer 查看命名空间1kubectl get namespace 创建命名空间1234apiVersion: v1kind: Namespacemetadata: name: development 查看容器12kubectl get pods -o widekubectl get deployment -o wide 查看服务1kubectl get service -o wide 查看详情123kubectl describe pod &lt;Pod Name&gt;kubectl describe deployment &lt;Deployment Name&gt;kubectl describe service &lt;Service Name&gt; 查看日志1kubectl logs -f &lt;Pod Name&gt; 删除容器和服务12kubectl delete deployment &lt;Deployment Name&gt;kubectl delete service &lt;Service Name&gt; 配置方式运行1kubectl create -f &lt;YAML&gt; 配置方式删除1kubectl delete -f &lt;YAML&gt; 查看配置12kubeadm config viewkubectl config view 查看 Ingress1kubectl get ingress 查看持久卷1kubectl get pv 查看持久卷消费者1kubectl get pvc 查看 ConfigMap1kubectl get cm &lt;ConfigMap Name&gt; 修改 ConfigMap1kubectl edit cm &lt;ConfigMap Name&gt;]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
</search>
